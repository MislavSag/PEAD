commit b586a820d8f8eb4a28dd66fe961ea7967c768797
Author: MislavSag <mislav.sagovac@contentio.biz>
Date:   Thu Mar 16 11:37:39 2023 +0100

    final version

diff --git a/Dockerfile b/Dockerfile
new file mode 100644
index 0000000..8de9992
--- /dev/null
+++ b/Dockerfile
@@ -0,0 +1,29 @@
+FROM rocker/r-base:4.1.1
+
+# Install any necessary packages
+RUN apt-get update && apt-get install -y \
+    libssl-dev \
+    libcurl4-openssl-dev \
+    libxml2-dev
+
+# Install necessary R packages
+RUN Rscript -e "install.packages('data.table', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('gausscov', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('paradox', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('mlr3', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('mlr3pipelines', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('mlr3tuning', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('mlr3mbo', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('mlr3misc', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('mlr3filters', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('mlr3learners', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('AzureStor', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('ranger', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('xgboost', repos='http://cran.rstudio.com/')"
+RUN Rscript -e "install.packages('kknn', repos='http://cran.rstudio.com/')"
+
+# Copy the R script into the container
+COPY my-r-script.R /
+
+# Run the R script when the container starts
+CMD ["Rscript", "my-r-script.R"]
diff --git a/live.R b/live.R
new file mode 100644
index 0000000..e69de29
diff --git a/mlr3ml_v1.R b/mlr3ml_v1.R
index 3f853ee..0a414f7 100644
--- a/mlr3ml_v1.R
+++ b/mlr3ml_v1.R
@@ -17,6 +17,7 @@ library(AzureStor)
 blob_key = "0M4WRlV0/1b6b3ZpFKJvevg4xbC/gaNBcdtVZW+zOZcRi0ZLfOm1v/j2FZ4v+o8lycJLu1wVE6HT+ASt0DdAPQ=="
 endpoint = "https://snpmarketdata.blob.core.windows.net/"
 BLOBENDPOINT = storage_endpoint(endpoint, key=blob_key)
+mlr3_save_path = "D:/mlfin/cvresults-pead"
 
 
 
@@ -311,9 +312,8 @@ design
 
 # NESTED CV BENCHMARK -----------------------------------------------------
 # nested for loop
-future::plan("multisession", workers = 4L)
-bmrs = list()
-for (i in seq_len(customi$iters)) { # seq_len(custom$iters)
+# future::plan("multisession", workers = 4L)
+for (i in 17:tail(customi$iters, 1)) { # seq_len(customi$iters)
 
   # debug
   # i = 1
@@ -339,16 +339,19 @@ for (i in seq_len(customi$iters)) { # seq_len(custom$iters)
 
   # nested CV for one round
   design = benchmark_grid(
-    tasks = list(task_ret_week, task_ret_month, task_ret_month2, task_ret_quarter),
+    tasks = list(task_ret_week, task_ret_month), # task_ret_month, task_ret_month2
     learners = at,
     resamplings = customo_
   )
   bmr = benchmark(design, store_models = TRUE)
-  bmrs[[i]] = bmr
+
+  # save locally and to list
+  time_ = format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
+  saveRDS(bmr, file.path(mlr3_save_path, paste0(i, "-", time_, ".rds")))
 }
 
 # inspect single benchmark
-bmr_ = bmrs[[2]]
+bmr_ = readRDS("D:/mlfin/cvresults-pead/1-20230306111336.rds")
 bmr_$aggregate(msrs(c("regr.mse", "linex", "regr.mae")))
 predicitons = as.data.table(as.data.table(bmr_)[, "prediction"][1][[1]][[1]])
 predicitons[, `:=`(
diff --git a/my-r-script.R b/my-r-script.R
new file mode 100644
index 0000000..f14ca1a
--- /dev/null
+++ b/my-r-script.R
@@ -0,0 +1,698 @@
+library(data.table)
+library(gausscov)
+library(paradox)
+library(mlr3)
+library(mlr3pipelines)
+library(mlr3tuning)
+library(mlr3mbo)
+library(mlr3misc)
+library(mlr3filters)
+library(mlr3learners)
+library(AzureStor)
+
+
+
+
+# SETUP -------------------------------------------------------------------
+# azure creds
+blob_key = "0M4WRlV0/1b6b3ZpFKJvevg4xbC/gaNBcdtVZW+zOZcRi0ZLfOm1v/j2FZ4v+o8lycJLu1wVE6HT+ASt0DdAPQ=="
+endpoint = "https://snpmarketdata.blob.core.windows.net/"
+BLOBENDPOINT = storage_endpoint(endpoint, key=blob_key)
+
+
+
+# PREPARE DATA ------------------------------------------------------------
+# read predictors
+DT = fread("https://snpmarketdata.blob.core.windows.net/jphd/pead-predictors.csv")
+
+# create group variable
+DT[, monthid := paste0(data.table::year(as.Date(date, origin = "1970-01-01")),
+                       data.table::month(as.Date(date, origin = "1970-01-01")))]
+DT[, monthid := as.integer(monthid)]
+setorder(DT, monthid)
+
+# define predictors
+cols_non_features <- c("symbol", "date", "time", "right_time",
+                       "bmo_return", "amc_return",
+                       "open", "high", "low", "close", "volume", "returns",
+                       "monthid"
+)
+targets <- c(colnames(DT)[grep("ret_excess", colnames(DT))])
+cols_features <- setdiff(colnames(DT), c(cols_non_features, targets))
+
+# convert columns to numeric. This is important only if we import existing features
+chr_to_num_cols <- setdiff(colnames(DT[, .SD, .SDcols = is.character]), c("symbol", "time", "right_time"))
+print(chr_to_num_cols)
+DT <- DT[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+
+# remove constant columns in set and remove same columns in test set
+features_ <- DT[, ..cols_features]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+cols_features <- setdiff(cols_features, remove_cols)
+
+# convert variables with low number of unique values to factors
+int_numbers = DT[, ..cols_features][, lapply(.SD, function(x) all(as.integer(x)==x) & x > 0.99)]
+int_cols = na.omit(colnames(DT[, ..cols_features])[as.matrix(int_numbers)[1,]])
+factor_cols = DT[, ..int_cols][, lapply(.SD, function(x) length(unique(x)))]
+factor_cols = as.matrix(factor_cols)[1, ]
+factor_cols = factor_cols[factor_cols <= 100]
+DT = DT[, (names(factor_cols)) := lapply(.SD, as.factor), .SD = names(factor_cols)]
+
+# remove observations with missing target
+# if we want to keep as much data as possible an use only one predicitn horizont
+# we can skeep this step
+DT = na.omit(DT, cols = setdiff(targets, colnames(DT)[grep("extreme", colnames(DT))]))
+
+# sort
+setorder(DT, date)
+
+
+
+# TASKS -------------------------------------------------------------------
+print("Tasks")
+### REGRESSION
+# task with future week returns as target
+target_ = colnames(DT)[grep("^ret_excess_stand_5", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+task_ret_week <- as_task_regr(DT[, ..cols_],
+                              id = "task_ret_week",
+                              target = target_)
+
+# task with future month returns as target
+target_ = colnames(DT)[grep("^ret_excess_stand_22", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+task_ret_month <- as_task_regr(DT[, ..cols_],
+                               id = "task_ret_month",
+                               target = target_)
+
+# task with future 2 months returns as target
+target_ = colnames(DT)[grep("^ret_excess_stand_44", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+task_ret_month2 <- as_task_regr(DT[, ..cols_],
+                                id = "task_ret_month2",
+                                target = target_)
+
+# task with future 2 months returns as target
+target_ = colnames(DT)[grep("^ret_excess_stand_66", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+task_ret_quarter <- as_task_regr(DT[, ..cols_],
+                                 id = "task_ret_quarter",
+                                 target = target_)
+
+
+# create group and holdout set
+# create_validation_set <- function(task, validation_month_start = 20226) {
+#   # add group role
+#   task$set_col_roles("monthid", "group")
+#   groups = task$groups
+#
+#   # add validation set
+#   val_ind <- min(which(groups$group == validation_month_start)):nrow(groups)
+#   task$set_row_roles(rows = val_ind, role = "holdout")
+#   task$set_col_roles("monthid", "feature")
+# }
+# create_validation_set(task_aroundzero_month)
+
+# inner custom rolling window resampling
+inner_split  <- function(task, train_length = 36, test_length = 2) {
+  custom = rsmp("custom")
+  task_ <- task$clone()
+  groups = cbind(id = 1:task_$nrow, task_$data(cols = "monthid"))
+  groups_v = groups[, unique(monthid)]
+  rm(task_)
+  train_groups <- lapply(1:(length(groups_v)-train_length-test_length), function(x) groups_v[x:(x+train_length)])
+  test_groups <- lapply(1:(length(groups_v)-train_length-test_length), function(x) groups_v[(x+train_length+1):(x+train_length+test_length)])
+  train_sets <- lapply(train_groups, function(mid) groups[monthid %in% mid, id])
+  test_sets <- lapply(test_groups, function(mid) groups[monthid %in% mid, id])
+  custom$instantiate(task, train_sets, test_sets)
+  return(custom)
+}
+customi = inner_split(task_ret_week)
+
+# outer custom rolling window resampling
+outer_split <- function(task, train_length = 36, test_length = 2, test_length_out = 1) {
+  customo = rsmp("custom")
+  task_ <- task$clone()
+  groups = cbind(id = 1:task_$nrow, task_$data(cols = "monthid"))
+  groups_v = groups[, unique(monthid)]
+  rm(task_)
+  insample_length = train_length + test_length
+  train_groups_out <- lapply(1:(length(groups_v)-train_length-test_length), function(x) groups_v[x:(x+insample_length)])
+  test_groups_out <- lapply(1:(length(groups_v)-train_length-test_length),
+                            function(x) groups_v[(x+insample_length):(x+insample_length+test_length_out-1)])
+  train_sets_out <- lapply(train_groups_out, function(mid) groups[monthid %in% mid, id])
+  test_sets_out <- lapply(test_groups_out, function(mid) groups[monthid %in% mid, id])
+  customo$instantiate(task, train_sets_out, test_sets_out)
+}
+customo = outer_split(task_ret_week)
+
+# custom checks
+(tail(customi$train_set(1), 1) + 1) == customi$test_set(1)[1] # test set start after train set 1
+(tail(customi$train_set(2), 1) + 1) == customi$test_set(2)[1] # test set start after train set 2
+all(c(customi$train_set(1), customi$test_set(1)) == customo$train_set(1)) # train set in outersample contains ids in innersample 1
+all(c(customi$train_set(2), customi$test_set(2)) == customo$train_set(2)) # train set in outersample contains ids in innersample 1
+
+
+
+# ADD PIPELINES -----------------------------------------------------------
+print("Add pipelines")
+PipeOpDropNA = R6::R6Class(
+  "PipeOpDropNA",
+  inherit = mlr3pipelines::PipeOpTaskPreproc,
+  public = list(
+    initialize = function(id = "drop.na") {
+      super$initialize(id)
+    }
+  ),
+
+  private = list(
+    .train_task = function(task) {
+      self$state = list()
+      featuredata = task$data(cols = task$feature_names)
+      exclude = apply(is.na(featuredata), 1, any)
+      task$filter(task$row_ids[!exclude])
+    },
+
+    .predict_task = function(task) {
+      # nothing to be done
+      task
+    }
+  )
+)
+
+PipeOpDropNACol = R6::R6Class(
+  "PipeOpDropNACol",
+  inherit = mlr3pipelines::PipeOpTaskPreprocSimple,
+  public = list(
+    initialize = function(id = "drop.nacol", param_vals = list()) {
+      ps = ParamSet$new(list(
+        ParamDbl$new("cutoff", lower = 0, upper = 1, default = 0.05, tags = c("dropnacol_tag"))
+      ))
+      ps$values = list(cutoff = 0.2)
+      super$initialize(id, param_set = ps, param_vals = param_vals)
+    }
+  ),
+
+  private = list(
+    .get_state = function(task) {
+      pv = self$param_set$get_values(tags = "dropnacol_tag")
+      features_names = task$feature_names
+      data = task$data(cols = features_names)
+      keep = sapply(data, function(column) (sum(is.na(column))) / length(column) < pv$cutoff)
+      list(cnames = colnames(data)[keep])
+    },
+
+    .transform = function(task) {
+      task$select(self$state$cnames)
+    }
+  )
+)
+PipeOpDropCorr = R6::R6Class(
+  "PipeOpDropCorr",
+  inherit = mlr3pipelines::PipeOpTaskPreprocSimple,
+  public = list(
+    initialize = function(id = "drop.const", param_vals = list()) {
+      ps = ParamSet$new(list(
+        ParamFct$new("use", c("everything", "all.obs", "complete.obs", "na.or.complete", "pairwise.complete.obs"), default = "everything"),
+        ParamFct$new("method", c("pearson", "kendall", "spearman"), default = "pearson"),
+        ParamDbl$new("cutoff", lower = 0, upper = 1, default = 0.99)
+      ))
+      ps$values = list(use = "everything", method = "pearson", cutoff = 0.99)
+      super$initialize(id = id, param_set = ps, param_vals = param_vals, feature_types = c("numeric"))
+    }
+  ),
+
+  private = list(
+    .get_state = function(task) {
+      # debug
+      # pv = list(
+      #   use = "everything",
+      #   method = "pearson",
+      #   cutoff = 0.9
+      # )
+
+      fn = task$feature_types[type == self$feature_types, id]
+      data = task$data(cols = fn)
+      pv = self$param_set$values
+
+      cm = mlr3misc::invoke(stats::cor, x = data, use = pv$use, method = pv$method)
+      cm[upper.tri(cm)] <- 0
+      diag(cm) <- 0
+      cm <- abs(cm)
+      remove_cols <- colnames(data)[apply(cm, 2, function(x) any(x > pv$cutoff))]
+      keep_cols <- setdiff(fn, remove_cols)
+      list(cnames = keep_cols)
+    },
+
+    .transform = function(task) {
+      task$select(self$state$cnames)
+    }
+  )
+)
+FilterGausscovF1st = R6::R6Class(
+  "FilterGausscovF1st",
+  inherit = mlr3filters::Filter,
+
+  public = list(
+
+    #' @description Create a GaussCov object.
+    initialize = function() {
+      param_set = ps(
+        p0   = p_dbl(lower = 0, upper = 1, default = 0.01),
+        kmn  = p_int(lower = 0, default = 0),
+        kmx  = p_int(lower = 0, default = 0),
+        mx   = p_int(lower = 1, default = 21),
+        kex  = p_int(lower = 0, default = 0),
+        sub  = p_lgl(default = TRUE),
+        inr  = p_lgl(default = TRUE),
+        xinr = p_lgl(default = FALSE),
+        qq   = p_int(lower = 0, default = 0)
+      )
+
+      super$initialize(
+        id = "gausscov_f1st",
+        task_types = c("classif", "regr"),
+        param_set = param_set,
+        feature_types = c("integer", "numeric"),
+        packages = "gausscov",
+        label = "Gauss Covariance f1st",
+        man = "mlr3filters::mlr_filters_gausscov_f1st"
+      )
+    }
+  ),
+
+  private = list(
+    .calculate = function(task, nfeat) {
+      # debug
+      # pv = list(
+      #   p0   = 0.01,
+      #   kmn  = 0,
+      #   kmx  = 0,
+      #   mx   = 21,
+      #   kex  = 0,
+      #   sub  = TRUE,
+      #   inr  = TRUE,
+      #   xinr = FALSE,
+      #   qq   = 0
+      # )
+
+      # empty vector with variable names as vector names
+      scores = rep(-1, length(task$feature_names))
+      scores = mlr3misc::set_names(scores, task$feature_names)
+
+      # calculate gausscov pvalues
+      pv = self$param_set$values
+      x = as.matrix(task$data(cols = task$feature_names))
+      if (task$task_type == "classif") {
+        y = as.matrix(as.integer(task$truth()))
+      } else {
+        y = as.matrix(task$truth())
+      }
+      res = mlr3misc::invoke(gausscov::f1st, y = y, x = x, .args = pv)
+      res_1 = res[[1]]
+      res_1 = res_1[res_1[, 1] != 0, , drop = FALSE]
+      scores[res_1[, 1]] = abs(res_1[, 4])
+      sort(scores, decreasing = TRUE)
+    }
+  )
+)
+PipeOpUniform = R6::R6Class(
+  "PipeOpUniform",
+  inherit = mlr3pipelines::PipeOpTaskPreproc,
+  public = list(
+    groups = NULL,
+    initialize = function(id = "uniformization", param_vals = list()) {
+      super$initialize(id, param_vals = param_vals, feature_types = c("numeric", "integer"))
+    }
+  ),
+
+  private = list(
+
+    .select_cols = function(task) {
+      self$groups = task$groups
+      task$feature_names
+    },
+
+    .train_dt = function(dt, levels, target) {
+      # state variables
+      if (!(is.null(self$groups))) {
+        row_ids  = self$groups[group == self$groups[nrow(self$groups), group], row_id]
+        ecdf_ = mlr3misc::map(dt[row_ids], ecdf)
+      } else {
+        ecdf_ = mlr3misc::map(dt, ecdf)
+      }
+      self$state = list(
+        ecdf_ = ecdf_
+      )
+
+      # dt object train
+      if (!(is.null(self$groups))) {
+        dt = dt[, lapply(.SD, function(x) as.vector(ecdf(x)(x))), by = self$groups[, group]]
+        dt = dt[, -1]
+      } else {
+        dt = dt[, lapply(.SD, function(x) ecdf(x)(x))]
+      }
+      dt
+    },
+
+    .predict_dt = function(dt, levels) {
+      dt[, Map(function(a, b) b(a), .SD, self$state$ecdf_)]
+    }
+  )
+)
+PipeOpWinsorizeSimple = R6::R6Class(
+  "PipeOpWinsorizeSimple",
+  inherit = mlr3pipelines::PipeOpTaskPreprocSimple,
+  public = list(
+    groups = NULL,
+    initialize = function(id = "winsorization", param_vals = list()) {
+      ps = ParamSet$new(list(
+        ParamDbl$new("probs_low", lower = 0, upper = 1, default = 0.05, tags = c("winsorize_tag")),
+        ParamDbl$new("probs_high", lower = 0, upper = 1, default = 0.95, tags = c("winsorize_tag")),
+        ParamLgl$new("na.rm", default = TRUE, tags = c("winsorize_tag")),
+        ParamInt$new("qtype", lower = 1L, upper = 9L, default = 7L, tags = c("winsorize_tag"))
+      ))
+      ps$values = list(qtype = 7L)
+      super$initialize(id, param_set = ps, param_vals = param_vals, feature_types = c("numeric"))
+    }
+  ),
+
+  private = list(
+
+    .get_state_dt = function(dt, levels, target) {
+      # debug
+      # task = copy(tsk_aroundzero_month)
+      # dt = tsk_aroundzero_month$data()
+      # cols = tsk_aroundzero_month$feature_types[type %in% c("numeric", "integer"), id]
+      # dt = dt[, ..cols]
+      # pv = list(
+      #   probs_low = 0.01, probs_high = 0.99, na.rm = TRUE, qtype = 7
+      # )
+      # self = list()
+
+      # params
+      pv = self$param_set$get_values(tags = "winsorize_tag")
+
+      # state variables
+      q = dt[, lapply(.SD,
+                      quantile,
+                      probs = c(pv$probs_low, pv$probs_high),
+                      na.rm = pv$na.rm,
+                      type = pv$qtype)]
+      list(
+        minvals = q[1],
+        maxvals = q[2]
+      )
+    },
+
+    .transform_dt  = function(dt, levels) {
+      dt = dt[, Map(function(a, b) ifelse(a < b, b, a), .SD, self$state$minvals)]
+      dt = dt[, Map(function(a, b) ifelse(a > b, b, a), .SD, self$state$maxvals)]
+      dt
+    }
+  )
+)
+PipeOpWinsorize = R6::R6Class(
+  "PipeOpWinsorize",
+  inherit = mlr3pipelines::PipeOpTaskPreproc,
+  public = list(
+    groups = NULL,
+    initialize = function(id = "winsorization", param_vals = list()) {
+      ps = ParamSet$new(list(
+        ParamDbl$new("probs_low", lower = 0, upper = 1, default = 0.05, tags = c("winsorize_tag")),
+        ParamDbl$new("probs_high", lower = 0, upper = 1, default = 0.95, tags = c("winsorize_tag")),
+        ParamLgl$new("na.rm", default = TRUE, tags = c("winsorize_tag")),
+        ParamInt$new("qtype", lower = 1L, upper = 9L, default = 7L, tags = c("winsorize_tag"))
+      ))
+      ps$values = list(qtype = 7L)
+      super$initialize(id, param_set = ps, param_vals = param_vals, feature_types = c("numeric", "integer"))
+    }
+  ),
+
+  private = list(
+
+    # .select_cols = function(task) {
+    #   self$groups = task$groups
+    #   cols = task$feature_types[type %in% self$feature_types, id]
+    #   cols[cols %in% task$feature_names]
+    # },
+
+    .train_dt = function(dt, levels, target) {
+      # debug
+      # task = copy(tsk_aroundzero_month)
+      # dt = tsk_aroundzero_month$data()
+      # cols = tsk_aroundzero_month$feature_types[type %in% c("numeric", "integer"), id]
+      # dt = dt[, ..cols]
+      # pv = list(
+      #   probs_low = 0.01, probs_high = 0.99, na.rm = TRUE, qtype = 7
+      # )
+      # self = list()
+
+      # params
+      pv = self$param_set$get_values(tags = "winsorize_tag")
+
+      # state variables
+      # if (!(is.null(self$groups))) {
+      #   row_ids  = self$groups[group == self$groups[nrow(self$groups), group], row_id]
+      #   q = dt[row_ids, lapply(.SD,
+      #                          quantile,
+      #                          probs = c(pv$probs_low, pv$probs_high),
+      #                          na.rm = pv$na.rm,
+      #                          type = pv$qtype)]
+      # } else {
+      q = dt[, lapply(.SD,
+                      quantile,
+                      probs = c(pv$probs_low, pv$probs_high),
+                      na.rm = pv$na.rm,
+                      type = pv$qtype)]
+      # }
+      self$state = list(
+        minvals = q[1],
+        maxvals = q[2]
+      )
+
+      # dt object train
+      # if (!(is.null(self$groups))) {
+      #   dt = dt[, lapply(.SD, function(x){
+      #     q = quantile(x,
+      #                  probs = c(pv$probs_low, pv$probs_high),
+      #                  na.rm = pv$na.rm,
+      #                  type = pv$qtype)
+      #     minval = q[1L]
+      #     maxval = q[2L]
+      #     x[x < minval] <- minval
+      #     x[x > maxval] <- maxval
+      #     x
+      #   }), by = self$groups[, group]]
+      #   dt = dt[, -1]
+      # } else {
+      dt = dt[, Map(function(a, b) ifelse(a < b, b, a), .SD, self$state$minvals)]
+      dt = dt[, Map(function(a, b) ifelse(a > b, b, a), .SD, self$state$maxvals)]
+      # }
+      dt
+    },
+
+    .predict_dt  = function(dt, levels) {
+      dt = dt[, Map(function(a, b) ifelse(a < b, b, a), .SD, self$state$minvals)]
+      dt = dt[, Map(function(a, b) ifelse(a > b, b, a), .SD, self$state$maxvals)]
+      dt
+    }
+  )
+)
+Linex = R6::R6Class(
+  "Linex",
+  inherit = mlr3::MeasureRegr,
+  public = list(
+    initialize = function() {
+      super$initialize(
+        # custom id for the measure
+        id = "linex",
+
+        # additional packages required to calculate this measure
+        packages = character(),
+
+        # properties, see below
+        properties = character(),
+
+        # required predict type of the learner
+        predict_type = "response",
+
+        # feasible range of values
+        range = c(0, Inf),
+
+        # minimize during tuning?
+        minimize = TRUE
+      )
+    }
+  ),
+
+  private = list(
+    # custom scoring function operating on the prediction object
+    .score = function(prediction, ...) {
+      linex = function(truth, response, a1 = 1, a2 = -1) {
+        mlr3measures:::assert_regr(truth, response = response)
+        if (a2 == 0) stop("Argument a2 can't be 0.")
+        if (a1 <= 0) stop("Argument a1 must be greater than 0.")
+        e = truth - response
+        mean(abs(a1 * (exp(-a2*e) - a2*e - 1)))
+      }
+
+      linex(prediction$truth, prediction$response)
+      # linex(c(0, 0.5, 1), c(0.5, 0.5, 0.5))
+      # root_mse = function(truth, response) {
+      #   mse = mean((truth - response)^2)
+      #   sqrt(mse)
+      # }
+      #
+      # root_mse(prediction$truth, prediction$response)
+      # root_mse(c(0, 0.5, 1), c(0.5, 0.5, 0.5))
+    }
+  )
+)
+
+# add my pipes to mlr dictionary
+mlr_pipeops$add("uniformization", PipeOpUniform)
+mlr_pipeops$add("winsorize", PipeOpWinsorize)
+mlr_pipeops$add("winsorizesimple", PipeOpWinsorizeSimple)
+mlr_pipeops$add("dropna", PipeOpDropNA)
+mlr_pipeops$add("dropnacol", PipeOpDropNACol)
+mlr_pipeops$add("dropcorr", PipeOpDropCorr)
+mlr_filters$add("gausscov_f1st", FilterGausscovF1st)
+mlr_measures$add("linex", Linex)
+
+
+
+# GRAPH -------------------------------------------------------------------
+print("Graph")
+# learners
+# learners_l = list(
+#   ranger = lrn("classif.ranger", predict_type = "prob", id = "ranger"),
+#   log_reg = lrn("classif.log_reg", predict_type = "prob", id = "log_reg"),
+#   kknn = lrn("classif.kknn", predict_type = "prob", id = "kknn"),
+#   # cv_glmnet = lrn("classif.cv_glmnet", predict_type = "prob", id = "cv_glmnet"),
+#   xgboost = lrn("classif.xgboost", predict_type = "prob", id = "xgboost")
+# )
+learners_l = list(
+  ranger = lrn("regr.ranger", id = "ranger"),
+  lm = lrn("regr.lm", id = "lm"),
+  kknn = lrn("regr.kknn", id = "kknn"),
+  # cv_glmnet = lrn("classif.cv_glmnet", predict_type = "prob", id = "cv_glmnet"),
+  xgboost = lrn("regr.xgboost", id = "xgboost")
+)
+
+# create graph from list of learners
+choices = c("ranger", "lm", "kknn", "xgboost")
+learners = po("branch", choices, id = "branch_learners") %>>%
+  gunion(learners_l) %>>%
+  po("unbranch", choices, id = "unbranch_learners")
+
+# create graph
+graph = po("dropnacol", id = "dropnacol", cutoff = 0.05) %>>%
+  po("dropna", id = "dropna") %>>%
+  po("removeconstants", id = "removeconstants_1", ratio = 0)  %>>%
+  po("winsorizesimple", id = "winsorizesimple", probs_low = 0.01, probs_high = 0.99, na.rm = TRUE) %>>%
+  po("removeconstants", id = "removeconstants_2", ratio = 0)  %>>%
+  po("dropcorr", id = "dropcorr", cutoff = 0.99) %>>%
+  po("uniformization") %>>%
+  po("dropna", id = "dropna_v2") %>>%
+  po("filter", filter = flt("gausscov_f1st"), filter.cutoff = 0) %>>%  # filter important predictors
+  # modelmatrix
+  po("branch", options = c("nop_filter", "modelmatrix"), id = "interaction_branch") %>>%
+  gunion(list(po("nop", id = "nop_filter"), po("modelmatrix", formula = ~ . ^ 2))) %>>%
+  po("unbranch", id = "interaction_unbranch") %>>%
+  po("removeconstants", id = "removeconstants_3", ratio = 0) %>>%
+  # learners
+  learners %>>%
+  po("regravg", innum = length(learners_l))
+plot(graph)
+graph_learner = as_learner(graph)
+
+# define search space
+as.data.table(graph_learner$param_set)[1:100, .(id, class, lower, upper)]
+as.data.table(graph_learner$param_set)[grep("drop", id), .(id, class, lower, upper)]
+search_space = ps(
+  # preprocessing
+  dropcorr.cutoff = p_fct(levels = c("0.90", "0.99"), trafo = function(x, param_set) {
+    switch(x,
+           "0.90" = 0.90,
+           "0.99" = 0.99
+    )
+  }),
+  interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  # winsorizesimple.probs_high = p_fct(levels = c("0.99", "0.98", "0.97", "0.90")),
+  winsorizesimple.probs_high = p_fct(levels = c(0.99, 0.98, 0.97, 0.90)),
+  # winsorizesimple.probs_low = p_dbl(lower = 0, upper = 1, ),
+  # winsorizesimple.probs_low = p_fct(levels = c("0.01", "0.02", "0.03", "0.1")),
+  winsorizesimple.probs_low = p_fct(levels = c(0.01, 0.02, 0.03, 0.1)),
+  # ranger
+  ranger.ranger.max.depth = p_fct(levels = c(2L, 10L)),
+  ranger.ranger.splitrule = p_fct(levels = c("variance", "extratrees")),
+  ranger.ranger.mtry.ratio = p_dbl(0.5, 1),
+  # kknn
+  kknn.kknn.k = p_int(1, 10)
+  # extra transformations
+  # .extra_trafo = function(x, param_set) {
+  #   x$winsorizesimple.probs_high = switch(
+  #     x$winsorizesimple.probs_high,
+  #     "0.99" = 0.99,
+  #     "0.98" = 0.98,
+  #     "0.97" = 0.97
+  #   )
+  #   x$winsorizesimple.probs_low = 1 - as.numeric(x$winsorizesimple.probs_high)
+  #   x
+  # }
+)
+
+# inspect search space
+design = rbindlist(generate_design_grid(search_space, 3)$transpose(), fill = TRUE)
+design
+
+
+
+# NESTED CV BENCHMARK -----------------------------------------------------
+print("Nested banchmark")
+# nested for loop
+# future::plan("multisession", workers = 4L)
+for (i in 26:tail(customi$iters, 1)) { # seq_len(customi$iters)
+
+  # debug
+  # i = 1
+  print(i)
+
+  # inner resampling
+  print("Inner resampling")
+  custom_ = rsmp("custom")
+  custom_$instantiate(task_ret_week, list(customi$train_set(i)), list(customi$test_set(i)))
+
+  # auto tuner
+  print("Auto tuner")
+  at = auto_tuner(
+    tuner = tnr("mbo"), # tnr("random_search", batch_size = 3),
+    learner = graph_learner,
+    resampling = custom_,
+    measure = msr("linex"),
+    search_space = search_space,
+    term_evals = 5
+  )
+
+  # outer resampling
+  print("Outer resampling")
+  customo_ = rsmp("custom")
+  customo_$instantiate(task_ret_week, list(customo$train_set(i)), list(customo$test_set(i)))
+
+  # nested CV for one round
+  print("Design")
+  design = benchmark_grid(
+    tasks = list(task_ret_week, task_ret_month), # task_ret_month, task_ret_month2
+    learners = at,
+    resamplings = customo_
+  )
+  bmr = benchmark(design, store_models = TRUE)
+
+  # save to azure blob
+  print("Save")
+  cont = storage_container(BLOBENDPOINT, "peadcv")
+  time_ = format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
+  storage_save_rds(bmr, cont, paste0(i, "-", time_, ".rds"))
+}
diff --git a/pead_v3.R b/pead_v3.R
index ac11360..19e115a 100644
--- a/pead_v3.R
+++ b/pead_v3.R
@@ -32,6 +32,9 @@ pd = reticulate::import("pandas", convert = FALSE)
 builtins = import_builtins(convert = FALSE)
 main = import_main(convert = FALSE)
 tsfel = reticulate::import("tsfel", convert = FALSE)
+tsfresh = reticulate::import("tsfresh", convert = FALSE)
+warnigns = reticulate::import("warnings", convert = FALSE)
+warnigns$filterwarnings('ignore')
 
 
 
@@ -55,7 +58,6 @@ fredr_set_key(Sys.getenv("FRED-KEY"))
 
 # parameters
 strategy = "PEAD"  # PEAD (for predicting post announcement drift) or PRE (for predicting pre announcement)
-start_holdout_date = as.Date("2021-06-01") # observations after this date belongs to holdout set
 events_data <- "intersection" # data source, one of "fmp", "investingcom", "intersection"
 
 
@@ -65,7 +67,7 @@ events_data <- "intersection" # data source, one of "fmp", "investingcom", "inte
 arr <- tiledb_array("s3://equity-usa-earningsevents", as.data.frame = TRUE)
 events <- arr[]
 events <- as.data.table(events)
-setorder(events)
+setorder(events, date)
 
 # coarse filtering
 events <- events[date < Sys.Date()]                 # remove announcements for today
@@ -179,6 +181,7 @@ spy <- prices_dt[symbol == "SPY", .(symbol, date, open, high, low, close, volume
 
 # REGRESSION LABELING ----------------------------------------------------------
 # calculate returns
+setorder(prices_dt, symbol, date)
 prices_dt[, ret_5 := shift(close, -5L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]   # PEAD
 prices_dt[, ret_22 := shift(close, -21L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"] # PEAD
 prices_dt[, ret_44 := shift(close, -43L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"] # PEAD
@@ -393,12 +396,12 @@ RollingGpdFeatures = RollingGpdInit$get_rolling_features(OhlcvInstance)
 # theft catch22 features
 print("Calculate Catch22 features.")
 RollingTheftInit = RollingTheft$new(windows = c(5, 22, 22 * 3, 22 * 12),
-                                    workers = 8L, at = at_, lag = lag_,
+                                    workers = 4L, at = at_, lag = lag_,
                                     features_set = c("catch22", "feasts"))
 RollingTheftCatch22Features = RollingTheftInit$get_rolling_features(OhlcvInstance)
 gc()
 
-# theft tsfeatures features
+# tsfeatures features
 print("Calculate tsfeatures features.")
 RollingTsfeaturesInit = RollingTsfeatures$new(windows = c(22 * 3, 22 * 6),
                                               workers = 8L, at = at_,
@@ -408,10 +411,15 @@ gc()
 
 # theft tsfel features, Must be alone, because number of workers have to be 1L
 print("Calculate tsfel features.")
+
+RollingTheftInit = RollingTheft$new(windows = c(22 * 3), workers = 1L,
+                                    at = 1:70, lag = lag_,  features_set = "TSFEL")
+test = Ohlcv$new(prices_dt[1:70, .(symbol, date, open, high, low, close, volume)], date_col = "date")
+RollingTheftTsfelFeatures = suppressMessages(RollingTheftInit$get_rolling_features(test))
+
+
 RollingTheftInit = RollingTheft$new(windows = c(22 * 3, 22 * 12), workers = 1L,
-                                    at = at_, lag = lag_,  features_set = "tsfel")
-RollingTheftTsfelFeatures = suppressMessages(RollingTheftInit$get_rolling_features(OhlcvInstance))
-gc()
+                                    at = at_, lag = lag_,  features_set = "TSFEL")
 
 # quarks
 RollingQuarksInit = RollingQuarks$new(windows = 22 * 6, workers = 6L, at = at_,
@@ -442,29 +450,30 @@ gc()
 # merge all features test
 features_set <- Reduce(function(x, y) merge(x, y, by = c("symbol", "date"),
                                             all.x = TRUE, all.y = FALSE),
-                       list(RollingBidAskFeatures,
-                            RollingBackCusumFeatures,
+                       list(OhlcvFeaturesSetSample,
+                            # RollingBidAskFeatures,
+                            # RollingBackCusumFeatures,
                             # RollingExuberFeatures,
-                            RollingForecatsFeatures,
+                            # RollingForecatsFeatures,
                             # RollingGasFeatures,
                             # RollingGpdFeatures,
                             RollingTheftCatch22Features,
-                            RollingTheftTsfelFeatures,
-                            RollingTsfeaturesFeatures,
-                            RollingQuarksFeatures,
+                            RollingTheftTsfelFeatures
+                            # RollingTsfeaturesFeatures,
+                            # RollingQuarksFeatures,
                             # RollingTvgarchFeatures
-                            RollingWaveletArimaFeatures
+                            # RollingWaveletArimaFeatures
                        ))
 features <- features_set[OhlcvFeaturesSetSample, on = c("symbol", "date"), roll = Inf]
+
+# check
 head(OhlcvFeaturesSetSample[, 1:5])
 head(features_set[, 1:5])
 head(features[, 1:5])
 
 # save ohlcv features and merged features
-# time_ <- format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
-# fwrite(OhlcvFeaturesSet, paste0("D:/features/OhlcvFeatues-PEAD-", time_, ".csv"))
-# fwrite(features, paste0("D:/features-PEAD-", time_, ".csv"))
-# fwrite(RollingGasFeatures, paste0("D:/features-PEAD-GPD", time_, ".csv"))
+time_ <- format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
+fwrite(features_set, paste0("D:/features-PEAD-", time_, ".csv"))
 
 # import features
 # list.files("D:/features")
diff --git a/postscriptum.R b/postscriptum.R
new file mode 100644
index 0000000..2e4b298
--- /dev/null
+++ b/postscriptum.R
@@ -0,0 +1,163 @@
+library(mlr3)
+library(data.table)
+library(AzureStor)
+
+
+
+
+# linex measure
+source("Linex.R")
+mlr_measures$add("linex", Linex)
+
+# setup
+blob_key = "0M4WRlV0/1b6b3ZpFKJvevg4xbC/gaNBcdtVZW+zOZcRi0ZLfOm1v/j2FZ4v+o8lycJLu1wVE6HT+ASt0DdAPQ=="
+endpoint = "https://snpmarketdata.blob.core.windows.net/"
+BLOBENDPOINT = storage_endpoint(endpoint, key=blob_key)
+mlr3_save_path = "D:/mlfin/cvresults-pead"
+
+# read predictors
+DT <- fread("D:/features/pead-predictors.csv")
+
+# create group variable
+DT[, monthid := paste0(data.table::year(as.Date(date, origin = "1970-01-01")),
+                       data.table::month(as.Date(date, origin = "1970-01-01")))]
+DT[, monthid := as.integer(monthid)]
+setorder(DT, monthid)
+
+# define predictors
+cols_non_features <- c("symbol", "date", "time", "right_time",
+                       "bmo_return", "amc_return",
+                       "open", "high", "low", "close", "volume", "returns",
+                       "monthid"
+)
+targets <- c(colnames(DT)[grep("ret_excess", colnames(DT))])
+cols_features <- setdiff(colnames(DT), c(cols_non_features, targets))
+
+# convert columns to numeric. This is important only if we import existing features
+chr_to_num_cols <- setdiff(colnames(DT[, .SD, .SDcols = is.character]), c("symbol", "time", "right_time"))
+print(chr_to_num_cols)
+DT <- DT[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+
+# remove constant columns in set and remove same columns in test set
+features_ <- DT[, ..cols_features]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+cols_features <- setdiff(cols_features, remove_cols)
+
+# convert variables with low number of unique values to factors
+int_numbers = DT[, ..cols_features][, lapply(.SD, function(x) all(as.integer(x)==x) & x > 0.99)]
+int_cols = na.omit(colnames(DT[, ..cols_features])[as.matrix(int_numbers)[1,]])
+factor_cols = DT[, ..int_cols][, lapply(.SD, function(x) length(unique(x)))]
+factor_cols = as.matrix(factor_cols)[1, ]
+factor_cols = factor_cols[factor_cols <= 100]
+DT = DT[, (names(factor_cols)) := lapply(.SD, as.factor), .SD = names(factor_cols)]
+
+# remove observations with missing target
+DT = na.omit(DT, cols = setdiff(targets, colnames(DT)[grep("extreme", colnames(DT))]))
+
+# sort
+setorder(DT, date)
+
+# add rowid column
+DT[, row_ids := 1:.N]
+
+# check saved files
+res_files = file.info(list.files(mlr3_save_path, full.names = TRUE))
+res_files = res_files[order(res_files$ctime), ]
+
+### REGRESSION
+# task with future week returns as target
+target_ = colnames(DT)[grep("^ret_excess_stand_5", colnames(DT))]
+cols_ = c(target_, "symbol", "monthid", cols_features)
+task_ret_week <- as_task_regr(DT[, ..cols_],
+                              id = "task_ret_week",
+                              target = target_)
+
+# outer custom rolling window resampling
+outer_split <- function(task, train_length = 36, test_length = 2, test_length_out = 1) {
+  customo = rsmp("custom")
+  task_ <- task$clone()
+  groups = cbind(id = 1:task_$nrow, task_$data(cols = "monthid"))
+  groups_v = groups[, unique(monthid)]
+  rm(task_)
+  insample_length = train_length + test_length
+  train_groups_out <- lapply(1:(length(groups_v)-train_length-test_length), function(x) groups_v[x:(x+insample_length)])
+  test_groups_out <- lapply(1:(length(groups_v)-train_length-test_length),
+                            function(x) groups_v[(x+insample_length):(x+insample_length+test_length_out-1)])
+  train_sets_out <- lapply(train_groups_out, function(mid) groups[monthid %in% mid, id])
+  test_sets_out <- lapply(test_groups_out, function(mid) groups[monthid %in% mid, id])
+  customo$instantiate(task, train_sets_out, test_sets_out)
+}
+customo = outer_split(task_ret_week)
+
+
+# function to check infividual benchmark result
+bmrs = lapply(rownames(res_files[2:nrow(res_files),]), readRDS)
+
+# get predictions function
+get_predictions_by_task = function(bmr, DT) {
+  bmr_dt = as.data.table(bmr)
+  task_names = lapply(bmr_dt$task, function(x) x$id)
+  # task_names = lapply(bmr_dt$task, function(x) x$id)
+  predictions = lapply(bmr_dt$prediction, function(x) as.data.table(x))
+  names(predictions) <- task_names
+  predictions <- lapply(predictions, function(x) {
+    x = DT[, .(row_ids, symbol, date)][x, on = "row_ids"]
+    x[, date := as.Date(date, origin = "1970-01-01")]
+  })
+  return(predictions)
+}
+predictions = lapply(bmrs, get_predictions_by_task, DT = DT)
+
+# choose task
+task_name = "task_ret_week"
+predictions_task = lapply(predictions, function(x) {
+  x[[task_name]]
+})
+predictions_task <- rbindlist(predictions_task)
+
+# save to azure for QC backtest
+predictions_qc <- predictions_task[, .(symbol, date, response)]
+predictions_qc = predictions_qc[, .(symbol = paste0(symbol, collapse = "|"),
+                                    response = paste0(response, collapse = "|")), by = date]
+predictions_qc[, date := as.character(date)]
+cont = storage_container(BLOBENDPOINT, "qc-backtest")
+storage_write_csv(predictions_qc, cont, "pead_task_ret_week.csv")
+universe = predictions_qc[, .(date, symbol)]
+storage_write_csv(universe, cont, "pead_task_ret_week_universe.csv", col_names = FALSE)
+
+# performance by varioues measures
+bmr_$aggregate(msrs(c("regr.mse", "linex", "regr.mae")))
+predicitons = as.data.table(as.data.table(bmr_)[, "prediction"][1][[1]][[1]])
+
+# prrformance by hit ratio
+predicitons[, `:=`(
+  truth_sign = as.factor(sign(truth)),
+  response_sign = as.factor(sign(response))
+)]
+mlr3measures::acc(predicitons$truth_sign, predicitons$response_sign)
+
+# hiy ratio for high predicted returns
+predicitons_sample = predicitons[response > 0.1]
+mlr3measures::acc(predicitons_sample$truth_sign, predicitons_sample$response_sign)
+
+# cumulative returns for same sample
+predicitons_sample[, .(
+  benchmark = mean(predicitons$truth),
+  strategy  = mean(truth)
+)]
+
+# important predictors
+bmr_ = bmrs[[18]]
+lapply(1:2, function(i) {
+  resample_res = as.data.table(bmr_$resample_result(i))
+  resample_res$learner[[1]]$state$model$learner$state$model$gausscov_f1st$features
+})
+
+# performance for every learner
+resample_res$learner[[1]]$state$model$learner$state$model$ranger.ranger$model$predictions
+as.data.table(bmr_)
+
+
+
+
diff --git a/setup.yaml b/setup.yaml
new file mode 100644
index 0000000..f51bfc0
--- /dev/null
+++ b/setup.yaml
@@ -0,0 +1,15 @@
+apiVersion: batch/v1  # Which version of the Kubernetes API you're using to create this object
+kind: Job             # What kind of object you want to create
+metadata:
+  name: peadv2 # Data that helps uniquely identify the object, including a name string, UID, and optional namespace
+  namespace: strategies
+spec:
+  template:
+    spec:
+      containers:
+      - name: peadv2
+        image: cgskbsregistry.azurecr.io/pead:latest
+      restartPolicy: Never
+      nodeSelector:
+        agentpool: strong
+  backoffLimit: 2  # specifies the number of re-tries before job controller gives up

commit a8561d45fd90e5018ad09e6073330e4285a7bfaf
Author: unknown <mislav.sagovac@contentio.biz>
Date:   Thu Mar 2 11:39:47 2023 +0100

    add new pipes

diff --git a/Linex.R b/Linex.R
new file mode 100644
index 0000000..98788ee
--- /dev/null
+++ b/Linex.R
@@ -0,0 +1,50 @@
+Linex = R6::R6Class(
+  "Linex",
+  inherit = mlr3::MeasureRegr,
+  public = list(
+    initialize = function() {
+      super$initialize(
+        # custom id for the measure
+        id = "linex",
+
+        # additional packages required to calculate this measure
+        packages = character(),
+
+        # properties, see below
+        properties = character(),
+
+        # required predict type of the learner
+        predict_type = "response",
+
+        # feasible range of values
+        range = c(0, Inf),
+
+        # minimize during tuning?
+        minimize = TRUE
+      )
+    }
+  ),
+
+  private = list(
+    # custom scoring function operating on the prediction object
+    .score = function(prediction, ...) {
+      linex = function(truth, response, a1 = 1, a2 = -1) {
+        mlr3measures:::assert_regr(truth, response = response)
+        if (a2 == 0) stop("Argument a2 can't be 0.")
+        if (a1 <= 0) stop("Argument a1 must be greater than 0.")
+        e = truth - response
+        mean(abs(a1 * (exp(-a2*e) - a2*e - 1)))
+      }
+
+      linex(prediction$truth, prediction$response)
+      # linex(c(0, 0.5, 1), c(0.5, 0.5, 0.5))
+      # root_mse = function(truth, response) {
+      #   mse = mean((truth - response)^2)
+      #   sqrt(mse)
+      # }
+      #
+      # root_mse(prediction$truth, prediction$response)
+      # root_mse(c(0, 0.5, 1), c(0.5, 0.5, 0.5))
+    }
+  )
+)
diff --git a/mlr3_dropna.R b/mlr3_dropna.R
index 3482f29..4e1a2ff 100644
--- a/mlr3_dropna.R
+++ b/mlr3_dropna.R
@@ -26,15 +26,15 @@ PipeOpDropNA = R6::R6Class(
     }
   )
 )
-
-# no group variable
-task = tsk("iris")
-new_dt = data.table("setosa", 1,2, 3, NA)
-setnames(new_dt, names(task$data()))
-task$rbind(new_dt)
-task$data()
-gr = Graph$new()
-gr$add_pipeop(PipeOpDropNA$new())
-result = gr$train(task)
-result[[1]]$data()
-gr$predict(task)
+#
+# # no group variable
+# task = tsk("iris")
+# new_dt = data.table("setosa", 1,2, 3, NA)
+# setnames(new_dt, names(task$data()))
+# task$rbind(new_dt)
+# task$data()
+# gr = Graph$new()
+# gr$add_pipeop(PipeOpDropNA$new())
+# result = gr$train(task)
+# result[[1]]$data()
+# gr$predict(task)
diff --git a/mlr3_filter_drop_corr.R b/mlr3_filter_drop_corr.R
index ccfedc6..3c0a6ae 100644
--- a/mlr3_filter_drop_corr.R
+++ b/mlr3_filter_drop_corr.R
@@ -1,9 +1,3 @@
-library(mlr3)
-library(paradox)
-library(mlr3filters)
-library(mlr3pipelines)
-
-
 PipeOpDropCorr = R6::R6Class(
   "PipeOpDropCorr",
   inherit = mlr3pipelines::PipeOpTaskPreprocSimple,
@@ -32,7 +26,7 @@ PipeOpDropCorr = R6::R6Class(
       data = task$data(cols = fn)
       pv = self$param_set$values
 
-      cm = invoke(stats::cor, x = data, use = pv$use, method = pv$method)
+      cm = mlr3misc::invoke(stats::cor, x = data, use = pv$use, method = pv$method)
       cm[upper.tri(cm)] <- 0
       diag(cm) <- 0
       cm <- abs(cm)
diff --git a/mlr3_gausscov_f1st.R b/mlr3_gausscov_f1st.R
index 720ae14..3b62ae7 100644
--- a/mlr3_gausscov_f1st.R
+++ b/mlr3_gausscov_f1st.R
@@ -1,14 +1,3 @@
-library(gausscov)
-library(paradox)
-library(mlr3)
-library(mlr3misc)
-library(mlr3filters)
-library(checkmate)
-library(R6)
-library(backports)
-
-
-
 FilterGausscovF1st = R6::R6Class(
   "FilterGausscovF1st",
   inherit = mlr3filters::Filter,
@@ -58,20 +47,18 @@ FilterGausscovF1st = R6::R6Class(
 
       # empty vector with variable names as vector names
       scores = rep(-1, length(task$feature_names))
-      scores = set_names(scores, task$feature_names)
+      scores = mlr3misc::set_names(scores, task$feature_names)
 
       # calculate gausscov pvalues
       pv = self$param_set$values
-      print(pv)
       x = as.matrix(task$data(cols = task$feature_names))
       if (task$task_type == "classif") {
         y = as.matrix(as.integer(task$truth()))
       } else {
         y = as.matrix(task$truth())
       }
-      res = invoke(gausscov::f1st, y = y, x = x, .args = pv)
+      res = mlr3misc::invoke(gausscov::f1st, y = y, x = x, .args = pv)
       res_1 = res[[1]]
-      print(res_1)
       res_1 = res_1[res_1[, 1] != 0, , drop = FALSE]
       scores[res_1[, 1]] = abs(res_1[, 4])
       sort(scores, decreasing = TRUE)
@@ -79,7 +66,7 @@ FilterGausscovF1st = R6::R6Class(
   )
 )
 
-mlr_filters$add("gausscov_f1st", FilterGausscovF1st)
+# mlr_filters$add("gausscov_f1st", FilterGausscovF1st)
 
 # # no group variable
 # task = tsk("iris")
diff --git a/mlr3_uniformization.R b/mlr3_uniformization.R
index b49bdd7..b6e40cc 100644
--- a/mlr3_uniformization.R
+++ b/mlr3_uniformization.R
@@ -1,8 +1,3 @@
-library(mlr3pipelines)
-library(mlr3verse)
-library(mlr3misc)
-library(R6)
-
 PipeOpUniform = R6::R6Class(
   "PipeOpUniform",
   inherit = mlr3pipelines::PipeOpTaskPreproc,
@@ -24,9 +19,9 @@ PipeOpUniform = R6::R6Class(
       # state variables
       if (!(is.null(self$groups))) {
         row_ids  = self$groups[group == self$groups[nrow(self$groups), group], row_id]
-        ecdf_ = map(dt[row_ids], ecdf)
+        ecdf_ = mlr3misc::map(dt[row_ids], ecdf)
       } else {
-        ecdf_ = map(dt, ecdf)
+        ecdf_ = mlr3misc::map(dt, ecdf)
       }
       self$state = list(
         ecdf_ = ecdf_
@@ -49,24 +44,24 @@ PipeOpUniform = R6::R6Class(
 )
 
 
-library("mlr3")
-
-# no group variable
-task = tsk("iris")
-gr = Graph$new()
-gr$add_pipeop(PipeOpUniform$new())
-result = gr$train(task)
-result[[1]]$data()
-gr$predict(task)
-
-# group variable
-dt = tsk("iris")$data()
-dt[, monthid := c(rep(1, 50), rep(2, 50), rep(3, 50))]
-task = as_task_classif(dt, target = "Species")
-task$set_col_roles("monthid", "group")
-gr = Graph$new()
-gr$add_pipeop(PipeOpUniform$new())
-result = gr$train(task)
-result[[1]]$data()
-preds = gr$predict(task)
-preds$uniformization.output$data()
+# library("mlr3")
+#
+# # no group variable
+# task = tsk("iris")
+# gr = Graph$new()
+# gr$add_pipeop(PipeOpUniform$new())
+# result = gr$train(task)
+# result[[1]]$data()
+# gr$predict(task)
+#
+# # group variable
+# dt = tsk("iris")$data()
+# dt[, monthid := c(rep(1, 50), rep(2, 50), rep(3, 50))]
+# task = as_task_classif(dt, target = "Species")
+# task$set_col_roles("monthid", "group")
+# gr = Graph$new()
+# gr$add_pipeop(PipeOpUniform$new())
+# result = gr$train(task)
+# result[[1]]$data()
+# preds = gr$predict(task)
+# preds$uniformization.output$data()
diff --git a/mlr3_winsorizationsimple.R b/mlr3_winsorizationsimple.R
new file mode 100644
index 0000000..a9ef8e0
--- /dev/null
+++ b/mlr3_winsorizationsimple.R
@@ -0,0 +1,82 @@
+library(mlr3pipelines)
+library(mlr3verse)
+library(mlr3misc)
+library(R6)
+library(paradox)
+
+PipeOpWinsorizeSimple = R6::R6Class(
+  "PipeOpWinsorizeSimple",
+  inherit = mlr3pipelines::PipeOpTaskPreprocSimple,
+  public = list(
+    groups = NULL,
+    initialize = function(id = "winsorization", param_vals = list()) {
+      ps = ParamSet$new(list(
+        ParamDbl$new("probs_low", lower = 0, upper = 1, default = 0.05, tags = c("winsorize_tag")),
+        ParamDbl$new("probs_high", lower = 0, upper = 1, default = 0.95, tags = c("winsorize_tag")),
+        ParamLgl$new("na.rm", default = TRUE, tags = c("winsorize_tag")),
+        ParamInt$new("qtype", lower = 1L, upper = 9L, default = 7L, tags = c("winsorize_tag"))
+      ))
+      ps$values = list(qtype = 7L)
+      super$initialize(id, param_set = ps, param_vals = param_vals, feature_types = c("numeric"))
+    }
+  ),
+
+  private = list(
+
+    .get_state_dt = function(dt, levels, target) {
+      # debug
+      # task = copy(tsk_aroundzero_month)
+      # dt = tsk_aroundzero_month$data()
+      # cols = tsk_aroundzero_month$feature_types[type %in% c("numeric", "integer"), id]
+      # dt = dt[, ..cols]
+      # pv = list(
+      #   probs_low = 0.01, probs_high = 0.99, na.rm = TRUE, qtype = 7
+      # )
+      # self = list()
+
+      # params
+      pv = self$param_set$get_values(tags = "winsorize_tag")
+
+      # state variables
+      q = dt[, lapply(.SD,
+                      quantile,
+                      probs = c(pv$probs_low, pv$probs_high),
+                      na.rm = pv$na.rm,
+                      type = pv$qtype)]
+      list(
+        minvals = q[1],
+        maxvals = q[2]
+      )
+    },
+
+    .transform_dt  = function(dt, levels) {
+      dt = dt[, Map(function(a, b) ifelse(a < b, b, a), .SD, self$state$minvals)]
+      dt = dt[, Map(function(a, b) ifelse(a > b, b, a), .SD, self$state$maxvals)]
+      dt
+    }
+  )
+)
+
+
+# library("mlr3")
+#
+# # no group variable
+# task = tsk("iris")
+# task$col_roles
+# task$row_roles
+# gr = Graph$new()
+# gr$add_pipeop(PipeOpWinsorize$new(param_vals = list(probs_low = 0.2, probs_high = 0.8, na.rm = TRUE)))
+# result = gr$train(task)
+# result[[1]]$data()
+# predres = gr$predict(task)
+#
+# # group variable
+# dt = tsk("iris")$data()
+# dt[, monthid := c(rep(1, 50), rep(2, 50), rep(3, 50))]
+# task = as_task_classif(dt, target = "Species")
+# task$set_col_roles("monthid", "group")
+# gr = Graph$new()
+# gr$add_pipeop(PipeOpWinsorize$new(param_vals = list(probs_low = 0.2, probs_high = 0.8, na.rm = TRUE)))
+# result = gr$train(task)
+# result[[1]]$data()
+# predres = gr$predict(task)
diff --git a/mlr3ml.R b/mlr3ml.R
deleted file mode 100644
index 15d840f..0000000
--- a/mlr3ml.R
+++ /dev/null
@@ -1,474 +0,0 @@
-library(data.table)
-library(gausscov)
-library(paradox)
-library(mlr3)
-library(mlr3pipelines)
-
-
-
-# PREPARE DATA ------------------------------------------------------------
-# read predictors
-DT <- fread("D:/features/pead-predictors.csv")
-
-# create group variable
-DT[, monthid := paste0(data.table::year(as.Date(date, origin = "1970-01-01")),
-                       data.table::month(as.Date(date, origin = "1970-01-01")))]
-DT[, monthid := as.integer(monthid)]
-setorder(DT, monthid)
-
-# define predictors
-cols_non_features <- c("symbol", "date", "time", "right_time",
-                       "ret_excess_stand_5", "ret_excess_stand_22", "ret_excess_stand_44", "ret_excess_stand_66",
-                       colnames(DT)[grep("aroundzero", colnames(DT))],
-                       colnames(DT)[grep("extreme", colnames(DT))],
-                       colnames(DT)[grep("bin_simple", colnames(DT))],
-                       colnames(DT)[grep("bin_decile", colnames(DT))],
-                       "bmo_return", "amc_return",
-                       "open", "high", "low", "close", "volume", "returns",
-                       "monthid"
-                       # 'predictors' we don't need
-                       # colnames(DT)[grep("nperiods_\\d+", colnames(DT))],
-                       # colnames(DT)[grep("seasonal_period_\\d+", colnames(DT))]
-                       )
-cols_features <- setdiff(colnames(DT), c(cols_non_features))
-
-# convert columns to numeric. This is important only if we import existing features
-chr_to_num_cols <- setdiff(colnames(DT[, .SD, .SDcols = is.character]), c("symbol", "time", "right_time"))
-print(chr_to_num_cols)
-DT <- DT[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
-# int_to_num_cols <- colnames(DT[, .SD, .SDcols = is.integer])
-# DT <- DT[, (int_to_num_cols) := lapply(.SD, as.numeric), .SDcols = int_to_num_cols]
-
-# remove constant columns in set and remove same columns in test set
-features_ <- DT[, ..cols_features]
-remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
-print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
-cols_features <- setdiff(cols_features, remove_cols)
-
-# convert variables with low number of unique values to factors
-int_numbers = DT[, ..cols_features][, lapply(.SD, function(x) all(as.integer(x)==x) & x > 0.99)]
-int_cols = na.omit(colnames(DT[, ..cols_features])[as.matrix(int_numbers)[1,]])
-factor_cols = DT[, ..int_cols][, lapply(.SD, function(x) length(unique(x)))]
-factor_cols = as.matrix(factor_cols)[1, ]
-factor_cols = factor_cols[factor_cols <= 20]
-DT = DT[, (names(factor_cols)) := lapply(.SD, as.factor), .SD = names(factor_cols)]
-
-
-
-# TASKS -------------------------------------------------------------------
-# task with aroundzero bins
-target_ = colnames(DT)[grep("around.*22", colnames(DT))]
-cols_ = c(target_, "monthid", cols_features)
-tsk_aroundzero_month <- as_task_classif(DT[, ..cols_],
-                                        id = "aroundzero_month",
-                                        target = target_)
-
-# remove NA from target variable
-any(is.na(tsk_aroundzero_month$data()))
-target_na_ids = which(is.na(tsk_aroundzero_month$truth()))
-target_na_ids = setdiff(tsk_aroundzero_month$row_ids, target_na_ids)
-tsk_aroundzero_month$filter(target_na_ids)
-any(is.na(tsk_aroundzero_month$data()))
-dim(tsk_aroundzero_month$data())
-
-# create group and holdout set
-create_validation_set <- function(task, validation_month_start = 20226) {
-  # add group role
-  task$set_col_roles("monthid", "group")
-  groups = task$groups
-
-  # add validation set
-  val_ind <- min(which(groups$group == validation_month_start)):nrow(groups)
-  task$set_row_roles(rows = val_ind, role = "holdout")
-  task$set_col_roles("monthid", "feature")
-}
-create_validation_set(tsk_aroundzero_month)
-
-# create custom rolling window cross validation set
-custom = rsmp("custom")
-task_ <- tsk_aroundzero_month$clone()
-task_$set_col_roles("monthid", "group")
-groups = task_$groups
-rm(task_)
-groups_v <- groups[, unique(group)]
-train_length <- 24
-test_length <- 1
-train_groups <- lapply(0:(length(groups_v)-(train_length+1)), function(x) x + (1:train_length))
-test_groups <- lapply(train_groups, function(x) tail(x, 1) + test_length)
-train_sets <- lapply(train_groups, function(x) groups[group %in% groups_v[x], row_id])
-test_sets <- lapply(test_groups, function(x) groups[group %in% groups_v[x], row_id])
-custom$instantiate(tsk_aroundzero_month, train_sets[1], test_sets[1])
-
-# inspect task
-# tsk_aroundzero_month$backend$primary_key
-# tsk_aroundzero_month$col_info
-# tsk_aroundzero_month$col_roles
-# tsk_aroundzero_month$labels
-# tsk_aroundzero_month$label
-# tsk_aroundzero_month$row_names
-# tsk_aroundzero_month$
-
-
-# GRAPH -------------------------------------------------------------------
-# source pipes, filters and other
-source("mlr3_winsorization.R")
-source("mlr3_uniformization.R")
-source("mlr3_gausscov_f1st.R")
-source("mlr3_dropna.R")
-source("mlr3_dropnacol.R")
-source("mlr3_filter_drop_corr.R")
-source("mlr3_gausscov_f1st.R")
-
-# add my pipes to mlr dictionary
-mlr_pipeops$add("uniformization", PipeOpUniform)
-mlr_pipeops$add("winsorize", PipeOpWinsorize)
-mlr_pipeops$add("dropna", PipeOpDropNA)
-mlr_pipeops$add("dropnacol", PipeOpDropNACol)
-mlr_pipeops$add("dropcorr", PipeOpDropCorr)
-mlr_filters$add("gausscov_f1st", FilterGausscovF1st)
-
-# create graph
-# graph = po("select", id = "select_corr") %>>%
-#   po("winsorize", id = "winsorize", probs_low = 0.01, probs_high = 0.99, na.rm = TRUE)
-graph = po("dropnacol", id = "dropnacol", cutoff = 0.05) %>>%
-  po("dropna", id = "dropna") %>>%
-  po("removeconstants", id = "removeconstants_1", ratio = 0.01)  %>>%
-  po("winsorize", id = "winsorize", probs_low = 0.01, probs_high = 0.99, na.rm = TRUE) %>>%
-  po("removeconstants", id = "removeconstants_2", ratio = 0.01)  %>>%
-  po("dropcorr", id = "dropcorr", cutoff = 0.99) %>>%
-  po("uniformization") %>>%
-  po("pca", id = "pca") %>>%
-  po("dropna", id = "dropna_v2") %>>%
-  po("filter", filter = flt("gausscov_f1st"), filter.cutoff = 0) %>>%
-  po("learner", learner = lrn("classif.ranger"))
-
-100
-
-
-base:         ret = eps_diff + momentum + bs
-alternativni: ret = eps_diff + momentum + bs + sentimenti
-
-5, 5.1 , 5.2
-13, 14, 15
-
-
-search_space = ps(
-  # preprocesing
-  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
-  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
-  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
-  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson")
-)
-
-# train/test graph rolling CV
-graph$train(tsk_aroundzero_month)
-graph$predict(tsk_aroundzero_month)
-
-graph_learner = as_learner(graph)
-task_ = tsk_aroundzero_month$clone()
-task_$select(task_$feature_names[1:900]) # 946
-# task_$feature_names[947]
-# table(task_$data()[, "feasts_shift_var_index_66"])
-# table(task_$data(rows = custom$train_set(1))[, "feasts_shift_var_index_66"])
-# table(task_$data(rows = custom$test_set(1))[, "feasts_shift_var_index_66"])
-# for test
-# task_$filter(custom$test_set(1))
-# task_$feature_names[947]
-# table(task_$data()[, "feasts_shift_var_index_66"])
-rr = resample(task_, graph_learner, custom, store_models = FALSE)
-rr$aggregate(msr("classif.acc"))
-rr$warnings
-rr$resampling
-rr$prediction()
-rr$resampling
-
-# holdout prediction
-# rr_decile = resample(task_decile, graph_learner, custom, store_models = TRUE)
-
-
-
-
-
-
-
-
-
-graph = po("removeconstants", ratio = 0.01) %>>%
-  # modelmatrix
-  po("branch", options = c("nop_filter", "modelmatrix"), id = "interaction_branch") %>>%
-  gunion(list(po("nop", id = "nop_filter"), po("modelmatrix", formula = ~ . ^ 2))) %>>%
-  po("unbranch", id = "interaction_unbranch") %>>%
-  po("removeconstants", id = "removeconstants_2", ratio = 0.01) %>>%
-  # scaling
-  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
-  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
-  po("unbranch", id = "prep_unbranch") %>>%
-  learners%>>%
-  po("classifavg", innum = length(learners_l))
-plot(graph)
-
-
-
-task = mlr3::tsk("mtcars")
-task$data()
-filter = flt("find_correlation")
-filter$calculate(task)
-as.data.table(filter)
-
-
-
-
-
-
-
-
-
-# FEATURE SELECTION (TEST) ------------------------------------------------
-# select features
-test_ <- na.omit(unique(c(predictors_f3st_1)))
-# task_extreme$select(test_)
-task_aroundzero$select(test_)
-task_simple$select(test_)
-task_decile$select(test_)
-task_reg$select(test_)
-
-# rpart tree classificatoin function
-tree_visualization <- function(task_, maxdepth = 4, cp = 0.002) {
-  learner = lrn("classif.rpart", maxdepth = maxdepth,
-                predict_type = "prob", cp = cp)
-  learner$train(task_)
-  predictins = learner$predict(task_)
-  print(predictins$score(c(msr("classif.acc"), msr("classif.recall"), msr("classif.precision"), msr("classif.fbeta"))))
-  print(learner$importance())
-  rpart_model <- learner$model
-  rpart.plot(rpart_model)
-}
-tree_visualization(task_simple$clone(), cp = 0.001)
-tree_visualization(task_simple$clone(), cp = 0.0001)
-tree_visualization(task_simple$clone(), cp = 0.00001)
-
-# rpart tree regression
-learner = lrn("regr.rpart", maxdepth = 4, cp = 0.01)
-task_ <- task_reg$clone()
-learner$train(task_reg)
-predictins = learner$predict(task_reg)
-predictins$score(msr("regr.mae"))
-learner$importance()
-rpart_model <- learner$model
-rpart.plot(rpart_model)
-
-
-
-# CLASSIFICATION AUTOML ---------------------------------------------------
-# learners
-learners_l = list(
-  ranger = lrn("classif.ranger", predict_type = "prob", id = "ranger"),
-  # log_reg = lrn("classif.log_reg", predict_type = "prob", id = "log_reg"),
-  # kknn = lrn("classif.kknn", predict_type = "prob", id = "kknn"),
-  # cv_glmnet = lrn("classif.cv_glmnet", predict_type = "prob", id = "cv_glmnet"),
-  xgboost = lrn("classif.xgboost", predict_type = "prob", id = "xgboost")
-)
-# create graph from list of learners
-choices = c("ranger", "xgboost")
-learners = po("branch", choices, id = "branch_learners") %>>%
-  gunion(learners_l) %>>%
-  po("unbranch", choices, id = "unbranch_learners")
-
-# create complete grapg
-graph = po("removeconstants", ratio = 0.01) %>>%
-  # modelmatrix
-  po("branch", options = c("nop_filter", "modelmatrix"), id = "interaction_branch") %>>%
-  gunion(list(po("nop", id = "nop_filter"), po("modelmatrix", formula = ~ . ^ 2))) %>>%
-  po("unbranch", id = "interaction_unbranch") %>>%
-  po("removeconstants", id = "removeconstants_2", ratio = 0.01) %>>%
-  # scaling
-  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
-  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
-  po("unbranch", id = "prep_unbranch") %>>%
-  learners%>>%
-  po("classifavg", innum = length(learners_l))
-plot(graph)
-graph_learner = as_learner(graph)
-as.data.table(graph_learner$param_set)[1:70, .(id, class, lower, upper)]
-search_space = ps(
-  # preprocesing
-  interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
-  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
-  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
-  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
-  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
-  # models
-  ranger.ranger.mtry.ratio = p_dbl(0.2, 1),
-  ranger.ranger.max.depth = p_int(2, 4),
-  # kknn.kknn.k = p_int(5, 20),
-  xgboost.xgboost.nrounds = p_int(100, 5000),
-  xgboost.xgboost.eta = p_dbl(1e-4, 1),
-  xgboost.xgboost.max_depth = p_int(1, 8),
-  xgboost.xgboost.colsample_bytree = p_dbl(0.1, 1),
-  xgboost.xgboost.colsample_bylevel = p_dbl(0.1, 1),
-  xgboost.xgboost.lambda = p_dbl(0.1, 1),
-  xgboost.xgboost.gamma = p_dbl(1e-4, 1000),
-  xgboost.xgboost.alpha = p_dbl(1e-4, 1000),
-  xgboost.xgboost.subsample = p_dbl(0.1, 1)
-)
-# plan("multisession", workers = 4L)
-
-rr = resample(task_aroundzero, graph_learner, custom, store_models = TRUE)
-rr$aggregate(msr("classif.acc"))
-rr$warnings
-rr$resampling
-rr$prediction()
-
-# holdout prediction
-rr$
-
-  rr_decile = resample(task_decile, graph_learner, custom, store_models = TRUE)
-
-
-at_classif = auto_tuner(
-  method = "random_search",
-  learner = graph_learner,
-  resampling = custom,
-  measure = msr("classif.acc"),
-  search_space = search_space
-  # term_evals = 10
-)
-at_classif
-# at_classif$train(task_aroundzero)
-
-# inspect results
-at_classif$tuning_result
-at_classif$learner
-archive <- as.data.table(at_classif$archive)
-length(at_classif$state)
-ggplot(archive[, mean(classif.fbeta), by = "ranger.ranger.max.depth"], aes(x = ranger.ranger.max.depth, y = V1)) + geom_line()
-ggplot(archive[, mean(classif.fbeta), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
-ggplot(archive[, mean(classif.fbeta), by = "interaction_branch.selection"], aes(x = interaction_branch.selection, y = V1)) + geom_bar(stat = "identity")
-preds = at_classif$predict(task_extreme)
-preds$confusion
-preds$score(list(msr("classif.acc")))
-preds$score(list(msr("classif.fbeta"), msr("classif.acc")))
-
-# holdout extreme
-preds_holdout <- at_classif$predict(task_extreme_holdout)
-preds_holdout$confusion
-autoplot(preds_holdout, type = "roc")
-preds_holdout$score(msrs(c("classif.acc")))
-preds_holdout$score(msrs(c("classif.acc", "classif.recall", "classif.precision", "classif.fbeta")))
-prediciotns_extreme_holdout <- as.data.table(preds_holdout)
-prediciotns_extreme_holdout <- prediciotns_extreme_holdout[`prob.1` > 0.6]
-nrow(prediciotns_extreme_holdout)
-mlr3measures::acc(prediciotns_extreme_holdout$truth,
-                  prediciotns_extreme_holdout$response)
-prediciotns_extreme_holdout[, truth := as.factor(ifelse(truth == 0, 1, -1))]
-prediciotns_extreme_holdout$truth <- droplevels(prediciotns_extreme_holdout$truth)
-prediciotns_extreme_holdout$response <- droplevels(prediciotns_extreme_holdout$response)
-# levels(prediciotns_extreme_holdout$response) <- c("-1", "1")
-# mlr3measures::acc(prediciotns_extreme_holdout$truth,
-#                   prediciotns_extreme_holdout$response)
-
-# try extreme on bin simple
-X_model_sim <- copy(X_holdout)
-levels(X_model_sim$bin_simple_ret_excess_stand_5) <- c("-1", "1")
-X_model_sim <- X_model_sim[, .SD, .SDcols = !c("symbol","date", labels[!grepl("simple", labels)])]
-setnames(X_model_sim, "bin_simple_ret_excess_stand_5", "bin_extreme_ret_excess_stand_5")
-X_model_sim$bin_extreme_ret_excess_stand_5
-# summary(X_model_sim$eps_diff)
-# X_model_sim <- X_model_sim[eps_diff > .1 | eps_diff < -.1] # sample here !
-# dim(X_model_sim)
-task_simple_on_extreme <- as_task_classif(na.omit(X_model_sim), id = "simple_on_extreme",
-                                          target = labels[grep("extreme", labels)])
-task_simple_on_extreme$select(test_)
-preds_holdout <- at_classif$predict(task_simple_on_extreme)
-as.data.table(task_simple_on_extreme)
-preds_holdout$confusion
-autoplot(preds_holdout, type = "roc")
-preds_holdout$score(msrs(c("classif.acc", "classif.recall", "classif.precision", "classif.fbeta")))
-prediciotns_extreme_holdout <- as.data.table(preds_holdout)
-prediciotns_extreme_holdout <- prediciotns_extreme_holdout[prob.1 > 0.55]
-nrow(prediciotns_extreme_holdout)
-mlr3measures::acc(prediciotns_extreme_holdout$truth, prediciotns_extreme_holdout$response)
-
-
-task_simple_extreme_holdout
-
-# which variable correlate with extreme?
-cols_ <- c(colnames(X_model)[3:which(colnames(X_model) == "DCOILWTICO_ret_week")], "ret_excess_stand_5")
-test_ <- X_model[, ..cols_]
-dim(test_)
-test_[, 700:703]
-test_[, 1:3]
-# test_[, bin_extreme_ret_excess_stand_5 := as.integer(as.character(bin_extreme_ret_excess_stand_5))]
-# test_ <- test_[!is.na(bin_extreme_ret_excess_stand_5)]
-corr_bin <- cor(test_[, 1:702], test_$ret_excess_stand_5)
-class(corr_bin)
-head(corr_bin)
-head(corr_bin[order(corr_bin[, 1], decreasing = TRUE), , drop = FALSE])
-
-# predictions for qc
-cols_qc <- c("symbol", "date")
-predictoins_qc <- cbind(X_holdout[, ..cols_qc], as.data.table(preds_holdout))
-predictoins_qc[, grep("row_ids|truth", colnames(predictoins_qc)) := NULL]
-predictoins_qc <- unique(predictoins_qc)
-setorder(predictoins_qc, "date")
-
-# save to dropbox for live trading (create table for backtest)
-cols <- c("date", "symbol", colnames(predictoins_qc)[4:ncol(predictoins_qc)])
-pead_qc <- predictoins_qc[, ..cols]
-pead_qc[, date := as.character(date)]
-print(unique(pead_qc$symbol))
-pead_qc <- pead_qc[, .(symbol = paste0(unlist(symbol), collapse = ", "),
-                       prob1 = paste0(unlist(prob.1), collapse = ",")), by = date]
-bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
-cont <- storage_container(bl_endp_key, "qc-backtest")
-storage_write_csv2(pead_qc, cont, file = "hft.csv", col_names = FALSE)
-
-
-
-# TRAIN FINAL MODEL -------------------------------------------------------
-# train final model
-hft_mlr3_model <- at_classif$learner$train(task_extreme)
-
-# holdout extreme
-preds_holdout <- hft_mlr3_model$predict(task_aroundzero_holdout)
-preds_holdout$confusion
-autoplot(preds_holdout, type = "roc")
-preds_holdout$score(msrs(c("classif.acc", "classif.recall", "classif.precision", "classif.fbeta")))
-prediciotns_extreme_holdout <- as.data.table(preds_holdout)
-prediciotns_extreme_holdout <- prediciotns_extreme_holdout[`prob.1` > 0.60]
-nrow(prediciotns_extreme_holdout)
-mlr3measures::acc(prediciotns_extreme_holdout$truth,
-                  prediciotns_extreme_holdout$response)
-mlr3measures::acc(prediciotns_extreme_holdout$truth,
-                  prediciotns_extreme_holdout$response)
-
-
-# time_ <- format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
-# saveRDS(hft_mlr3_model,
-#         paste0("D:/mlfin/mlr3_models/hft_mlr3_model-", time_, ".rds"))
-# hft_mlr3_model
-#
-#
-# hftmlr_model = readRDS(file = "D:/mlfin/mlr3_models/hft_mlr3_model-20220830164033.rds")
-# saveRDS(hftmlr_model,
-#         paste0("D:/mlfin/mlr3_models/hftmlr_model.rds"))
-
-
-
-library(mlr3)
-library(mlr3pipelines)
-task = tsk("iris")
-pop = po("scalemaxabs")
-pop$train(list(task))[[1]]$data()
-
-library(mlr3)
-library(mlr3pipelines)
-task = tsk("iris")
-dt = task$data()
-dt[, month := c(rep(1, 50), rep(2, 50), rep(3, 50))]
-task = as_task_classif(dt, target = "Species", id = "iris")
-
-task$data()[, lapply(.SD, function(x) as.vector(scale(x))), .SDcols = names(DT)[2:5], by = month]
-
-pop = po("scalemaxabs")
-pop$train(list(task))[[1]]$data()
diff --git a/mlr3ml_v1.R b/mlr3ml_v1.R
new file mode 100644
index 0000000..3f853ee
--- /dev/null
+++ b/mlr3ml_v1.R
@@ -0,0 +1,424 @@
+library(data.table)
+library(gausscov)
+library(paradox)
+library(mlr3)
+library(mlr3pipelines)
+library(mlr3viz)
+library(mlr3tuning)
+library(mlr3mbo)
+library(mlr3misc)
+library(AzureStor)
+
+
+
+
+# SETUP -------------------------------------------------------------------
+# azure creds
+blob_key = "0M4WRlV0/1b6b3ZpFKJvevg4xbC/gaNBcdtVZW+zOZcRi0ZLfOm1v/j2FZ4v+o8lycJLu1wVE6HT+ASt0DdAPQ=="
+endpoint = "https://snpmarketdata.blob.core.windows.net/"
+BLOBENDPOINT = storage_endpoint(endpoint, key=blob_key)
+
+
+
+# PREPARE DATA ------------------------------------------------------------
+# read predictors
+DT <- fread("D:/features/pead-predictors.csv")
+
+# save to azure
+cont <- storage_container(BLOBENDPOINT, "test")
+cols_ = colnames(DT)[1:50]
+sample_ <- DT[, ..cols_]
+storage_write_csv(as.data.frame(sample_), cont, file = "mlr3test.csv", col_names = TRUE)
+
+# create group variable
+DT[, monthid := paste0(data.table::year(as.Date(date, origin = "1970-01-01")),
+                       data.table::month(as.Date(date, origin = "1970-01-01")))]
+DT[, monthid := as.integer(monthid)]
+setorder(DT, monthid)
+
+# define predictors
+cols_non_features <- c("symbol", "date", "time", "right_time",
+                       "bmo_return", "amc_return",
+                       "open", "high", "low", "close", "volume", "returns",
+                       "monthid"
+                       )
+targets <- c(colnames(DT)[grep("ret_excess", colnames(DT))])
+cols_features <- setdiff(colnames(DT), c(cols_non_features, targets))
+
+# convert columns to numeric. This is important only if we import existing features
+chr_to_num_cols <- setdiff(colnames(DT[, .SD, .SDcols = is.character]), c("symbol", "time", "right_time"))
+print(chr_to_num_cols)
+DT <- DT[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+
+# remove constant columns in set and remove same columns in test set
+features_ <- DT[, ..cols_features]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+cols_features <- setdiff(cols_features, remove_cols)
+
+# convert variables with low number of unique values to factors
+int_numbers = DT[, ..cols_features][, lapply(.SD, function(x) all(as.integer(x)==x) & x > 0.99)]
+int_cols = na.omit(colnames(DT[, ..cols_features])[as.matrix(int_numbers)[1,]])
+factor_cols = DT[, ..int_cols][, lapply(.SD, function(x) length(unique(x)))]
+factor_cols = as.matrix(factor_cols)[1, ]
+factor_cols = factor_cols[factor_cols <= 100]
+DT = DT[, (names(factor_cols)) := lapply(.SD, as.factor), .SD = names(factor_cols)]
+
+# remove observations with missing target
+# if we want to keep as much data as possible an use only one predicitn horizont
+# we can skeep this step
+DT = na.omit(DT, cols = setdiff(targets, colnames(DT)[grep("extreme", colnames(DT))]))
+
+# sort
+setorder(DT, date)
+
+
+
+# TASKS -------------------------------------------------------------------
+# task with aroundzero bins and weekly target
+target_ = colnames(DT)[grep("around.*5", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+task_aroundzero_week <- as_task_classif(DT[, ..cols_],
+                                        id = "aroundzero_week",
+                                        target = target_)
+
+# task with aroundzero binsa and month target
+target_ = targets[grep("around.*22", targets)]
+cols_ = c(target_, "monthid", cols_features)
+task_aroundzero_month <- as_task_classif(DT[, ..cols_],
+                                         id = "aroundzero_month",
+                                         target = target_)
+
+# task with aroundzero binsa and quarter target
+target_ = targets[grep("around.*66", targets)]
+cols_ = c(target_, "monthid", cols_features)
+task_aroundzero_quarter <- as_task_classif(DT[, ..cols_],
+                                           id = "aroundzero_quarter",
+                                           target = target_)
+
+### REGRESSION
+# task with future week returns as target
+target_ = colnames(DT)[grep("^ret_excess_stand_5", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+task_ret_week <- as_task_regr(DT[, ..cols_],
+                              id = "task_ret_week",
+                              target = target_)
+
+# task with future month returns as target
+target_ = colnames(DT)[grep("^ret_excess_stand_22", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+task_ret_month <- as_task_regr(DT[, ..cols_],
+                               id = "task_ret_month",
+                               target = target_)
+
+# task with future 2 months returns as target
+target_ = colnames(DT)[grep("^ret_excess_stand_44", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+task_ret_month2 <- as_task_regr(DT[, ..cols_],
+                                id = "task_ret_month2",
+                                target = target_)
+
+# task with future 2 months returns as target
+target_ = colnames(DT)[grep("^ret_excess_stand_66", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+task_ret_quarter <- as_task_regr(DT[, ..cols_],
+                                 id = "task_ret_quarter",
+                                 target = target_)
+
+
+# create group and holdout set
+# create_validation_set <- function(task, validation_month_start = 20226) {
+#   # add group role
+#   task$set_col_roles("monthid", "group")
+#   groups = task$groups
+#
+#   # add validation set
+#   val_ind <- min(which(groups$group == validation_month_start)):nrow(groups)
+#   task$set_row_roles(rows = val_ind, role = "holdout")
+#   task$set_col_roles("monthid", "feature")
+# }
+# create_validation_set(task_aroundzero_month)
+
+# inner custom rolling window resampling
+inner_split  <- function(task, train_length = 36, test_length = 2) {
+  custom = rsmp("custom")
+  task_ <- task$clone()
+  groups = cbind(id = 1:task_$nrow, task_$data(cols = "monthid"))
+  groups_v = groups[, unique(monthid)]
+  rm(task_)
+  train_groups <- lapply(1:(length(groups_v)-train_length-test_length), function(x) groups_v[x:(x+train_length)])
+  test_groups <- lapply(1:(length(groups_v)-train_length-test_length), function(x) groups_v[(x+train_length+1):(x+train_length+test_length)])
+  train_sets <- lapply(train_groups, function(mid) groups[monthid %in% mid, id])
+  test_sets <- lapply(test_groups, function(mid) groups[monthid %in% mid, id])
+  custom$instantiate(task, train_sets, test_sets)
+  return(custom)
+}
+customi = inner_split(task_aroundzero_month)
+
+# outer custom rolling window resampling
+outer_split <- function(task, train_length = 36, test_length = 2, test_length_out = 1) {
+  customo = rsmp("custom")
+  task_ <- task$clone()
+  groups = cbind(id = 1:task_$nrow, task_$data(cols = "monthid"))
+  groups_v = groups[, unique(monthid)]
+  rm(task_)
+  insample_length = train_length + test_length
+  train_groups_out <- lapply(1:(length(groups_v)-train_length-test_length), function(x) groups_v[x:(x+insample_length)])
+  test_groups_out <- lapply(1:(length(groups_v)-train_length-test_length),
+                             function(x) groups_v[(x+insample_length):(x+insample_length+test_length_out-1)])
+  train_sets_out <- lapply(train_groups_out, function(mid) groups[monthid %in% mid, id])
+  test_sets_out <- lapply(test_groups_out, function(mid) groups[monthid %in% mid, id])
+  customo$instantiate(task, train_sets_out, test_sets_out)
+}
+customo = outer_split(task_aroundzero_month)
+
+# custom checks
+(tail(customi$train_set(1), 1) + 1) == customi$test_set(1)[1] # test set start after train set 1
+(tail(customi$train_set(2), 1) + 1) == customi$test_set(2)[1] # test set start after train set 2
+all(c(customi$train_set(1), customi$test_set(1)) == customo$train_set(1)) # train set in outersample contains ids in innersample 1
+all(c(customi$train_set(2), customi$test_set(2)) == customo$train_set(2)) # train set in outersample contains ids in innersample 1
+
+
+
+# ADD PIPELINES -----------------------------------------------------------
+# source pipes, filters and other
+source("mlr3_winsorization.R")
+source("mlr3_uniformization.R")
+source("mlr3_gausscov_f1st.R")
+source("mlr3_dropna.R")
+source("mlr3_dropnacol.R")
+source("mlr3_filter_drop_corr.R")
+source("mlr3_winsorizationsimple.R")
+source("Linex.R")
+
+# add my pipes to mlr dictionary
+mlr_pipeops$add("uniformization", PipeOpUniform)
+mlr_pipeops$add("winsorize", PipeOpWinsorize)
+mlr_pipeops$add("winsorizesimple", PipeOpWinsorizeSimple)
+mlr_pipeops$add("dropna", PipeOpDropNA)
+mlr_pipeops$add("dropnacol", PipeOpDropNACol)
+mlr_pipeops$add("dropcorr", PipeOpDropCorr)
+mlr_filters$add("gausscov_f1st", FilterGausscovF1st)
+mlr_measures$add("linex", Linex)
+
+
+
+# GRAPH -------------------------------------------------------------------
+# learners
+# learners_l = list(
+#   ranger = lrn("classif.ranger", predict_type = "prob", id = "ranger"),
+#   log_reg = lrn("classif.log_reg", predict_type = "prob", id = "log_reg"),
+#   kknn = lrn("classif.kknn", predict_type = "prob", id = "kknn"),
+#   # cv_glmnet = lrn("classif.cv_glmnet", predict_type = "prob", id = "cv_glmnet"),
+#   xgboost = lrn("classif.xgboost", predict_type = "prob", id = "xgboost")
+# )
+learners_l = list(
+  ranger = lrn("regr.ranger", id = "ranger"),
+  lm = lrn("regr.lm", id = "lm"),
+  kknn = lrn("regr.kknn", id = "kknn"),
+  # cv_glmnet = lrn("classif.cv_glmnet", predict_type = "prob", id = "cv_glmnet"),
+  xgboost = lrn("regr.xgboost", id = "xgboost")
+)
+
+# create graph from list of learners
+choices = c("ranger", "lm", "kknn", "xgboost")
+learners = po("branch", choices, id = "branch_learners") %>>%
+  gunion(learners_l) %>>%
+  po("unbranch", choices, id = "unbranch_learners")
+
+# create graph
+graph = po("dropnacol", id = "dropnacol", cutoff = 0.05) %>>%
+  po("dropna", id = "dropna") %>>%
+  po("removeconstants", id = "removeconstants_1", ratio = 0)  %>>%
+  po("winsorizesimple", id = "winsorizesimple", probs_low = 0.01, probs_high = 0.99, na.rm = TRUE) %>>%
+  po("removeconstants", id = "removeconstants_2", ratio = 0)  %>>%
+  po("dropcorr", id = "dropcorr", cutoff = 0.99) %>>%
+  po("uniformization") %>>%
+  po("dropna", id = "dropna_v2") %>>%
+  po("filter", filter = flt("gausscov_f1st"), filter.cutoff = 0) %>>%  # filter important predictors
+  # modelmatrix
+  po("branch", options = c("nop_filter", "modelmatrix"), id = "interaction_branch") %>>%
+  gunion(list(po("nop", id = "nop_filter"), po("modelmatrix", formula = ~ . ^ 2))) %>>%
+  po("unbranch", id = "interaction_unbranch") %>>%
+  po("removeconstants", id = "removeconstants_3", ratio = 0) %>>%
+  # learners
+  learners %>>%
+  po("regravg", innum = length(learners_l))
+plot(graph)
+graph_learner = as_learner(graph)
+
+# define search space
+as.data.table(graph_learner$param_set)[1:100, .(id, class, lower, upper)]
+as.data.table(graph_learner$param_set)[grep("drop", id), .(id, class, lower, upper)]
+search_space = ps(
+  # preprocessing
+  dropcorr.cutoff = p_fct(levels = c("0.90", "0.99"), trafo = function(x, param_set) {
+    switch(x,
+           "0.90" = 0.90,
+           "0.99" = 0.99
+    )
+  }),
+  interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  # winsorizesimple.probs_high = p_fct(levels = c("0.99", "0.98", "0.97", "0.90")),
+  winsorizesimple.probs_high = p_fct(levels = c(0.99, 0.98, 0.97, 0.90)),
+  # winsorizesimple.probs_low = p_dbl(lower = 0, upper = 1, ),
+  # winsorizesimple.probs_low = p_fct(levels = c("0.01", "0.02", "0.03", "0.1")),
+  winsorizesimple.probs_low = p_fct(levels = c(0.01, 0.02, 0.03, 0.1)),
+  # ranger
+  ranger.ranger.max.depth = p_fct(levels = c(2L, 10L)),
+  ranger.ranger.splitrule = p_fct(levels = c("variance", "extratrees")),
+  ranger.ranger.mtry.ratio = p_dbl(0.5, 1),
+  # kknn
+  kknn.kknn.k = p_int(1, 10)
+  # extra transformations
+  # .extra_trafo = function(x, param_set) {
+  #   x$winsorizesimple.probs_high = switch(
+  #     x$winsorizesimple.probs_high,
+  #     "0.99" = 0.99,
+  #     "0.98" = 0.98,
+  #     "0.97" = 0.97
+  #   )
+  #   x$winsorizesimple.probs_low = 1 - as.numeric(x$winsorizesimple.probs_high)
+  #   x
+  # }
+)
+
+# inspect search space
+design = rbindlist(generate_design_grid(search_space, 3)$transpose(), fill = TRUE)
+design
+
+
+
+
+# BAYES OPT ---------------------------------------------------------------
+# Gaussian Process, EI, FocusSearch
+# surrogate = srlrn(lrn("regr.km",
+#                       covtype = "matern3_2",
+#                       optim.method = "gen",
+#                       nugget.estim = TRUE,
+#                       jitter = 1e-12,
+#                       control = list(trace = FALSE)))
+# acq_function = acqf("ei")
+# acq_optimizer = acqo(opt("focus_search", n_points = 100L, maxit = 9),
+#                      terminator = trm("evals", n_evals = 2000))
+# tuner = tnr("mbo",
+#             loop_function = bayesopt_ego,
+#             surrogate = surrogate,
+#             acq_function = acq_function,
+#             acq_optimizer = acq_optimizer)
+
+
+
+# NESTED CV BENCHMARK -----------------------------------------------------
+# nested for loop
+future::plan("multisession", workers = 4L)
+bmrs = list()
+for (i in seq_len(customi$iters)) { # seq_len(custom$iters)
+
+  # debug
+  # i = 1
+  print(i)
+
+  # inner resampling
+  custom_ = rsmp("custom")
+  custom_$instantiate(task_aroundzero_month, list(customi$train_set(i)), list(customi$test_set(i)))
+
+  # auto tuner
+  at = auto_tuner(
+    method = "mbo", # tnr("random_search", batch_size = 3),
+    learner = graph_learner,
+    resampling = custom_,
+    measure = msr("linex"),
+    search_space = search_space,
+    term_evals = 5
+  )
+
+  # outer resampling
+  customo_ = rsmp("custom")
+  customo_$instantiate(task_aroundzero_month, list(customo$train_set(i)), list(customo$test_set(i)))
+
+  # nested CV for one round
+  design = benchmark_grid(
+    tasks = list(task_ret_week, task_ret_month, task_ret_month2, task_ret_quarter),
+    learners = at,
+    resamplings = customo_
+  )
+  bmr = benchmark(design, store_models = TRUE)
+  bmrs[[i]] = bmr
+}
+
+# inspect single benchmark
+bmr_ = bmrs[[2]]
+bmr_$aggregate(msrs(c("regr.mse", "linex", "regr.mae")))
+predicitons = as.data.table(as.data.table(bmr_)[, "prediction"][1][[1]][[1]])
+predicitons[, `:=`(
+  truth_sign = as.factor(sign(truth)),
+  response_sign = as.factor(sign(response))
+)]
+mlr3measures::acc(predicitons$truth_sign, predicitons$response_sign)
+predicitons_sample = predicitons[response > 0.5]
+mlr3measures::acc(predicitons_sample$truth_sign, predicitons_sample$response_sign)
+predicitons_sample[, .(
+  benchmark = mean(predicitons$truth),
+  strategy  = mean(truth)
+)]
+
+# important predictors
+resample_res = as.data.table(bmr_$resample_result(1))
+resample_res$learner[[1]]$state$model$learner$state$model$gausscov_f1st
+
+
+bmr$learners$learner[[1]]
+bmr$learners$learner[[1]]$archive
+test = bmr$resample_result(1)
+test = as.data.table(test)
+test$learner[[1]]$archive
+test$learner[[1]]$tuning_instance$result
+
+
+# # V1 -----------------------------------------------------------------------
+# # tuning instance
+# instance = ti(
+#   task = task_aroundzero_month,
+#   learner = graph_learner,
+#   resampling = custom,
+#   measures = msr("classif.acc"),
+#   terminator = trm("none"),
+#   search_space = search_space
+# )
+#
+# # tuner
+# tuner = tnr("grid_search", batch_size = 4)
+# tuner$optimize(instance)
+#
+# # check results
+# instance$result
+# instance$archive
+# as.data.table(instance$archive)[, resample_result]
+# # first parameter
+# x = as.data.table(instance$archive)[, resample_result][[1]]
+# as.data.table(instance$archive)[, resample_result][[1]]$score()
+# x$learner$param_set$values
+# task_ = task_aroundzero_month$clone()
+# x$learner$predict(task_$filter(rows = customo$test_set(1)))
+# # second parameter
+# x = as.data.table(instance$archive)[, resample_result][[2]]
+# as.data.table(instance$archive)[, resample_result][[2]]$score()
+# x$learner$param_set$values
+# x$learner$predict()
+#
+# # evaluate models on test set
+# instance$archive
+# as.data.table(instance$archive)[, resample_result][[1]]$score()
+# graph_learner_clone = graph_learner$clone()
+# graph_learner_clone$param_set$values = instance$result_learner_param_vals
+# task_train = task_aroundzero_month$clone()
+# task_train$filter(rows = c(custom$train_set(1), custom$test_set(1)))
+# graph_learner_clone$train(task_train)
+# task_test = task_aroundzero_month$clone()
+# task_test$filter(rows = customo$test_set(1))
+# predictions = graph_learner_clone$predict(task_test)
+# predictions$confusion
+# predictions$score(msr("classif.acc"))
+#
+#
diff --git a/qa.R b/qa.R
new file mode 100644
index 0000000..f716ba8
--- /dev/null
+++ b/qa.R
@@ -0,0 +1,116 @@
+library(mlr3)
+library(mlr3tuning)
+library(mlr3pipelines)
+library(mlr3learners)
+
+
+# task
+task  = tsk("iris")
+task_ = task$clone()
+data_ = task_$data()
+data_ = cbind(data_, monthid = c(rep(1, 30), rep(2, 30), rep(3, 30), rep(4, 30), rep(5, 30)))
+task = as_task_classif(data_, target = "Species")
+
+# inner custom rolling window resampling
+custom_inner <- function(task, train_length = 2, test_length = 1) {
+  custom = rsmp("custom")
+  task_ <- task$clone()
+  task_$set_col_roles("monthid", "group")
+  groups = task_$groups
+  rm(task_)
+  groups_v <- groups[, unique(group)]
+  train_groups <- lapply(0:(length(groups_v)-(train_length+1)), function(x) x + (1:train_length))
+  test_groups <- lapply(train_groups, function(x) tail(x, 1) + test_length)
+  train_sets <- lapply(train_groups, function(x) groups[group %in% groups_v[x], row_id])
+  test_sets <- lapply(test_groups, function(x) groups[group %in% groups_v[x], row_id])
+  custom$instantiate(task, train_sets, test_sets)
+  return(custom)
+}
+customi = custom_inner(task)
+customi$train_set(1)
+customi$test_set(1)
+customi$train_set(2)
+customi$test_set(2)
+customi$train_set(3)
+customi$test_set(3)
+
+# outer custom rolling window resampling
+custom_outer <- function(task, train_length = 2, test_length = 1, test_length_out = 1) {
+  customo = rsmp("custom")
+  task_ <- task$clone()
+  task_$set_col_roles("monthid", "group")
+  groups = task_$groups
+  rm(task_)
+  groups_v <- groups[, unique(group)]
+  train_length_out <- train_length + test_length
+  test_length_out <- 1
+  train_groups_out <- lapply(0:(length(groups_v)-(train_length_out+1)), function(x) x + (1:train_length_out))
+  test_groups_out <- lapply(train_groups_out, function(x) tail(x, 1) + test_length_out)
+  train_sets_out <- lapply(train_groups_out, function(x) groups[group %in% groups_v[x], row_id])
+  test_sets_out <- lapply(test_groups_out, function(x) groups[group %in% groups_v[x], row_id])
+  customo$instantiate(task, train_sets_out, test_sets_out)
+}
+customo = custom_outer(task)
+customo$train_set(1)
+customo$test_set(1)
+customo$train_set(2)
+customo$test_set(2)
+tryCatch(customo$train_set(3), error = function(e) NULL)  # don't have data for test set
+tryCatch(customo$test_set(3), error = function(e) NULL)   # don't have data for test set
+
+# costruct graph
+graph = po("removeconstants", id = "removeconstants_1", ratio = 0)  %>>%
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  po("learner", learner = lrn("classif.rpart"))
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:70, .(id, class, lower, upper)]
+search_space = ps(
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 3, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 3, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson")
+)
+
+
+bmrs = list()
+for (i in seq_len(customi$iters)) { # seq_len(custom$iters)
+
+  # debug
+  # i = 1
+  print(i)
+
+  # stop if last fold (we don't have outofsample data)
+  if (i == customi$iters) {
+    break
+  }
+
+  # inner resampling
+  custom_ = rsmp("custom")
+  custom_$instantiate(task, list(customi$train_set(i)), list(customi$test_set(i)))
+
+  # auto tuner
+  at = auto_tuner(
+    method = tnr("grid_search", batch_size = 2),
+    learner = graph_learner,
+    resampling = custom_,
+    measure = msr("classif.acc"),
+    search_space = search_space,
+    term_evals = 2
+  )
+
+  # outer resampling
+  customo_ = rsmp("custom")
+  customo_$instantiate(task, list(customo$train_set(i)), list(customo$test_set(i)))
+
+  # nested CV for one round
+  design = benchmark_grid(
+    tasks = list(task),
+    learners = at,
+    resamplings = customo_
+  )
+  bmr = benchmark(design, store_models = TRUE)
+  bmrs[[i]] = bmr
+}
diff --git a/regr_linex.R b/regr_linex.R
new file mode 100644
index 0000000..0c06023
--- /dev/null
+++ b/regr_linex.R
@@ -0,0 +1,23 @@
+#' @title Linear-exponential Loss
+#'
+#' @details
+#' Linear-exponential, or Linex, loss takes the form \deqn{
+#'   L(e)  =  a{1}(exp(a a{2}e)−a{2}e −1).
+#' }
+#'
+#' @templateVar mid linex
+#' @template regr_template
+#'
+#' @inheritParams regr_params
+#' @template regr_example
+#' @export
+linex = function(truth, response, a1 = 1, a2 = -1) {
+  mlr3measures:::assert_regr(truth, response = response)
+  if (a2 == 0) stop("Argument a2 can't be 0.")
+  if (a1 <= 0) stop("Argument a1 must be greater than 0.")
+  e = truth - response
+  a1 * (exp(-a2*e) - a2*e - 1)
+}
+
+#' @include measures.R
+mlr3measures:::add_measure(linex, "Linear-exponential Loss", "regr", 0, Inf, TRUE)

commit 3464e2e631b7d240d9b7c030cc3c37e8c871ade2
Author: unknown <mislav.sagovac@contentio.biz>
Date:   Mon Feb 13 11:55:11 2023 +0100

    new versiion

diff --git a/.Renviron b/.Renviron
new file mode 100644
index 0000000..5c53424
--- /dev/null
+++ b/.Renviron
@@ -0,0 +1,7 @@
+APIKEY-FMPCLOUD=15cd5d0adf4bc6805a724b4417bbaafc
+BLOB-ENDPOINT=https://contentiobatch.blob.core.windows.net/
+BLOB-KEY=qdTsMJMGbnbQ5rK1mG/9R1fzfRnejKNIuOv3X3PzxoBqc1wwTxMyUuxNVSxNxEasCotuzHxwXECo79BLv71rPw==
+FRED-KEY=fb7e8cbac4b84762980f507906176c3c
+AWS-ACCESS-KEY=AKIA43AHCLIIM6XWLNLJ
+AWS-SECRET-KEY=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
+AWS-REGION=eu-central-1
diff --git a/mlr3_dropna.R b/mlr3_dropna.R
new file mode 100644
index 0000000..3482f29
--- /dev/null
+++ b/mlr3_dropna.R
@@ -0,0 +1,40 @@
+library(mlr3pipelines)
+library(mlr3verse)
+library(mlr3misc)
+library(R6)
+
+PipeOpDropNA = R6::R6Class(
+  "PipeOpDropNA",
+  inherit = mlr3pipelines::PipeOpTaskPreproc,
+  public = list(
+    initialize = function(id = "drop.na") {
+      super$initialize(id)
+    }
+  ),
+
+  private = list(
+    .train_task = function(task) {
+      self$state = list()
+      featuredata = task$data(cols = task$feature_names)
+      exclude = apply(is.na(featuredata), 1, any)
+      task$filter(task$row_ids[!exclude])
+    },
+
+    .predict_task = function(task) {
+      # nothing to be done
+      task
+    }
+  )
+)
+
+# no group variable
+task = tsk("iris")
+new_dt = data.table("setosa", 1,2, 3, NA)
+setnames(new_dt, names(task$data()))
+task$rbind(new_dt)
+task$data()
+gr = Graph$new()
+gr$add_pipeop(PipeOpDropNA$new())
+result = gr$train(task)
+result[[1]]$data()
+gr$predict(task)
diff --git a/mlr3_dropnacol.R b/mlr3_dropnacol.R
new file mode 100644
index 0000000..1b88367
--- /dev/null
+++ b/mlr3_dropnacol.R
@@ -0,0 +1,44 @@
+library(mlr3pipelines)
+library(mlr3verse)
+library(mlr3misc)
+library(R6)
+
+PipeOpDropNACol = R6::R6Class(
+  "PipeOpDropNACol",
+  inherit = mlr3pipelines::PipeOpTaskPreprocSimple,
+  public = list(
+    initialize = function(id = "drop.nacol", param_vals = list()) {
+      ps = ParamSet$new(list(
+        ParamDbl$new("cutoff", lower = 0, upper = 1, default = 0.05, tags = c("dropnacol_tag"))
+      ))
+      ps$values = list(cutoff = 0.2)
+      super$initialize(id, param_set = ps, param_vals = param_vals)
+    }
+  ),
+
+  private = list(
+    .get_state = function(task) {
+      pv = self$param_set$get_values(tags = "dropnacol_tag")
+      features_names = task$feature_names
+      data = task$data(cols = features_names)
+      keep = sapply(data, function(column) (sum(is.na(column))) / length(column) < pv$cutoff)
+      list(cnames = colnames(data)[keep])
+    },
+
+    .transform = function(task) {
+      task$select(self$state$cnames)
+    }
+  )
+)
+
+# # no group variable
+# task = tsk("iris")
+# dt = task$data()
+# dt[1:50, Sepal.Width := NA]
+# task = as_task_classif(dt, target = "Species")
+#
+# gr = Graph$new()
+# gr$add_pipeop(PipeOpDropNACol$new())
+# result = gr$train(task)
+# result[[1]]$data()
+# gr$predict(task)
diff --git a/mlr3_filter_drop_corr.R b/mlr3_filter_drop_corr.R
new file mode 100644
index 0000000..ccfedc6
--- /dev/null
+++ b/mlr3_filter_drop_corr.R
@@ -0,0 +1,56 @@
+library(mlr3)
+library(paradox)
+library(mlr3filters)
+library(mlr3pipelines)
+
+
+PipeOpDropCorr = R6::R6Class(
+  "PipeOpDropCorr",
+  inherit = mlr3pipelines::PipeOpTaskPreprocSimple,
+  public = list(
+    initialize = function(id = "drop.const", param_vals = list()) {
+      ps = ParamSet$new(list(
+        ParamFct$new("use", c("everything", "all.obs", "complete.obs", "na.or.complete", "pairwise.complete.obs"), default = "everything"),
+        ParamFct$new("method", c("pearson", "kendall", "spearman"), default = "pearson"),
+        ParamDbl$new("cutoff", lower = 0, upper = 1, default = 0.99)
+      ))
+      ps$values = list(use = "everything", method = "pearson", cutoff = 0.99)
+      super$initialize(id = id, param_set = ps, param_vals = param_vals, feature_types = c("numeric"))
+    }
+  ),
+
+  private = list(
+    .get_state = function(task) {
+      # debug
+      # pv = list(
+      #   use = "everything",
+      #   method = "pearson",
+      #   cutoff = 0.9
+      # )
+
+      fn = task$feature_types[type == self$feature_types, id]
+      data = task$data(cols = fn)
+      pv = self$param_set$values
+
+      cm = invoke(stats::cor, x = data, use = pv$use, method = pv$method)
+      cm[upper.tri(cm)] <- 0
+      diag(cm) <- 0
+      cm <- abs(cm)
+      remove_cols <- colnames(data)[apply(cm, 2, function(x) any(x > pv$cutoff))]
+      keep_cols <- setdiff(fn, remove_cols)
+      list(cnames = keep_cols)
+    },
+
+    .transform = function(task) {
+      task$select(self$state$cnames)
+    }
+  )
+)
+
+# # no group variable
+# task = tsk("iris")
+# gr = Graph$new()
+# gr$add_pipeop(PipeOpDropCorr$new(param_vals = list(cutoff = 0.9)))
+# result = gr$train(task)
+# result[[1]]$data()
+# predres = gr$predict(task)
diff --git a/mlr3_gausscov_f1st.R b/mlr3_gausscov_f1st.R
new file mode 100644
index 0000000..720ae14
--- /dev/null
+++ b/mlr3_gausscov_f1st.R
@@ -0,0 +1,104 @@
+library(gausscov)
+library(paradox)
+library(mlr3)
+library(mlr3misc)
+library(mlr3filters)
+library(checkmate)
+library(R6)
+library(backports)
+
+
+
+FilterGausscovF1st = R6::R6Class(
+  "FilterGausscovF1st",
+  inherit = mlr3filters::Filter,
+
+  public = list(
+
+    #' @description Create a GaussCov object.
+    initialize = function() {
+      param_set = ps(
+        p0   = p_dbl(lower = 0, upper = 1, default = 0.01),
+        kmn  = p_int(lower = 0, default = 0),
+        kmx  = p_int(lower = 0, default = 0),
+        mx   = p_int(lower = 1, default = 21),
+        kex  = p_int(lower = 0, default = 0),
+        sub  = p_lgl(default = TRUE),
+        inr  = p_lgl(default = TRUE),
+        xinr = p_lgl(default = FALSE),
+        qq   = p_int(lower = 0, default = 0)
+      )
+
+      super$initialize(
+        id = "gausscov_f1st",
+        task_types = c("classif", "regr"),
+        param_set = param_set,
+        feature_types = c("integer", "numeric"),
+        packages = "gausscov",
+        label = "Gauss Covariance f1st",
+        man = "mlr3filters::mlr_filters_gausscov_f1st"
+      )
+    }
+  ),
+
+  private = list(
+    .calculate = function(task, nfeat) {
+      # debug
+      # pv = list(
+      #   p0   = 0.01,
+      #   kmn  = 0,
+      #   kmx  = 0,
+      #   mx   = 21,
+      #   kex  = 0,
+      #   sub  = TRUE,
+      #   inr  = TRUE,
+      #   xinr = FALSE,
+      #   qq   = 0
+      # )
+
+      # empty vector with variable names as vector names
+      scores = rep(-1, length(task$feature_names))
+      scores = set_names(scores, task$feature_names)
+
+      # calculate gausscov pvalues
+      pv = self$param_set$values
+      print(pv)
+      x = as.matrix(task$data(cols = task$feature_names))
+      if (task$task_type == "classif") {
+        y = as.matrix(as.integer(task$truth()))
+      } else {
+        y = as.matrix(task$truth())
+      }
+      res = invoke(gausscov::f1st, y = y, x = x, .args = pv)
+      res_1 = res[[1]]
+      print(res_1)
+      res_1 = res_1[res_1[, 1] != 0, , drop = FALSE]
+      scores[res_1[, 1]] = abs(res_1[, 4])
+      sort(scores, decreasing = TRUE)
+    }
+  )
+)
+
+mlr_filters$add("gausscov_f1st", FilterGausscovF1st)
+
+# # no group variable
+# task = tsk("iris")
+# # task = tsk("mtcars")
+# task$data()
+# task$target_names
+# filter = flt("gausscov_f1st")
+# filter$param_set
+# filter$calculate(task)
+# as.data.table(filter)
+# task$data()$Species
+# as.numeric(task$data()$Species)
+#
+# # graph
+# graph = po("filter", filter = flt("gausscov_f1st"), filter.cutoff = 0) %>>%
+#   po("learner", lrn("classif.rpart"))
+# learner = as_learner(graph)
+# learner$param_set
+# result = learner$train(task)
+# result$model$gausscov_f1st
+# learner$predict(task)
+
diff --git a/mlr3_uniformization.R b/mlr3_uniformization.R
new file mode 100644
index 0000000..b49bdd7
--- /dev/null
+++ b/mlr3_uniformization.R
@@ -0,0 +1,72 @@
+library(mlr3pipelines)
+library(mlr3verse)
+library(mlr3misc)
+library(R6)
+
+PipeOpUniform = R6::R6Class(
+  "PipeOpUniform",
+  inherit = mlr3pipelines::PipeOpTaskPreproc,
+  public = list(
+    groups = NULL,
+    initialize = function(id = "uniformization", param_vals = list()) {
+      super$initialize(id, param_vals = param_vals, feature_types = c("numeric", "integer"))
+    }
+  ),
+
+  private = list(
+
+    .select_cols = function(task) {
+      self$groups = task$groups
+      task$feature_names
+    },
+
+    .train_dt = function(dt, levels, target) {
+      # state variables
+      if (!(is.null(self$groups))) {
+        row_ids  = self$groups[group == self$groups[nrow(self$groups), group], row_id]
+        ecdf_ = map(dt[row_ids], ecdf)
+      } else {
+        ecdf_ = map(dt, ecdf)
+      }
+      self$state = list(
+        ecdf_ = ecdf_
+      )
+
+      # dt object train
+      if (!(is.null(self$groups))) {
+        dt = dt[, lapply(.SD, function(x) as.vector(ecdf(x)(x))), by = self$groups[, group]]
+        dt = dt[, -1]
+      } else {
+        dt = dt[, lapply(.SD, function(x) ecdf(x)(x))]
+      }
+      dt
+    },
+
+    .predict_dt = function(dt, levels) {
+      dt[, Map(function(a, b) b(a), .SD, self$state$ecdf_)]
+    }
+  )
+)
+
+
+library("mlr3")
+
+# no group variable
+task = tsk("iris")
+gr = Graph$new()
+gr$add_pipeop(PipeOpUniform$new())
+result = gr$train(task)
+result[[1]]$data()
+gr$predict(task)
+
+# group variable
+dt = tsk("iris")$data()
+dt[, monthid := c(rep(1, 50), rep(2, 50), rep(3, 50))]
+task = as_task_classif(dt, target = "Species")
+task$set_col_roles("monthid", "group")
+gr = Graph$new()
+gr$add_pipeop(PipeOpUniform$new())
+result = gr$train(task)
+result[[1]]$data()
+preds = gr$predict(task)
+preds$uniformization.output$data()
diff --git a/mlr3_winsorization.R b/mlr3_winsorization.R
new file mode 100644
index 0000000..6bd5859
--- /dev/null
+++ b/mlr3_winsorization.R
@@ -0,0 +1,117 @@
+library(mlr3pipelines)
+library(mlr3verse)
+library(mlr3misc)
+library(R6)
+library(paradox)
+
+PipeOpWinsorize = R6::R6Class(
+  "PipeOpWinsorize",
+  inherit = mlr3pipelines::PipeOpTaskPreproc,
+  public = list(
+    groups = NULL,
+    initialize = function(id = "winsorization", param_vals = list()) {
+      ps = ParamSet$new(list(
+        ParamDbl$new("probs_low", lower = 0, upper = 1, default = 0.05, tags = c("winsorize_tag")),
+        ParamDbl$new("probs_high", lower = 0, upper = 1, default = 0.95, tags = c("winsorize_tag")),
+        ParamLgl$new("na.rm", default = TRUE, tags = c("winsorize_tag")),
+        ParamInt$new("qtype", lower = 1L, upper = 9L, default = 7L, tags = c("winsorize_tag"))
+      ))
+      ps$values = list(qtype = 7L)
+      super$initialize(id, param_set = ps, param_vals = param_vals, feature_types = c("numeric", "integer"))
+    }
+  ),
+
+  private = list(
+
+    # .select_cols = function(task) {
+    #   self$groups = task$groups
+    #   cols = task$feature_types[type %in% self$feature_types, id]
+    #   cols[cols %in% task$feature_names]
+    # },
+
+    .train_dt = function(dt, levels, target) {
+      # debug
+      # task = copy(tsk_aroundzero_month)
+      # dt = tsk_aroundzero_month$data()
+      # cols = tsk_aroundzero_month$feature_types[type %in% c("numeric", "integer"), id]
+      # dt = dt[, ..cols]
+      # pv = list(
+      #   probs_low = 0.01, probs_high = 0.99, na.rm = TRUE, qtype = 7
+      # )
+      # self = list()
+
+      # params
+      pv = self$param_set$get_values(tags = "winsorize_tag")
+
+      # state variables
+      # if (!(is.null(self$groups))) {
+      #   row_ids  = self$groups[group == self$groups[nrow(self$groups), group], row_id]
+      #   q = dt[row_ids, lapply(.SD,
+      #                          quantile,
+      #                          probs = c(pv$probs_low, pv$probs_high),
+      #                          na.rm = pv$na.rm,
+      #                          type = pv$qtype)]
+      # } else {
+      q = dt[, lapply(.SD,
+                      quantile,
+                      probs = c(pv$probs_low, pv$probs_high),
+                      na.rm = pv$na.rm,
+                      type = pv$qtype)]
+      # }
+      self$state = list(
+        minvals = q[1],
+        maxvals = q[2]
+      )
+
+      # dt object train
+      # if (!(is.null(self$groups))) {
+      #   dt = dt[, lapply(.SD, function(x){
+      #     q = quantile(x,
+      #                  probs = c(pv$probs_low, pv$probs_high),
+      #                  na.rm = pv$na.rm,
+      #                  type = pv$qtype)
+      #     minval = q[1L]
+      #     maxval = q[2L]
+      #     x[x < minval] <- minval
+      #     x[x > maxval] <- maxval
+      #     x
+      #   }), by = self$groups[, group]]
+      #   dt = dt[, -1]
+      # } else {
+      dt = dt[, Map(function(a, b) ifelse(a < b, b, a), .SD, self$state$minvals)]
+      dt = dt[, Map(function(a, b) ifelse(a > b, b, a), .SD, self$state$maxvals)]
+      # }
+      dt
+    },
+
+    .predict_dt  = function(dt, levels) {
+      dt = dt[, Map(function(a, b) ifelse(a < b, b, a), .SD, self$state$minvals)]
+      dt = dt[, Map(function(a, b) ifelse(a > b, b, a), .SD, self$state$maxvals)]
+      dt
+    }
+  )
+)
+
+
+# library("mlr3")
+#
+# # no group variable
+# task = tsk("iris")
+# task$col_roles
+# task$row_roles
+# gr = Graph$new()
+# gr$add_pipeop(PipeOpWinsorize$new(param_vals = list(probs_low = 0.2, probs_high = 0.8, na.rm = TRUE)))
+# result = gr$train(task)
+# result[[1]]$data()
+# predres = gr$predict(task)
+#
+# # group variable
+# dt = tsk("iris")$data()
+# dt[, monthid := c(rep(1, 50), rep(2, 50), rep(3, 50))]
+# task = as_task_classif(dt, target = "Species")
+# task$set_col_roles("monthid", "group")
+# gr = Graph$new()
+# gr$add_pipeop(PipeOpWinsorize$new(param_vals = list(probs_low = 0.2, probs_high = 0.8, na.rm = TRUE)))
+# result = gr$train(task)
+# result[[1]]$data()
+# predres = gr$predict(task)
diff --git a/mlr3ml.R b/mlr3ml.R
new file mode 100644
index 0000000..15d840f
--- /dev/null
+++ b/mlr3ml.R
@@ -0,0 +1,474 @@
+library(data.table)
+library(gausscov)
+library(paradox)
+library(mlr3)
+library(mlr3pipelines)
+
+
+
+# PREPARE DATA ------------------------------------------------------------
+# read predictors
+DT <- fread("D:/features/pead-predictors.csv")
+
+# create group variable
+DT[, monthid := paste0(data.table::year(as.Date(date, origin = "1970-01-01")),
+                       data.table::month(as.Date(date, origin = "1970-01-01")))]
+DT[, monthid := as.integer(monthid)]
+setorder(DT, monthid)
+
+# define predictors
+cols_non_features <- c("symbol", "date", "time", "right_time",
+                       "ret_excess_stand_5", "ret_excess_stand_22", "ret_excess_stand_44", "ret_excess_stand_66",
+                       colnames(DT)[grep("aroundzero", colnames(DT))],
+                       colnames(DT)[grep("extreme", colnames(DT))],
+                       colnames(DT)[grep("bin_simple", colnames(DT))],
+                       colnames(DT)[grep("bin_decile", colnames(DT))],
+                       "bmo_return", "amc_return",
+                       "open", "high", "low", "close", "volume", "returns",
+                       "monthid"
+                       # 'predictors' we don't need
+                       # colnames(DT)[grep("nperiods_\\d+", colnames(DT))],
+                       # colnames(DT)[grep("seasonal_period_\\d+", colnames(DT))]
+                       )
+cols_features <- setdiff(colnames(DT), c(cols_non_features))
+
+# convert columns to numeric. This is important only if we import existing features
+chr_to_num_cols <- setdiff(colnames(DT[, .SD, .SDcols = is.character]), c("symbol", "time", "right_time"))
+print(chr_to_num_cols)
+DT <- DT[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+# int_to_num_cols <- colnames(DT[, .SD, .SDcols = is.integer])
+# DT <- DT[, (int_to_num_cols) := lapply(.SD, as.numeric), .SDcols = int_to_num_cols]
+
+# remove constant columns in set and remove same columns in test set
+features_ <- DT[, ..cols_features]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+cols_features <- setdiff(cols_features, remove_cols)
+
+# convert variables with low number of unique values to factors
+int_numbers = DT[, ..cols_features][, lapply(.SD, function(x) all(as.integer(x)==x) & x > 0.99)]
+int_cols = na.omit(colnames(DT[, ..cols_features])[as.matrix(int_numbers)[1,]])
+factor_cols = DT[, ..int_cols][, lapply(.SD, function(x) length(unique(x)))]
+factor_cols = as.matrix(factor_cols)[1, ]
+factor_cols = factor_cols[factor_cols <= 20]
+DT = DT[, (names(factor_cols)) := lapply(.SD, as.factor), .SD = names(factor_cols)]
+
+
+
+# TASKS -------------------------------------------------------------------
+# task with aroundzero bins
+target_ = colnames(DT)[grep("around.*22", colnames(DT))]
+cols_ = c(target_, "monthid", cols_features)
+tsk_aroundzero_month <- as_task_classif(DT[, ..cols_],
+                                        id = "aroundzero_month",
+                                        target = target_)
+
+# remove NA from target variable
+any(is.na(tsk_aroundzero_month$data()))
+target_na_ids = which(is.na(tsk_aroundzero_month$truth()))
+target_na_ids = setdiff(tsk_aroundzero_month$row_ids, target_na_ids)
+tsk_aroundzero_month$filter(target_na_ids)
+any(is.na(tsk_aroundzero_month$data()))
+dim(tsk_aroundzero_month$data())
+
+# create group and holdout set
+create_validation_set <- function(task, validation_month_start = 20226) {
+  # add group role
+  task$set_col_roles("monthid", "group")
+  groups = task$groups
+
+  # add validation set
+  val_ind <- min(which(groups$group == validation_month_start)):nrow(groups)
+  task$set_row_roles(rows = val_ind, role = "holdout")
+  task$set_col_roles("monthid", "feature")
+}
+create_validation_set(tsk_aroundzero_month)
+
+# create custom rolling window cross validation set
+custom = rsmp("custom")
+task_ <- tsk_aroundzero_month$clone()
+task_$set_col_roles("monthid", "group")
+groups = task_$groups
+rm(task_)
+groups_v <- groups[, unique(group)]
+train_length <- 24
+test_length <- 1
+train_groups <- lapply(0:(length(groups_v)-(train_length+1)), function(x) x + (1:train_length))
+test_groups <- lapply(train_groups, function(x) tail(x, 1) + test_length)
+train_sets <- lapply(train_groups, function(x) groups[group %in% groups_v[x], row_id])
+test_sets <- lapply(test_groups, function(x) groups[group %in% groups_v[x], row_id])
+custom$instantiate(tsk_aroundzero_month, train_sets[1], test_sets[1])
+
+# inspect task
+# tsk_aroundzero_month$backend$primary_key
+# tsk_aroundzero_month$col_info
+# tsk_aroundzero_month$col_roles
+# tsk_aroundzero_month$labels
+# tsk_aroundzero_month$label
+# tsk_aroundzero_month$row_names
+# tsk_aroundzero_month$
+
+
+# GRAPH -------------------------------------------------------------------
+# source pipes, filters and other
+source("mlr3_winsorization.R")
+source("mlr3_uniformization.R")
+source("mlr3_gausscov_f1st.R")
+source("mlr3_dropna.R")
+source("mlr3_dropnacol.R")
+source("mlr3_filter_drop_corr.R")
+source("mlr3_gausscov_f1st.R")
+
+# add my pipes to mlr dictionary
+mlr_pipeops$add("uniformization", PipeOpUniform)
+mlr_pipeops$add("winsorize", PipeOpWinsorize)
+mlr_pipeops$add("dropna", PipeOpDropNA)
+mlr_pipeops$add("dropnacol", PipeOpDropNACol)
+mlr_pipeops$add("dropcorr", PipeOpDropCorr)
+mlr_filters$add("gausscov_f1st", FilterGausscovF1st)
+
+# create graph
+# graph = po("select", id = "select_corr") %>>%
+#   po("winsorize", id = "winsorize", probs_low = 0.01, probs_high = 0.99, na.rm = TRUE)
+graph = po("dropnacol", id = "dropnacol", cutoff = 0.05) %>>%
+  po("dropna", id = "dropna") %>>%
+  po("removeconstants", id = "removeconstants_1", ratio = 0.01)  %>>%
+  po("winsorize", id = "winsorize", probs_low = 0.01, probs_high = 0.99, na.rm = TRUE) %>>%
+  po("removeconstants", id = "removeconstants_2", ratio = 0.01)  %>>%
+  po("dropcorr", id = "dropcorr", cutoff = 0.99) %>>%
+  po("uniformization") %>>%
+  po("pca", id = "pca") %>>%
+  po("dropna", id = "dropna_v2") %>>%
+  po("filter", filter = flt("gausscov_f1st"), filter.cutoff = 0) %>>%
+  po("learner", learner = lrn("classif.ranger"))
+
+100
+
+
+base:         ret = eps_diff + momentum + bs
+alternativni: ret = eps_diff + momentum + bs + sentimenti
+
+5, 5.1 , 5.2
+13, 14, 15
+
+
+search_space = ps(
+  # preprocesing
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson")
+)
+
+# train/test graph rolling CV
+graph$train(tsk_aroundzero_month)
+graph$predict(tsk_aroundzero_month)
+
+graph_learner = as_learner(graph)
+task_ = tsk_aroundzero_month$clone()
+task_$select(task_$feature_names[1:900]) # 946
+# task_$feature_names[947]
+# table(task_$data()[, "feasts_shift_var_index_66"])
+# table(task_$data(rows = custom$train_set(1))[, "feasts_shift_var_index_66"])
+# table(task_$data(rows = custom$test_set(1))[, "feasts_shift_var_index_66"])
+# for test
+# task_$filter(custom$test_set(1))
+# task_$feature_names[947]
+# table(task_$data()[, "feasts_shift_var_index_66"])
+rr = resample(task_, graph_learner, custom, store_models = FALSE)
+rr$aggregate(msr("classif.acc"))
+rr$warnings
+rr$resampling
+rr$prediction()
+rr$resampling
+
+# holdout prediction
+# rr_decile = resample(task_decile, graph_learner, custom, store_models = TRUE)
+
+
+
+
+
+
+
+
+
+graph = po("removeconstants", ratio = 0.01) %>>%
+  # modelmatrix
+  po("branch", options = c("nop_filter", "modelmatrix"), id = "interaction_branch") %>>%
+  gunion(list(po("nop", id = "nop_filter"), po("modelmatrix", formula = ~ . ^ 2))) %>>%
+  po("unbranch", id = "interaction_unbranch") %>>%
+  po("removeconstants", id = "removeconstants_2", ratio = 0.01) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learners%>>%
+  po("classifavg", innum = length(learners_l))
+plot(graph)
+
+
+
+task = mlr3::tsk("mtcars")
+task$data()
+filter = flt("find_correlation")
+filter$calculate(task)
+as.data.table(filter)
+
+
+
+
+
+
+
+
+
+# FEATURE SELECTION (TEST) ------------------------------------------------
+# select features
+test_ <- na.omit(unique(c(predictors_f3st_1)))
+# task_extreme$select(test_)
+task_aroundzero$select(test_)
+task_simple$select(test_)
+task_decile$select(test_)
+task_reg$select(test_)
+
+# rpart tree classificatoin function
+tree_visualization <- function(task_, maxdepth = 4, cp = 0.002) {
+  learner = lrn("classif.rpart", maxdepth = maxdepth,
+                predict_type = "prob", cp = cp)
+  learner$train(task_)
+  predictins = learner$predict(task_)
+  print(predictins$score(c(msr("classif.acc"), msr("classif.recall"), msr("classif.precision"), msr("classif.fbeta"))))
+  print(learner$importance())
+  rpart_model <- learner$model
+  rpart.plot(rpart_model)
+}
+tree_visualization(task_simple$clone(), cp = 0.001)
+tree_visualization(task_simple$clone(), cp = 0.0001)
+tree_visualization(task_simple$clone(), cp = 0.00001)
+
+# rpart tree regression
+learner = lrn("regr.rpart", maxdepth = 4, cp = 0.01)
+task_ <- task_reg$clone()
+learner$train(task_reg)
+predictins = learner$predict(task_reg)
+predictins$score(msr("regr.mae"))
+learner$importance()
+rpart_model <- learner$model
+rpart.plot(rpart_model)
+
+
+
+# CLASSIFICATION AUTOML ---------------------------------------------------
+# learners
+learners_l = list(
+  ranger = lrn("classif.ranger", predict_type = "prob", id = "ranger"),
+  # log_reg = lrn("classif.log_reg", predict_type = "prob", id = "log_reg"),
+  # kknn = lrn("classif.kknn", predict_type = "prob", id = "kknn"),
+  # cv_glmnet = lrn("classif.cv_glmnet", predict_type = "prob", id = "cv_glmnet"),
+  xgboost = lrn("classif.xgboost", predict_type = "prob", id = "xgboost")
+)
+# create graph from list of learners
+choices = c("ranger", "xgboost")
+learners = po("branch", choices, id = "branch_learners") %>>%
+  gunion(learners_l) %>>%
+  po("unbranch", choices, id = "unbranch_learners")
+
+# create complete grapg
+graph = po("removeconstants", ratio = 0.01) %>>%
+  # modelmatrix
+  po("branch", options = c("nop_filter", "modelmatrix"), id = "interaction_branch") %>>%
+  gunion(list(po("nop", id = "nop_filter"), po("modelmatrix", formula = ~ . ^ 2))) %>>%
+  po("unbranch", id = "interaction_unbranch") %>>%
+  po("removeconstants", id = "removeconstants_2", ratio = 0.01) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learners%>>%
+  po("classifavg", innum = length(learners_l))
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:70, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # models
+  ranger.ranger.mtry.ratio = p_dbl(0.2, 1),
+  ranger.ranger.max.depth = p_int(2, 4),
+  # kknn.kknn.k = p_int(5, 20),
+  xgboost.xgboost.nrounds = p_int(100, 5000),
+  xgboost.xgboost.eta = p_dbl(1e-4, 1),
+  xgboost.xgboost.max_depth = p_int(1, 8),
+  xgboost.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  xgboost.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  xgboost.xgboost.lambda = p_dbl(0.1, 1),
+  xgboost.xgboost.gamma = p_dbl(1e-4, 1000),
+  xgboost.xgboost.alpha = p_dbl(1e-4, 1000),
+  xgboost.xgboost.subsample = p_dbl(0.1, 1)
+)
+# plan("multisession", workers = 4L)
+
+rr = resample(task_aroundzero, graph_learner, custom, store_models = TRUE)
+rr$aggregate(msr("classif.acc"))
+rr$warnings
+rr$resampling
+rr$prediction()
+
+# holdout prediction
+rr$
+
+  rr_decile = resample(task_decile, graph_learner, custom, store_models = TRUE)
+
+
+at_classif = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = custom,
+  measure = msr("classif.acc"),
+  search_space = search_space
+  # term_evals = 10
+)
+at_classif
+# at_classif$train(task_aroundzero)
+
+# inspect results
+at_classif$tuning_result
+at_classif$learner
+archive <- as.data.table(at_classif$archive)
+length(at_classif$state)
+ggplot(archive[, mean(classif.fbeta), by = "ranger.ranger.max.depth"], aes(x = ranger.ranger.max.depth, y = V1)) + geom_line()
+ggplot(archive[, mean(classif.fbeta), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+ggplot(archive[, mean(classif.fbeta), by = "interaction_branch.selection"], aes(x = interaction_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_classif$predict(task_extreme)
+preds$confusion
+preds$score(list(msr("classif.acc")))
+preds$score(list(msr("classif.fbeta"), msr("classif.acc")))
+
+# holdout extreme
+preds_holdout <- at_classif$predict(task_extreme_holdout)
+preds_holdout$confusion
+autoplot(preds_holdout, type = "roc")
+preds_holdout$score(msrs(c("classif.acc")))
+preds_holdout$score(msrs(c("classif.acc", "classif.recall", "classif.precision", "classif.fbeta")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+prediciotns_extreme_holdout <- prediciotns_extreme_holdout[`prob.1` > 0.6]
+nrow(prediciotns_extreme_holdout)
+mlr3measures::acc(prediciotns_extreme_holdout$truth,
+                  prediciotns_extreme_holdout$response)
+prediciotns_extreme_holdout[, truth := as.factor(ifelse(truth == 0, 1, -1))]
+prediciotns_extreme_holdout$truth <- droplevels(prediciotns_extreme_holdout$truth)
+prediciotns_extreme_holdout$response <- droplevels(prediciotns_extreme_holdout$response)
+# levels(prediciotns_extreme_holdout$response) <- c("-1", "1")
+# mlr3measures::acc(prediciotns_extreme_holdout$truth,
+#                   prediciotns_extreme_holdout$response)
+
+# try extreme on bin simple
+X_model_sim <- copy(X_holdout)
+levels(X_model_sim$bin_simple_ret_excess_stand_5) <- c("-1", "1")
+X_model_sim <- X_model_sim[, .SD, .SDcols = !c("symbol","date", labels[!grepl("simple", labels)])]
+setnames(X_model_sim, "bin_simple_ret_excess_stand_5", "bin_extreme_ret_excess_stand_5")
+X_model_sim$bin_extreme_ret_excess_stand_5
+# summary(X_model_sim$eps_diff)
+# X_model_sim <- X_model_sim[eps_diff > .1 | eps_diff < -.1] # sample here !
+# dim(X_model_sim)
+task_simple_on_extreme <- as_task_classif(na.omit(X_model_sim), id = "simple_on_extreme",
+                                          target = labels[grep("extreme", labels)])
+task_simple_on_extreme$select(test_)
+preds_holdout <- at_classif$predict(task_simple_on_extreme)
+as.data.table(task_simple_on_extreme)
+preds_holdout$confusion
+autoplot(preds_holdout, type = "roc")
+preds_holdout$score(msrs(c("classif.acc", "classif.recall", "classif.precision", "classif.fbeta")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+prediciotns_extreme_holdout <- prediciotns_extreme_holdout[prob.1 > 0.55]
+nrow(prediciotns_extreme_holdout)
+mlr3measures::acc(prediciotns_extreme_holdout$truth, prediciotns_extreme_holdout$response)
+
+
+task_simple_extreme_holdout
+
+# which variable correlate with extreme?
+cols_ <- c(colnames(X_model)[3:which(colnames(X_model) == "DCOILWTICO_ret_week")], "ret_excess_stand_5")
+test_ <- X_model[, ..cols_]
+dim(test_)
+test_[, 700:703]
+test_[, 1:3]
+# test_[, bin_extreme_ret_excess_stand_5 := as.integer(as.character(bin_extreme_ret_excess_stand_5))]
+# test_ <- test_[!is.na(bin_extreme_ret_excess_stand_5)]
+corr_bin <- cor(test_[, 1:702], test_$ret_excess_stand_5)
+class(corr_bin)
+head(corr_bin)
+head(corr_bin[order(corr_bin[, 1], decreasing = TRUE), , drop = FALSE])
+
+# predictions for qc
+cols_qc <- c("symbol", "date")
+predictoins_qc <- cbind(X_holdout[, ..cols_qc], as.data.table(preds_holdout))
+predictoins_qc[, grep("row_ids|truth", colnames(predictoins_qc)) := NULL]
+predictoins_qc <- unique(predictoins_qc)
+setorder(predictoins_qc, "date")
+
+# save to dropbox for live trading (create table for backtest)
+cols <- c("date", "symbol", colnames(predictoins_qc)[4:ncol(predictoins_qc)])
+pead_qc <- predictoins_qc[, ..cols]
+pead_qc[, date := as.character(date)]
+print(unique(pead_qc$symbol))
+pead_qc <- pead_qc[, .(symbol = paste0(unlist(symbol), collapse = ", "),
+                       prob1 = paste0(unlist(prob.1), collapse = ",")), by = date]
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-backtest")
+storage_write_csv2(pead_qc, cont, file = "hft.csv", col_names = FALSE)
+
+
+
+# TRAIN FINAL MODEL -------------------------------------------------------
+# train final model
+hft_mlr3_model <- at_classif$learner$train(task_extreme)
+
+# holdout extreme
+preds_holdout <- hft_mlr3_model$predict(task_aroundzero_holdout)
+preds_holdout$confusion
+autoplot(preds_holdout, type = "roc")
+preds_holdout$score(msrs(c("classif.acc", "classif.recall", "classif.precision", "classif.fbeta")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+prediciotns_extreme_holdout <- prediciotns_extreme_holdout[`prob.1` > 0.60]
+nrow(prediciotns_extreme_holdout)
+mlr3measures::acc(prediciotns_extreme_holdout$truth,
+                  prediciotns_extreme_holdout$response)
+mlr3measures::acc(prediciotns_extreme_holdout$truth,
+                  prediciotns_extreme_holdout$response)
+
+
+# time_ <- format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
+# saveRDS(hft_mlr3_model,
+#         paste0("D:/mlfin/mlr3_models/hft_mlr3_model-", time_, ".rds"))
+# hft_mlr3_model
+#
+#
+# hftmlr_model = readRDS(file = "D:/mlfin/mlr3_models/hft_mlr3_model-20220830164033.rds")
+# saveRDS(hftmlr_model,
+#         paste0("D:/mlfin/mlr3_models/hftmlr_model.rds"))
+
+
+
+library(mlr3)
+library(mlr3pipelines)
+task = tsk("iris")
+pop = po("scalemaxabs")
+pop$train(list(task))[[1]]$data()
+
+library(mlr3)
+library(mlr3pipelines)
+task = tsk("iris")
+dt = task$data()
+dt[, month := c(rep(1, 50), rep(2, 50), rep(3, 50))]
+task = as_task_classif(dt, target = "Species", id = "iris")
+
+task$data()[, lapply(.SD, function(x) as.vector(scale(x))), .SDcols = names(DT)[2:5], by = month]
+
+pop = po("scalemaxabs")
+pop$train(list(task))[[1]]$data()
diff --git a/myml.R b/myml.R
new file mode 100644
index 0000000..21f3d8e
--- /dev/null
+++ b/myml.R
@@ -0,0 +1,592 @@
+library(data.table)
+library(DescTools)
+library(gausscov)
+
+
+
+# read predictors
+DT <- fread("D:/features/pead-predictors.csv")
+
+# create group variable
+DT[, monthid := paste0(data.table::year(as.Date(date, origin = "1970-01-01")),
+                       data.table::month(as.Date(date, origin = "1970-01-01")))]
+
+# choose label
+print(paste0("Choose among this features: ",
+             colnames(DT)[grep("^ret_excess_stand", colnames(DT))]))
+LABEL = "ret_excess_stand_22"
+
+# define features
+cols_non_features <- c("symbol", "date", "time", "right_time",
+                       "ret_excess_stand_5", "ret_excess_stand_22", "ret_excess_stand_44", "ret_excess_stand_66",
+                       colnames(DT)[grep("aroundzero", colnames(DT))],
+                       colnames(DT)[grep("extreme", colnames(DT))],
+                       colnames(DT)[grep("bin_simple", colnames(DT))],
+                       colnames(DT)[grep("bin_decile", colnames(DT))],
+                       "bmo_return", "amc_return",
+                       "open", "high", "low", "close", "volume", "returns",
+                       "monthid")
+cols_features <- setdiff(colnames(DT), c(cols_non_features))
+
+# convert columns to numeric. This is important only if we import existing features
+chr_to_num_cols <- setdiff(colnames(DT[, .SD, .SDcols = is.character]), c("symbol", "time", "right_time"))
+DT <- DT[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+int_to_num_cols <- colnames(DT[, .SD, .SDcols = is.integer])
+DT <- DT[, (int_to_num_cols) := lapply(.SD, as.numeric), .SDcols = int_to_num_cols]
+log_to_num_cols <- colnames(DT[, .SD, .SDcols = is.logical])
+DT <- DT[, (log_to_num_cols) := lapply(.SD, as.numeric), .SDcols = log_to_num_cols]
+
+
+# define feature matrix
+cols_keep <- c("symbol", "date", cols_features, LABEL, "monthid")
+X <- DT[, ..cols_keep]
+
+# winsorize LABEL
+X[, (LABEL) := Winsorize(get(LABEL), probs = c(0.01, 0.99), na.rm = TRUE)]
+X <- na.omit(X)
+setorder(X, date)
+
+# Instantiate Resampling
+groups <- X[, unique(monthid)]
+train_length <- 24
+test_length <- 1
+train_groups <- lapply(0:(length(groups)-(train_length+1)), function(x) x + (1:train_length))
+test_groups <- lapply(train_groups, function(x) tail(x, 1) + test_length)
+train_sets <- lapply(train_groups, function(x) groups[x])
+test_sets <- lapply(test_groups, function(x) groups[x])
+
+# ML loop
+ml_results <- list()
+for (i in seq_along(test_groups)) { # seq_along(test_groups)
+
+  # debug i = 78
+  print(i)
+
+  # month ids
+  train_ids = train_sets[[i]]
+  test_ids = test_sets[[i]]
+
+  # train / test split
+  train_set <- X[monthid %in% train_ids]
+  test_set <- X[monthid %in% test_ids]
+
+  # define feature columns
+  feature_cols <- colnames(train_set)[colnames(train_set) %in% cols_features]
+
+  # macro vars
+  macro_cols <- colnames(train_set)[which(colnames(train_set) == "tbl"):which(colnames(train_set) == "t10y2y")]
+
+  # quantiles for winsorizing test test
+  summary(test_set$q1_close_divergence_528)
+  wins_cols <- feature_cols # setdiff(feature_cols, macro_cols)
+  train_set[, q_ := paste0(data.table::year(as.Date(date, origin = as.Date("1970-01-01"))),
+                           data.table::quarter(as.Date(date, origin = as.Date("1970-01-01"))))]
+  q_lower <- train_set[,  lapply(.SD, function(x) quantile(x, probs = c(0.01), na.rm = TRUE)),
+                       .SDcols = wins_cols,
+                       by = q_]
+  q_lower <- q_lower[, lapply(.SD, mean), .SDcols = colnames(q_lower)[-1]]
+  q_upper <- train_set[,  lapply(.SD, function(x) quantile(x, probs = c(0.99), na.rm = TRUE)),
+                       .SDcols = wins_cols,
+                       by = q_]
+  q_upper <- q_upper[, lapply(.SD, mean), .SDcols = colnames(q_upper)[-1]]
+  test_set[, (wins_cols) := Map(function(a, b) ifelse(a < b, b, a),
+                                .SD, q_lower), .SDcols = wins_cols]
+  test_set[, (wins_cols) := Map(function(a, b) ifelse(a > b, b, a),
+                                .SD, q_upper), .SDcols = wins_cols]
+
+  # debug
+  summary(test_set$q1_close_divergence_528)
+  q_lower$q1_close_divergence_528
+  q_upper$q1_close_divergence_528
+
+  # winsorization train set
+  train_set[, (wins_cols) := lapply(.SD, Winsorize, probs = c(0.01, 0.99), na.rm = TRUE),
+            .SDcols = wins_cols,
+            by = q_]
+  train_set[, c("q_")  := NULL]
+
+  # remove constant columns in set and remove same columns in test set
+  features_ <- train_set[, ..feature_cols]
+  remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+  # print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+  feature_cols <- setdiff(feature_cols, remove_cols)
+
+  # remove highly correlated features
+  features_ <- train_set[, ..feature_cols]
+  cor_matrix <- cor(features_)
+  cor_matrix_rm <- cor_matrix                  # Modify correlation matrix
+  cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
+  diag(cor_matrix_rm) <- 0
+  remove_cols <- colnames(features_)[apply(cor_matrix_rm, 2, function(x) any(x > 0.99))]
+  # print(paste0("Removing highly correlated featue (> 0.99): ", remove_cols))
+  feature_cols <- setdiff(feature_cols, remove_cols)
+
+  # remove missing values
+  train_set <- na.omit(train_set, cols = feature_cols)
+  test_set <- na.omit(test_set, cols = feature_cols)
+
+  # uniformisation of features in test set
+  test_uniformatization <- rbind(train_set[monthid %in% tail(train_ids, 3)], test_set)
+  test_set_first_date = test_set[, head(date, 1)]
+  dates_ = test_uniformatization[, unique(date)]
+  # print(as.Date(dates_, origin = "1970-01-01"))
+  dates_v <- c()
+  test_uniform_l <- list()
+  for (j in seq_along(dates_)) {
+    d = dates_[j]
+    dates_v <- c(dates_v, d)
+    if (d < test_set_first_date) {
+      next
+    }
+    y <- test_uniformatization[date %in% dates_v]
+    y[, (feature_cols) := lapply(.SD, function(x) ecdf(x)(x)), .SDcols = feature_cols]
+    test_uniform_l[[j]] = y[date == tail(dates_v, 1)]
+  }
+  X_test_unif = rbindlist(test_uniform_l)
+  X_test_unif[, as.Date(date, origin = "1970-01-01")] # debug
+
+  # uniformisation of features
+  # TODO Should we uniform macro predictors
+  train_set[, q_ := paste0(data.table::year(as.Date(date, origin = as.Date("1970-01-01"))),
+                           data.table::quarter(as.Date(date, origin = as.Date("1970-01-01"))))]
+  train_set[, (feature_cols) := lapply(.SD, function(x) ecdf(x)(x)),
+            .SDcols = feature_cols,
+            by = q_]
+  train_set[, c("q_")  := NULL]
+
+  # features selection
+  y_train <- as.matrix(train_set[, get(LABEL)])
+  X_train <- as.matrix(train_set[, .SD, .SDcols = feature_cols])
+  f1st_fi_ <- f1st(y_train, X_train, kmn = 20, sub = TRUE)
+  cov_index_f1st_1 <- colnames(as.matrix(X_train))[f1st_fi_[[1]][, 1]]
+  # print(cov_index_f1st_1)
+  # TODO: THIS IS SLOW, TRY IN SECOND ITERATION
+  # f3st_1_ <- f3st(y_train, X_train, kmn = 10, m = 1)
+  # f3st_1_index <- unique(as.integer(f3st_1_[[1]][1, ]))[-1]
+  # f3st_1_index <- f3st_1_index[f3st_1_index != 0]
+  # predictors_f3st_1 <- colnames(X_train)[f3st_1_index]
+
+  # # train linear regression
+  # cov_index_f1st_1 <- cov_index_f1st_1[-1]
+  # X_train_imp <- X_train[, cov_index_f1st_1]
+  # train_data <- cbind.data.frame(y = y_train, X_train_imp)
+  # reg <- lm(y ~ ., data = train_data)
+  # summary(reg)
+  # # plot(reg)
+  #
+  # # sample data for test set
+  # test_set_sample <- X_test_unif[, ..cov_index_f1st_1]
+  # predictions <- predict(reg, newdata = test_set_sample)
+  # # predictions <- sort(predictions, decreasing = TRUE)
+  # cols_test <- c("symbol", "date", LABEL)
+  # predictions_test <- cbind(test_set[, ..cols_test], predictions)
+  # setorder(predictions_test, -predictions)
+  # predictions_test[, .(mean = mean(predictions), median = median(predictions))]
+  # predictions_test[, true := as.factor(ifelse(ret_excess_stand_22 > 0, 1, 0))]
+  # predictions_test[, predict := as.factor(ifelse(predictions > 0, 1, 0))]
+
+  # save all important objects
+  save_obj = list(
+    train_months = train_sets[[i]],
+    test_monts = test_sets[[i]],
+    f1st_1 =  f1st_fi_[[1]],
+    f1st_2 =  f1st_fi_[[2]],
+    f1st_3 =  f1st_fi_[[3]],
+    f1st_predictors = cov_index_f1st_1
+    # f3st_1_1 =  f1st_fi_[[1]],
+    # f3st_1_2 =  f1st_fi_[[2]],
+    # f3st_1_3 =  f1st_fi_[[3]],
+    # f1st_predictors = cov_index_f1st_1,
+    # train_data = train_data,
+    # train_reg = reg,
+    # test_data = test_set_sample,
+    # predictions_test = predictions_test
+  )
+
+  # save results
+  ml_results[[i]] <- save_obj
+}
+
+# inspect
+length(ml_results)
+length(unique(lengths(ml_results))) == 1
+ml_results[[1]]
+
+# save results
+time_ = format.POSIXct(Sys.time(), format = "%y%m%d%H%M%S")
+file_name = paste0("D:/mlfin/mypead/prad_ml_myapproach-", time_, ".rds")
+saveRDS(ml_results, file_name)
+
+
+
+# REG ---------------------------------------------------------------------
+# most important predictors througt time
+ip_l = lapply(ml_results, function(x) x$f1st_predictors)
+ip = data.table(predictors = unlist(ip_l))
+ip = ip[, .N, by = predictors]
+setorder(ip, N)
+tail(ip, 20)
+
+# regression with n important predictors
+predictions_best = lapply(seq_along(ml_results), function(i) {
+  # debug
+  print(i)
+
+  # month ids
+  train_ids = train_sets[[i]]
+  test_ids = test_sets[[i]]
+
+  # train / test split
+  train_set <- X[monthid %in% train_ids]
+  test_set <- X[monthid %in% test_ids]
+
+  # keep important features
+  feature_cols <- ml_results[[i]]$f1st_predictors
+
+  # macro vars
+  macro_cols <- colnames(train_set)[which(colnames(train_set) == "tbl"):which(colnames(train_set) == "t10y2y")]
+
+  # quantiles for winsorizing test test
+  wins_cols <- setdiff(feature_cols, macro_cols)
+  train_set[, q_ := paste0(data.table::year(as.Date(date, origin = as.Date("1970-01-01"))),
+                           data.table::quarter(as.Date(date, origin = as.Date("1970-01-01"))))]
+  q_lower <- train_set[,  lapply(.SD, function(x) quantile(x, probs = c(0.01), na.rm = TRUE)),
+                       .SDcols = wins_cols,
+                       by = q_]
+  q_lower <- q_lower[, lapply(.SD, mean), .SDcols = colnames(q_lower)[-1]]
+  q_upper <- train_set[,  lapply(.SD, function(x) quantile(x, probs = c(0.99), na.rm = TRUE)),
+                       .SDcols = wins_cols,
+                       by = q_]
+  q_upper <- q_upper[, lapply(.SD, mean), .SDcols = colnames(q_upper)[-1]]
+  test_set[, (wins_cols) := Map(function(a, b) ifelse(a < b, b, a),
+                                .SD, q_lower), .SDcols = wins_cols]
+  test_set[, (wins_cols) := Map(function(a, b) ifelse(a > b, b, a),
+                                .SD, q_upper), .SDcols = wins_cols]
+
+  # winsorization train set
+  train_set[, (wins_cols) := lapply(.SD, Winsorize, probs = c(0.01, 0.99), na.rm = TRUE),
+            .SDcols = wins_cols,
+            by = q_]
+  train_set[, c("q_")  := NULL]
+
+  # remove constant columns in set and remove same columns in test set
+  features_ <- train_set[, ..feature_cols]
+  remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+  print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+  feature_cols <- setdiff(feature_cols, remove_cols)
+
+  # remove highly correlated features
+  features_ <- train_set[, ..feature_cols]
+  cor_matrix <- cor(features_)
+  cor_matrix_rm <- cor_matrix                  # Modify correlation matrix
+  cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
+  diag(cor_matrix_rm) <- 0
+  remove_cols <- colnames(features_)[apply(cor_matrix_rm, 2, function(x) any(x > 0.99))]
+  print(paste0("Removing highly correlated featue (> 0.99): ", remove_cols))
+  feature_cols <- setdiff(feature_cols, remove_cols)
+
+  # remove missing values
+  train_set <- na.omit(train_set, cols = feature_cols)
+  test_set <- na.omit(test_set, cols = feature_cols)
+
+  # uniformisation of features in test set
+  test_uniformatization <- rbind(train_set[monthid %in% tail(train_ids, 3)], test_set)
+  test_set_first_date = test_set[, head(date, 1)]
+  dates_ = test_uniformatization[, unique(date)]
+  # print(as.Date(dates_, origin = "1970-01-01"))
+  dates_v <- c()
+  test_uniform_l <- list()
+  for (j in seq_along(dates_)) {
+    d = dates_[j]
+    dates_v <- c(dates_v, d)
+    if (d < test_set_first_date) {
+      next
+    }
+    y <- test_uniformatization[date %in% dates_v]
+    y[, (feature_cols) := lapply(.SD, function(x) ecdf(x)(x)), .SDcols = feature_cols]
+    test_uniform_l[[j]] = y[date == tail(dates_v, 1)]
+  }
+  X_test_unif = rbindlist(test_uniform_l)
+  X_test_unif[, as.Date(date, origin = "1970-01-01")] # debug
+
+  # uniformisation of features
+  # TODO Should we uniform macro predictors
+  train_set[, q_ := paste0(data.table::year(as.Date(date, origin = as.Date("1970-01-01"))),
+                           data.table::quarter(as.Date(date, origin = as.Date("1970-01-01"))))]
+  train_set[, (feature_cols) := lapply(.SD, function(x) ecdf(x)(x)),
+            .SDcols = feature_cols,
+            by = q_]
+  train_set[, c("q_")  := NULL]
+
+  # target and X
+  y_train <- as.matrix(train_set[, get(LABEL)])
+  X_train <- as.matrix(train_set[, .SD, .SDcols = feature_cols])
+
+  # train linear regression
+  n = 3
+  X_train_imp <- X_train[, feature_cols[1:n]]
+  train_data <- cbind.data.frame(y = y_train, X_train_imp)
+  reg <- lm(y ~ ., data = train_data)
+  summary(reg)
+  # plot(reg)
+  predictions_train = predict(reg)
+
+  # sample data for test set
+  cols = feature_cols[1:3]
+  test_set_sample <- X_test_unif[, ..cols]
+  predictions <- predict(reg, newdata = test_set_sample)
+  cols_test <- c("symbol", "date", LABEL)
+  predictions_test <- cbind(test_set[, ..cols_test], predictions)
+  setorder(predictions_test, -predictions)
+  predictions_test[, .(mean = mean(predictions), median = median(predictions))]
+  predictions_test[, true := as.factor(ifelse(ret_excess_stand_22 > 0, 1, 0))]
+  predictions_test[, predict := as.factor(ifelse(predictions > 0, 1, 0))]
+
+  # save results
+  list(
+    predictions_train = predictions_train,
+    predictions_test = predictions_test
+  )
+})
+
+# accuracy on whole test sets
+accs <- vapply(predictions_best, function(y) {
+  train_predicitons_ = y$predictions_train
+  test_predicitons_ = y$predictions_test
+  truth = test_predicitons_$true
+  resp = test_predicitons_$predict
+  if (all(resp == 1)) {
+    resp <- as.numeric(resp)
+    resp <- factor(resp, levels = c("0", "1"))
+  } else if (all(resp == 0)) {
+    levels(resp) <- c("0", "1")
+  }
+  acc <- mlr3measures::acc(truth,
+                           resp)
+  acc
+}, numeric(1))
+mean(accs)
+median(accs)
+
+
+# prediction for highest return predictions
+# y = predictions_best[[1]]
+predictions_best_l <- lapply(predictions_best, function(y) {
+  train_predicitons_ = y$predictions_train
+  test_predicitons_ = y$predictions_test
+  q_train <- quantile(train_predicitons_, 0.95)
+  predictions_q <- test_predicitons_[predictions > q_train]
+  if (nrow(predictions_q) == 0) {
+    print(y$test_monts)
+    return(NULL)
+  }
+  if (all(predictions_q$predict == 1) & length(levels(predictions_q$predict)) == 1) {
+    predictions_q$predict <- as.numeric(predictions_q$predict)
+    predictions_q$predict <- factor(predictions_q$predict, levels = c("0", "1"))
+  } else if (all(predictions_q$predict == 0) & length(levels(predictions_q$predict)) == 1) {
+    levels(predictions_q$predict) <- c("0", "1")
+  }
+  acc <- mlr3measures::acc(predictions_q$true,
+                           predictions_q$predict)
+  cbind.data.frame(obs = nrow(predictions_q), acc = acc)
+})
+predictions_best_ <- rbindlist(predictions_best_l)
+# predictions_best_ <- cbind(vapply(ml_results, function(x) x[[2]], numeric(1)), predictions_best_)
+predictions_best_[, .(mean = mean(acc), median = median(acc),
+                      mean_weight = weighted.mean(acc, obs))]
+
+#
+predictions_best_l <- lapply(predictions_best, function(y) {
+  train_predicitons_ = y$predictions_train
+  test_predicitons_ = y$predictions_test
+  q_train <- quantile(train_predicitons_, 0.90)
+  predictions_q <- test_predicitons_[predictions > q_train]
+  if (nrow(predictions_q) == 0) {
+    print(y$test_monts)
+    return(NULL)
+  }
+  if (all(predictions_q$predict == 1) & length(levels(predictions_q$predict)) == 1) {
+    predictions_q$predict <- as.numeric(predictions_q$predict)
+    predictions_q$predict <- factor(predictions_q$predict, levels = c("0", "1"))
+  } else if (all(predictions_q$predict == 0) & length(levels(predictions_q$predict)) == 1) {
+    levels(predictions_q$predict) <- c("0", "1")
+  }
+  cbind.data.frame(true = predictions_q$true, predict = predictions_q$predict)
+})
+predictions_best_ <- rbindlist(predictions_best_l)
+mlr3measures::acc(predictions_best_$true,
+                  predictions_best_$predict)
+
+#
+
+
+
+# INTERACTION -------------------------------------------------------------
+# regression with n important predictors
+predictions_best_int = lapply(seq_along(ml_results), function(i) {
+  # debug
+  print(i)
+
+  # month ids
+  train_ids = train_sets[[i]]
+  test_ids = test_sets[[i]]
+
+  # train / test split
+  train_set <- X[monthid %in% train_ids]
+  test_set <- X[monthid %in% test_ids]
+
+  # keep important features
+  feature_cols <- ml_results[[i]]$f1st_predictors
+
+  # macro vars
+  macro_cols <- colnames(train_set)[which(colnames(train_set) == "tbl"):which(colnames(train_set) == "t10y2y")]
+
+  # quantiles for winsorizing test test
+  wins_cols <- setdiff(feature_cols, macro_cols)
+  train_set[, q_ := paste0(data.table::year(as.Date(date, origin = as.Date("1970-01-01"))),
+                           data.table::quarter(as.Date(date, origin = as.Date("1970-01-01"))))]
+  q_lower <- train_set[,  lapply(.SD, function(x) quantile(x, probs = c(0.01), na.rm = TRUE)),
+                       .SDcols = wins_cols,
+                       by = q_]
+  q_lower <- q_lower[, lapply(.SD, mean), .SDcols = colnames(q_lower)[-1]]
+  q_upper <- train_set[,  lapply(.SD, function(x) quantile(x, probs = c(0.99), na.rm = TRUE)),
+                       .SDcols = wins_cols,
+                       by = q_]
+  q_upper <- q_upper[, lapply(.SD, mean), .SDcols = colnames(q_upper)[-1]]
+  test_set[, (wins_cols) := Map(function(a, b) ifelse(a < b, b, a),
+                                .SD, q_lower), .SDcols = wins_cols]
+  test_set[, (wins_cols) := Map(function(a, b) ifelse(a > b, b, a),
+                                .SD, q_upper), .SDcols = wins_cols]
+
+  # winsorization train set
+  train_set[, (wins_cols) := lapply(.SD, Winsorize, probs = c(0.01, 0.99), na.rm = TRUE),
+            .SDcols = wins_cols,
+            by = q_]
+  train_set[, c("q_")  := NULL]
+
+  # remove constant columns in set and remove same columns in test set
+  features_ <- train_set[, ..feature_cols]
+  remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+  print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+  feature_cols <- setdiff(feature_cols, remove_cols)
+
+  # remove highly correlated features
+  features_ <- train_set[, ..feature_cols]
+  cor_matrix <- cor(features_)
+  cor_matrix_rm <- cor_matrix                  # Modify correlation matrix
+  cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
+  diag(cor_matrix_rm) <- 0
+  remove_cols <- colnames(features_)[apply(cor_matrix_rm, 2, function(x) any(x > 0.99))]
+  print(paste0("Removing highly correlated featue (> 0.99): ", remove_cols))
+  feature_cols <- setdiff(feature_cols, remove_cols)
+
+  # remove missing values
+  train_set <- na.omit(train_set, cols = feature_cols)
+  test_set <- na.omit(test_set, cols = feature_cols)
+
+  # uniformisation of features in test set
+  test_uniformatization <- rbind(train_set[monthid %in% tail(train_ids, 3)], test_set)
+  test_set_first_date = test_set[, head(date, 1)]
+  dates_ = test_uniformatization[, unique(date)]
+  # print(as.Date(dates_, origin = "1970-01-01"))
+  dates_v <- c()
+  test_uniform_l <- list()
+  for (j in seq_along(dates_)) {
+    d = dates_[j]
+    dates_v <- c(dates_v, d)
+    if (d < test_set_first_date) {
+      next
+    }
+    y <- test_uniformatization[date %in% dates_v]
+    y[, (feature_cols) := lapply(.SD, function(x) ecdf(x)(x)), .SDcols = feature_cols]
+    test_uniform_l[[j]] = y[date == tail(dates_v, 1)]
+  }
+  X_test_unif = rbindlist(test_uniform_l)
+  X_test_unif[, as.Date(date, origin = "1970-01-01")] # debug
+
+  # uniformisation of features
+  # TODO Should we uniform macro predictors
+  train_set[, q_ := paste0(data.table::year(as.Date(date, origin = as.Date("1970-01-01"))),
+                           data.table::quarter(as.Date(date, origin = as.Date("1970-01-01"))))]
+  train_set[, (feature_cols) := lapply(.SD, function(x) ecdf(x)(x)),
+            .SDcols = feature_cols,
+            by = q_]
+  train_set[, c("q_")  := NULL]
+
+  # target and X
+  y_train <- as.matrix(train_set[, get(LABEL)])
+  X_train <- as.matrix(train_set[, .SD, .SDcols = feature_cols])
+
+  # train linear regression
+  X_train_imp <- X_train[, feature_cols]
+  train_data <- cbind.data.frame(y = y_train, X_train_imp)
+  train_data <- model.matrix(y ~ (.)^2 - 1, data = train_data)
+  reg <- lm(y ~ ., data = cbind.data.frame(y = y_train, train_data))
+
+  # Get the coefficient matrix
+  coefs <- summary(reg)$coefficients
+  vars <- rownames(coefs)[which(coefs[, 4] < 0.05)]
+  vars = setdiff(vars, "(Intercept)")
+  reg <- lm(y ~ ., data = cbind.data.frame(y = y_train, train_data[, gsub("`", "", vars)]))
+  summary(reg)
+  predictions_train = predict(reg)
+
+  # sample data for test set
+  test_set_sample <- X_test_unif[, ..feature_cols]
+  test_set_sample <- model.matrix( ~ (.)^2 - 1, data = test_set_sample)
+  test_set_sample <- test_set_sample[, gsub("`", "", vars), drop = FALSE]
+  predictions <- predict(reg, newdata = as.data.frame(test_set_sample))
+  cols_test <- c("symbol", "date", LABEL)
+  predictions_test <- cbind(test_set[, ..cols_test], predictions)
+  setorder(predictions_test, -predictions)
+  predictions_test[, .(mean = mean(predictions), median = median(predictions))]
+  predictions_test[, true := as.factor(ifelse(ret_excess_stand_22 > 0, 1, 0))]
+  predictions_test[, predict := as.factor(ifelse(predictions > 0, 1, 0))]
+
+  # save results
+  list(
+    predictions_train = predictions_train,
+    predictions_test = predictions_test
+  )
+})
+
+# accuracy on whole test sets
+accs <- vapply(predictions_best_int, function(y) {
+  train_predicitons_ = y$predictions_train
+  test_predicitons_ = y$predictions_test
+  truth = test_predicitons_$true
+  resp = test_predicitons_$predict
+  if (all(resp == 1)) {
+    resp <- as.numeric(resp)
+    resp <- factor(resp, levels = c("0", "1"))
+  } else if (all(resp == 0)) {
+    levels(resp) <- c("0", "1")
+  }
+  acc <- mlr3measures::acc(truth,
+                           resp)
+  acc
+}, numeric(1))
+mean(accs)
+median(accs)
+
+#
+predictions_best_int_l <- lapply(predictions_best_int, function(y) {
+  train_predicitons_ = y$predictions_train
+  test_predicitons_ = y$predictions_test
+  q_train <- quantile(train_predicitons_, 0.90)
+  predictions_q <- test_predicitons_[predictions > q_train]
+  if (nrow(predictions_q) == 0) {
+    print(y$test_monts)
+    return(NULL)
+  }
+  if (all(predictions_q$predict == 1) & length(levels(predictions_q$predict)) == 1) {
+    predictions_q$predict <- as.numeric(predictions_q$predict)
+    predictions_q$predict <- factor(predictions_q$predict, levels = c("0", "1"))
+  } else if (all(predictions_q$predict == 0) & length(levels(predictions_q$predict)) == 1) {
+    levels(predictions_q$predict) <- c("0", "1")
+  }
+  cbind.data.frame(true = predictions_q$true, predict = predictions_q$predict)
+})
+predictions_best_int_ <- rbindlist(predictions_best_int_l)
+mlr3measures::acc(predictions_best_int_$true,
+                  predictions_best_int_$predict)
diff --git a/pead.R b/pead.R
index 849c5e7..be67ef3 100644
--- a/pead.R
+++ b/pead.R
@@ -13,6 +13,7 @@ library(DescTools)
 library(fredr)
 library(future.apply)
 library(reticulate)
+library(pins)
 # Python environment and python modules
 # Instructions: some functions use python modules. Steps to use python include:
 # 1. create new conda environment:
@@ -23,9 +24,9 @@ library(reticulate)
 #    mlfinlab
 #    tsfresh
 #    TSFEL
-reticulate::use_python("C:/ProgramData/Anaconda3/envs/mlfinlabenv/python.exe", required = TRUE) # check the path on yout system!
-pd <- reticulate::import("pandas", convert = FALSE) # import pandas
-mlfinlab <- reticulate::import("mlfinlab", convert = FALSE) # import mlfinlab
+# reticulate::use_python("C:/ProgramData/Anaconda3/envs/mlfinlabenv/python.exe", required = TRUE) # check the path on yout system!
+# pd <- reticulate::import("pandas", convert = FALSE) # import pandas
+# mlfinlab <- reticulate::import("mlfinlab", convert = FALSE) # import mlfinlab
 
 
 # SET UP ------------------------------------------------------------------
@@ -44,32 +45,66 @@ fred_api_key <- "fb7e8cbac4b84762980f507906176c3c"
 fredr_set_key(fred_api_key)
 
 # parameters
-strategy = "PEAD"  # can be PEAD (for predicting post announcement drift) or PRE (for predicting pre announcement)
-use_fundamental_data = FALSE  # should we use fundamental data as features?
+strategy = "PRE"  # can be PEAD (for predicting post announcement drift) or PRE (for predicting pre announcement)
+use_fundamental_data = TRUE  # should we use fundamental data as features?
 start_holdout_date = as.Date("2021-01-01") # observations after this date belongs to holdout set
+events_data <- "intersection" # one of "fmp", "investingcom", "intersection"
 
+# pins boards
+board_fundamentals <- board_azure(
+  container = storage_container(ENDPOINT, "fundamentals"), # HERE CHANGE WHEN MINUTE DATA !!!
+  path = "",
+  n_processes = 10,
+  versioned = FALSE,
+  cache = NULL
+)
+board_fmp <- board_azure(
+  container = storage_container(ENDPOINT, "fmpcloud"), # HERE CHANGE WHEN MINUTE DATA !!!
+  path = "",
+  n_processes = 10,
+  versioned = FALSE,
+  cache = NULL
+)
+CACHEDIR = "D:/findata" # here define your local folder wher data will be saved
+board_prices <- board_azure(
+  container = storage_container(ENDPOINT, "fmpcloud-daily"),
+  path = "",
+  n_processes = 6L,
+  versioned = FALSE,
+  cache = CACHEDIR
+)
 
 # EVENTS ------------------------------------------------------------------
 # get events data
-events <- as.data.table(storage_read_csv(CONT, "EarningAnnouncements.csv")) # PINS !
-events <- na.omit(events, cols = c("eps", "epsEstimated")) # remove rows with NA for earnings
-events <- events[date < Sys.Date()] # remove announcements for today
+events <- pin_read(board_fmp, "EarningAnnouncements")
+events <- as.data.table(events)
+events[, `:=`(date = as.Date(date), symbol = as.character(symbol), time = as.character(time),
+              updatedFromDate = as.Date(updatedFromDate), fiscalDateEnding = as.Date(fiscalDateEnding))]
+
+# coarse filtering
+events <- events[date < Sys.Date()]                 # remove announcements for today
+events <- unique(events, by = c("symbol", "date"))  # remove duplicated symobl / date pair
+if (strategy == "PEAD") {
+  print(paste0("Remove ", sum(is.na(events$eps)), " observations because of missing eps values or ",
+               100 * round(sum(is.na(events$eps)) / nrow(events), 4), "% percent."))
+  events <- na.omit(events, cols = c("eps")) # remove rows with NA for earnings
+}
 
 # keep only usa stocks
 url <- modify_url("https://financialmodelingprep.com/", path = "api/v3/available-traded/list",
                   query = list(apikey = Sys.getenv("APIKEY-FMPCLOUD") ))
 stocks <- rbindlist(content(GET(url)))
-filter_symbols <- stocks[exchange %in% c("AMEX", "New York Stock Exchange Arca",
-                                         "New York Stock Exchange", "NasdaqGS",
-                                         "Nasdaq", "NASDAQ", "AMEX", "NYSEArca",
-                                         "NASDAQ Global Market", "Nasdaq Global Market",
-                                         "NYSE American", "Nasdaq Capital Market",
-                                         "Nasdaq Global Select")]
-events <- events[symbol %in% filter_symbols$symbo]
+usa_symbols <- stocks[exchangeShortName %in% c("AMEX", "NASDAQ", "NYSE", "OTC")]
+print(paste0("Remove ", nrow(events[!(symbol %in% usa_symbols$symbo)]),
+             " observations because they are not usa stocks, or ",
+             100 * round(nrow(events[!(symbol %in% usa_symbols$symbo)]) / nrow(events), 4), "% percent."))
+events <- events[symbol %in% usa_symbols$symbo]
 
 # investing.com data
 investingcom_ea <- as.data.table(storage_read_csv(CONTINVESTINGCOM, "EarningAnnouncementsInvestingCom.csv"))
-investingcom_ea <- na.omit(investingcom_ea, cols = c("eps", "eps_forecast"))
+if (strategy == "PEAD") {
+  investingcom_ea <- na.omit(investingcom_ea, cols = c("eps", "eps_forecast"))
+}
 investingcom_ea <- investingcom_ea[, .(symbol, datetime, eps, eps_forecast, revenue, revenue_forecast, right_time)]
 investingcom_ea[, date_investingcom := as.Date(datetime)]
 setnames(investingcom_ea, colnames(investingcom_ea)[2:6], paste0(colnames(investingcom_ea)[2:6], "_investingcom"))
@@ -81,20 +116,34 @@ events <- merge(events, investingcom_ea,
                 all.x = TRUE, all.y = FALSE)
 events <- events[date == as.Date(datetime_investingcom)] # keep only observations available in both datasets
 
-# replace FMP cloud data with investing.com data if FMP CLOUD data doesn't exists
-events[, eps := ifelse(is.na(eps), eps_investingcom, eps)]
-events[, epsEstimated := ifelse(is.na(epsEstimated), eps_forecast_investingcom, epsEstimated)]
-events[, revenue := ifelse(is.na(revenue), revenue_investingcom, revenue)]
-events[, revenueEstimated := ifelse(is.na(revenueEstimated), revenue_forecast_investingcom, revenueEstimated)]
-
-# check if time are the same
-events[, right_time := ifelse(is.na(right_time), NA, ifelse(right_time == "marketClosed ", "amc", "bmc"))]
-events[, time_dummy := time == right_time]
-
-# if both fmp cloud and investing.com data exists keep similar
-print(paste0("Number of removed observations because of investing.com / FMP cloud disbalance is :",
-             nrow(events[abs(eps - eps_investingcom) > 0.04])))
-events <- events[abs(eps - eps_investingcom) < 0.04] # keep only observations where earnings are very similar
+# choose events subsample
+if (events_data == "intersection") {
+  # replace FMP cloud data with investing.com data if FMP CLOUD data doesn't exists
+  events[, eps := ifelse(is.na(eps), eps_investingcom, eps)]
+  events[, epsEstimated := ifelse(is.na(epsEstimated), eps_forecast_investingcom, epsEstimated)]
+  events[, revenue := ifelse(is.na(revenue), revenue_investingcom, revenue)]
+  events[, revenueEstimated := ifelse(is.na(revenueEstimated), revenue_forecast_investingcom, revenueEstimated)]
+
+  # check if time are the same
+  events[!is.na(right_time) & right_time == "marketClosed ", right_time := "amc"]
+  events[!is.na(right_time) & right_time == "marketOpen ", right_time := "bmo"]
+  events[, same_announce_time := time == right_time]
+
+  # if both fmp cloud and investing.com data exists keep similar
+  print(paste0("Number of removed observations because of investing.com / FMP cloud disbalance is :",
+               nrow(events[abs(eps - eps_investingcom) > 0.02]), " or ",
+               round(nrow(events[abs(eps - eps_investingcom) > 0.02]) / nrow(events), 4) * 100, "% percent."))
+  events <- events[abs(eps - eps_investingcom) < 0.02] # keep only observations where earnings are very similar
+
+  # if PRE keep only same time
+  if (strategy == "PRE") {
+    # if both fmp cloud and investing.com data exists keep similar
+    print(paste0("Number of removed observations because time of announcements are not same :",
+                 sum(!((events$same_announce_time) == TRUE), na.rm = TRUE), " or ",
+                 round(sum(!((events$same_announce_time) == TRUE), na.rm = TRUE) / nrow(events), 4) * 100, "% percent."))
+    events <- events[events$same_announce_time == TRUE] # keep only observations where earnings are very similar
+  }
+}
 
 # remove duplicated events
 events <- unique(events, by = c("symbol", "date"))
@@ -143,9 +192,11 @@ prices <- unique(prices, by = c("symbol", "date")) # remove duplicates if they e
 
 # LABELING ----------------------------------------------------------------
 # calculate returns
-prices[, ret_22 := shift(close, -21L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+prices[, ret_22 := shift(close, -21L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"] # close not shift(close, -1L, "shift") ??
 prices[, ret_44 := shift(close, -43L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
 prices[, ret_66 := shift(close, -65L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+prices[, amc_return := shift(open, -1L, "shift") / close - 1, by = "symbol"] # PRE
+prices[, bmo_return := open / shift(close) - 1, by = "symbol"] # PRE
 
 # calculate rolling sd
 prices[, sd_22 := roll::roll_sd(close / shift(close, 1L) - 1, 22), by = "symbol"]
@@ -176,23 +227,13 @@ prices[, `:=`(ret_22 = NULL, ret_44 = NULL, ret_66 = NULL,
               sd_22 = NULL, sd_44 = NULL, sd_66 = NULL,
               ret_22_excess = NULL, ret_44_excess = NULL, ret_66_excess = NULL)]
 
-# labels for PRE announcement drift
-# prices_dt[, close_open_return := close / open - 1, by = "symbol"]
-# prices_dt[, open_close_return := open / shift(close) - 1, by = "symbol"]
-
-
-
-
-# ADD FEATURES (LATER THIS GOES TO FINFEATURES) ---------------------------
-# ath divergence
-# prices[, ath_month_div := (shift(frollapply(high, 22, max), 1L) / close) - 1]
-# prices[, ath_week_div := (shift(frollapply(high, 5, max), 1L) / close) - 1]
 
 
 # MERGE MARKET DATA, EVENTS AND LABELS ------------------------------------
 # merge clf_data and labels
 dataset <- merge(events,
-                 prices[, .(symbol, date, ret_excess_stand_22, ret_excess_stand_44, ret_excess_stand_66)],
+                 prices[, .(symbol, date, ret_excess_stand_22, ret_excess_stand_44, ret_excess_stand_66,
+                            amc_return, bmo_return)],
                  by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
 
 # extreme labeling
@@ -223,6 +264,354 @@ dataset[, (bin_aroundzero_col_names) := lapply(.SD, labeling_around_zero), .SDco
 setorderv(dataset, c("symbol", "date"))
 
 
+
+# PRE ANALYSIS ------------------------------------------------------------
+# select coluimns we need
+data_pre <- dataset[, .(symbol, date, time, amc_return, bmo_return, fiscalDateEnding)]
+data_pre <- na.omit(data_pre)
+data_pre[time == "amc", after_annouoncement_return := amc_return]
+data_pre[time == "bmo", after_annouoncement_return := bmo_return ]
+table(data_pre$time)
+data_pre[symbol == "AMZN"]
+
+# # scrap all data
+# # financial analysis
+# library(findata)
+# fmp = FMP$new()
+# sp500_symobls <- unique(data_pre$symbol)
+# ratios <- lapply(sp500_symobls, fmp$get_financial_metrics, type = "ratios", period = "quarter")
+# ratios <- rbindlist(ratios)
+# pin_write(board_fundamentals, ratios, "ratios", type = "csv")
+# key_metrics <- lapply(sp500_symobls, fmp$get_financial_metrics, type = "key-metrics", period = "quarter")
+# key_metrics <- rbindlist(key_metrics)
+# pin_write(board_fundamentals, key_metrics, "key-metrics", type = "csv")
+# fin_growth <- lapply(sp500_symobls, fmp$get_financial_metrics, type = "financial-growth", period = "quarter")
+# fin_growth <- rbindlist(fin_growth)
+# pin_write(board_fundamentals, fin_growth, "financial-growth-growth", type = "csv")
+# # financial statements
+# get_fis <- function(fi_name = "balance-sheet-statement") {
+#   x <- lapply(sp500_symobls, fmp$get_fi_statement, statement = fi_name, period = "quarter")
+#   x <- rbindlist(x)
+#   pin_write(board_fundamentals, x, fi_name, type = "csv")
+# }
+# get_fis()
+# get_fis("income-statement")
+# get_fis("cash-flow-statement")
+
+# fundamental data
+pin_list(board_fundamentals)
+key_metrics <- as.data.table(pin_read(board_fundamentals, "key-metrics"))
+key_metrics[, price := pfcfRatio * freeCashFlowPerShare]
+key_metrics[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol))]
+fg <- as.data.table(pin_read(board_fundamentals, "financial-growth-growth"))
+fg[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol))]
+is <- as.data.table(pin_read(board_fundamentals, "income-statement"))
+is[, `:=`(date = as.Date(as.character(date)), symbol = as.character(symbol), fillingDate = as.Date(as.character(fillingDate)))]
+bs <- as.data.table(pin_read(board_fundamentals, "balance-sheet-statement"))
+bs[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol),
+          fillingDate = as.Date(as.character(fillingDate)))]
+cf <- as.data.table(pin_read(board_fundamentals, "cash-flow-statement"))
+cf[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol),
+          fillingDate = as.Date(as.character(fillingDate)))]
+ratios <- as.data.table(pin_read(board_fundamentals, "ratios"))
+ratios[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol))]
+# merge fundamntal datasets
+fundamentals <- Reduce(function(x, y) merge(x, y, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE),
+                       list(is, bs, cf, key_metrics, fg, ratios))
+setorderv(fundamentals, c("symbol", "fillingDate"))
+fundamentals <- unique(fundamentals, by = c("symbol", "date"))
+# writexl::write_xlsx(fundamentals, "~/fundamentals.xlsx")
+
+# merge date pre and choosen fundamentals
+fund_cols <- c("symbol", "date", colnames(fundamentals)[100:ncol(fundamentals)])
+DT <- merge(data_pre, fundamentals[, ..fund_cols],
+            by.x = c("symbol", "fiscalDateEnding"),
+            by.y = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+DT[, `:=`(link = NULL, finalLink = NULL)]
+
+# remove columns with lots of NA values
+keep_cols <- names(which(colMeans(!is.na(DT)) > 0.5))
+print(paste0("Removing columns with many NA values: ", setdiff(colnames(DT), keep_cols)))
+DT <- DT[, .SD, .SDcols = keep_cols]
+DT <- na.omit(DT)
+
+# add features based on market data
+prices_events <- prices[open > 1e-005 & high > 1e-005 & low > 1e-005 & close > 1e-005 & symbol %in% unique(DT$symbol)]
+prices_events <- merge(prices_events,
+                       DT[, .(symbol, date, time, after_annouoncement_return)],
+                       by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+at_ <- which(!is.na(prices_events$after_annouoncement_return))
+OhlcvInstance = Ohlcv$new(prices_events[, 1:7], date_col = "date")
+lag_ <- ifelse(prices_events$time == "amc", 0, -1)
+at_ohlcv <- at_ + lag_[at_]
+
+# Debug
+head(at_, 20)
+head(lag_[at_], 20)
+head(at_ohlcv, 20)
+
+# Features from OHLLCV
+print("Calculate Ohlcv features.")
+OhlcvFeaturesInit = OhlcvFeatures$new(at = at_ohlcv,
+                                      frequnit = 1,
+                                      windows = c(5, 10, 22, 22 * 3, 22 * 6, 22 * 12),
+                                      quantile_divergence_window =  c(22, 22*3, 22*6, 22*12))
+OhlcvFeaturesSet = OhlcvFeaturesInit$get_ohlcv_features(OhlcvInstance)
+setorderv(OhlcvFeaturesSet, c("symbol", "date"))
+
+# DEBUG
+tail(dataset[, .(symbol, date, time)], 10)
+head(OhlcvFeaturesSet[symbol == "ZYXI", .(symbol, date)], 10)
+
+# Exuber features
+print("Calculate Exuber features.")
+s <- Sys.time()
+RollingExuberInit = RollingExuber$new(windows = c(200, 600), workers = 4L, at = at_,
+                                      lag = lag_[at_] * -1,
+                                      na_pad = TRUE,
+                                      simplify = FALSE,
+                                      exuber_lag = 1L)
+RollingExuberFeatures = RollingExuberInit$get_rolling_features(OhlcvInstance)
+e <- Sys.time()
+e - s
+gc()
+
+# DEBUG
+tail(dataset[, .(symbol, date, time)], 10)
+tail(RollingExuberFeatures[symbol == "ZYXI", .(symbol, date)], 10)
+
+# Forecast Features
+print("Calculate AutoArima features.")
+RollingForecatsInstance = RollingForecats$new(windows = c(100, 252),
+                                              workers = 8L,
+                                              lag = lag_[at_] * -1,
+                                              at = at_,
+                                              na_pad = TRUE,
+                                              simplify = FALSE,
+                                              forecast_type = "autoarima",
+                                              h = 22)
+RollingForecatsAutoarimaFeatures = RollingForecatsInstance$get_rolling_features(OhlcvInstance)
+print("Calculate Nnetar features.")
+gc()
+
+# merge all features test
+cols_ohlcv <- c("symbol", "date", colnames(OhlcvFeaturesSet)[9:ncol(OhlcvFeaturesSet)])
+features <- Reduce(function(x, y) merge(x, y, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE),
+                   list(OhlcvFeaturesSet[, ..cols_ohlcv], RollingExuberFeatures,
+                        RollingForecatsAutoarimaFeatures))
+
+# DEBUG
+features[, 1:5]
+DT[, 1:5]
+
+# merge DT and features
+features[, date_features := date]
+features <- features[DT, on = c("symbol", "date"), roll = +Inf]
+
+# DEBUG
+features[, .(symbol, date, date_features)]
+tail(features[, .(symbol, date, date_features)], 10)
+
+# save data with fundamentals
+setorderv(features, c("symbol", "date"))
+print("Saving features with fundamentals to blob.")
+fwrite(features, "D:/mlfin/mlr3_models/PRE-features.csv")
+# features <- fread("D:/mlfin/mlr3_models/PRE-features.csv")
+# colnames(features) <- gsub(" |-", "_", colnames(features))
+
+# remove columns with lots of NA values
+# keep_cols <- names(which(colMeans(!is.na(features)) > 0.6))
+# print(paste0("Removing columns with many NA values: ", setdiff(colnames(features), keep_cols)))
+# features <- features[, .SD, .SDcols = keep_cols]
+
+# remove missing values
+print(paste0("Number of feature before omiting missing valaues: ", nrow(features)))
+features <- na.omit(features)
+print(paste0("Number of feature after omiting missing valaues: ", nrow(features)))
+
+# important features
+cols_keep <- colnames(features)[9:ncol(features)]
+cols_keep <- setdiff(cols_keep, c("date_features", "fiscalDateEnding", "time", "index", "amc_return", "bmo_return"))
+X <- features[, ..cols_keep]
+X <- X[is.finite(rowSums(X[, .SD, .SDcols = is.numeric], na.rm = TRUE))] # remove inf values
+X <- na.omit(X) # remove NA values
+
+# remov constant and highly correlated values
+remove_cols <- colnames(X)[apply(X, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+X <- as.matrix(X)
+cor_matrix <- cor(X)
+cor_matrix_rm <- cor_matrix                  # Modify correlation matrix
+cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
+diag(cor_matrix_rm) <- 0
+remove_cols <- colnames(X)[apply(cor_matrix_rm, 2, function(x) any(x > 0.97))]
+print(paste0("Removing highly correlated featue (> 0.98): ", remove_cols))
+X <- X[, which(!(colnames(X) %in% remove_cols))]
+
+# f1st
+label_index <- which(colnames(X) == "after_annouoncement_return")
+f1st_fi <- f1st(X[, label_index], X[, -label_index], sub = TRUE)
+cov_index_f1st <- colnames(X[, -ncol(X)])[f1st_fi[[1]][, 1]]
+
+# f3st_1
+f3st_1 <- f3st(X[, label_index], X[, -label_index], m = 1)
+cov_index_f3st_1 <- unique(as.integer(f3st_1[[1]][1, ]))[-1]
+cov_index_f3st_1 <- cov_index_f3st_1[cov_index_f3st_1 != 0]
+cov_index_f3st_1 <- colnames(X[, -ncol(X)])[cov_index_f3st_1]
+
+# interesection of all important vars
+most_important_vars <- intersect(cov_index_f1st, cov_index_f3st_1)
+important_vars <- unique(cov_index_f1st, cov_index_f3st_1)
+
+# test, summaries, analyasis
+DT[, mean(after_annouoncement_return)]
+DT[, median(after_annouoncement_return)]
+DT[, min(after_annouoncement_return)]
+DT[, max(after_annouoncement_return)]
+nrow(DT[after_annouoncement_return >= 0]) / nrow(DT)
+nrow(DT[debtRatio > 0.8])
+DT[debtRatio < -1, mean(after_annouoncement_return)]
+
+# ML apprach
+cols_keep_ml <- c("symbol", "fiscalDateEnding", "date", "time", "after_annouoncement_return", important_vars)
+X <- features[, ..cols_keep_ml]
+
+# TODO ADD THIS INSIDE MLR3 GRAPH
+X[, y := data.table::year(as.Date(date))]
+cols <- c("after_annouoncement_return", important_vars)
+X[, (cols) := lapply(.SD, function(x) {Winsorize(as.numeric(x), probs = c(0.01, 0.99), na.rm = TRUE)}), by = "y", .SDcols = cols]
+X[, y := NULL]
+
+# train / test
+X_train <- X[date <= as.Date("2021-06-01")]
+dim(X_train)
+X_holdout <- X[date > as.Date("2021-06-01")]
+dim(X_holdout)
+
+# define task
+task <- as_task_regr(X_train[, 5:ncol(X_train)], target = "after_annouoncement_return", id ="pre")
+task_holdout <- as_task_regr(X_holdout[, 5:ncol(X_holdout)], target = "after_annouoncement_return", id ="pre")
+
+# indivudal learners for feature importance
+library(rpart.plot)
+learner = lrn("regr.rpart", maxdepth = 4, minbucket = 50, minsplit = 10, cp = 0.001)
+learner$param_set
+task_ <- task$clone()
+learner$train(task_)
+predictins = learner$predict(task_)
+predictins$score(msr("regr.mae"))
+learner$importance()
+rpart_model <- learner$model
+rpart.plot(rpart_model)
+
+
+# learners
+learners = list(
+  ranger = lrn("regr.ranger", id = "ranger"),
+  kknn = lrn("regr.kknn", id = "kknn"),
+  cv_glmnet = lrn("regr.cv_glmnet", id = "cv_glmnet"),
+  xgboost = lrn("regr.xgboost", id = "xgboost")
+)
+
+# create complete grapg
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  # learners
+  learners %>>%
+  po("regravg")
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:100, .(id, class, lower, upper)]
+as.data.table(graph_learner$param_set)[100:190, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  # interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # models
+  ranger.ranger.mtry.ratio = p_dbl(0.2, 1),
+  ranger.ranger.max.depth = p_int(2, 6),
+  kknn.kknn.k = p_int(5, 20),
+  # extratrees.extratrees.ntree = p_int(200, 1000),
+  # extratrees.extratrees.mtry = p_int(5, task_extreme$ncol),
+  # extratrees.extratrees.nodesize = p_int(2, 10),
+  # extratrees.extratrees.numRandomCuts = p_int(2, 5)
+  xgboost.xgboost.nrounds = p_int(100, 5000),
+  xgboost.xgboost.eta = p_dbl(1e-4, 1),
+  xgboost.xgboost.max_depth = p_int(1, 8),
+  xgboost.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  xgboost.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  xgboost.xgboost.lambda = p_dbl(0.1, 1),
+  xgboost.xgboost.gamma = p_dbl(1e-4, 1000),
+  xgboost.xgboost.alpha = p_dbl(1e-4, 1000),
+  xgboost.xgboost.subsample = p_dbl(0.1, 1)
+)
+# plan("multisession", workers = 4L)
+at_regr = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("regr.mae"),
+  search_space = search_space,
+  term_evals = 20
+)
+at_regr$train(task)
+
+# inspect results
+archive <- as.data.table(at_regr$archive)
+setorder(archive, "regr.mae")
+archive
+ggplot(archive, aes(x = ranger.ranger.mtry.ratio, y = regr.mae)) + geom_line()
+ggplot(archive[, mean(regr.mae), by = "ranger.ranger.max.depth"], aes(x = ranger.ranger.max.depth, y = V1)) + geom_line()
+ggplot(archive[, mean(regr.mae), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_regr$predict(task)
+preds$score(msr("regr.rmse"))
+prediciotns <- as.data.table(preds)
+prediciotns <- prediciotns[response < 0]
+nrow(prediciotns)
+prediciotns[, `:=`(truth_01 = ifelse(truth > 0, 1, 0), response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns$truth_01), factor(prediciotns$response_01, levels = c("0", "1")))
+
+# holdout reg
+preds_holdout <- at_regr$predict(task_holdout)
+preds_holdout$score(msrs(c("regr.rmse")))
+prediciotns_reg_holdout <- as.data.table(preds_holdout)
+prediciotns_reg_holdout <- cbind(X_holdout, prediciotns_reg_holdout)
+prediciotns_reg_holdout_sample <- prediciotns_reg_holdout[response < -0.01]
+nrow(prediciotns_reg_holdout_sample)
+prediciotns_reg_holdout_sample[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                      response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns_reg_holdout_sample$truth_01),
+                  factor(prediciotns_reg_holdout_sample$response_01, levels = c("0", "1")))
+prediciotns_reg_holdout_sample[truth_01 == 0, mean(truth)]
+prediciotns_reg_holdout_sample[truth_01 == 1, mean(truth)]
+prediciotns_reg_holdout_sample[truth_01 == 0, median(truth)]
+prediciotns_reg_holdout_sample[truth_01 == 1, median(truth)]
+
+# save data to blob
+qc_backtest <- copy(prediciotns_reg_holdout_sample)
+qc_backtest <- qc_backtest[, .(date, time, symbol, response)]
+# cols <- setdiff(cols_keep, "datetime")
+# qc_backtest[, (cols) := lapply(.SD, shift), .SDcols = cols] # VERY IMPORTANT STEP !
+qc_backtest <- na.omit(qc_backtest)
+qc_backtest <- qc_backtest[, .(symbol = paste0(unlist(symbol), collapse = ", "),
+                               prob1 = paste0(unlist(response), collapse = ","),
+                               time = paste0(unlist(time), collapse = ", ")), by = date]
+setorder(qc_backtest, "date")
+file_name <- "D:/risks/pr/pre.csv"
+fwrite(qc_backtest, file_name, col.names = FALSE, dateTimeAs = "write.csv", sep = ";")
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-backtest")
+storage_upload(cont, file_name, basename(file_name))
+
+
+
+
 # FEATURES ----------------------------------------------------------------
 # prepare arguments for features
 prices_events <- merge(prices, dataset, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
@@ -1072,3 +1461,6 @@ nrow(prediciotns_extreme_holdout_buy)
 prediciotns_extreme_holdout_buy[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
                                        response_01 = ifelse(response > 0, 1, 0))]
 mlr3measures::acc(prediciotns_extreme_holdout$truth, prediciotns_extreme_holdout$response)
+
+
+
diff --git a/pead_v2.R b/pead_v2.R
new file mode 100644
index 0000000..3641d91
--- /dev/null
+++ b/pead_v2.R
@@ -0,0 +1,1452 @@
+library(data.table)
+library(tiledb)
+# Python environment and python modules
+# Instructions: some functions use python modules. Steps to use python include:
+# 1. create new conda environment:
+#    https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html
+#    Choose python 3.8. for example:
+#    conda create -n mlfinlabenv python=3.8
+# 2. Install following packages inside environments
+#    mlfinlab
+#    tsfresh
+#    TSFEL
+# reticulate::use_python("C:/ProgramData/Anaconda3/envs/mlfinlabenv/python.exe", required = TRUE) # check the path on yout system!
+# pd <- reticulate::import("pandas", convert = FALSE) # import pandas
+# mlfinlab <- reticulate::import("mlfinlab", convert = FALSE) # import mlfinlab
+
+
+# SET UP ------------------------------------------------------------------
+# checks
+assert_choice("BLOB-ENDPOINT", names(Sys.getenv()))
+assert_choice("BLOB-KEY", names(Sys.getenv()))
+assert_choice("APIKEY-FMPCLOUD", names(Sys.getenv()))
+
+# global vars
+ENDPOINT = storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+CONT = storage_container(ENDPOINT, "fmpcloud")
+CONTINVESTINGCOM = storage_container(ENDPOINT, "investingcom")
+fmpc_set_token(Sys.getenv("APIKEY-FMPCLOUD"))
+CACHEDIR = "D:/findata" # here define your local folder wher data will be saved
+fred_api_key <- "fb7e8cbac4b84762980f507906176c3c"
+fredr_set_key(fred_api_key)
+
+# parameters
+strategy = "PRE"  # can be PEAD (for predicting post announcement drift) or PRE (for predicting pre announcement)
+use_fundamental_data = TRUE  # should we use fundamental data as features?
+start_holdout_date = as.Date("2021-01-01") # observations after this date belongs to holdout set
+events_data <- "intersection" # one of "fmp", "investingcom", "intersection"
+
+# pins boards
+board_fundamentals <- board_azure(
+  container = storage_container(ENDPOINT, "fundamentals"), # HERE CHANGE WHEN MINUTE DATA !!!
+  path = "",
+  n_processes = 10,
+  versioned = FALSE,
+  cache = NULL
+)
+board_fmp <- board_azure(
+  container = storage_container(ENDPOINT, "fmpcloud"), # HERE CHANGE WHEN MINUTE DATA !!!
+  path = "",
+  n_processes = 10,
+  versioned = FALSE,
+  cache = NULL
+)
+CACHEDIR = "D:/findata" # here define your local folder wher data will be saved
+board_prices <- board_azure(
+  container = storage_container(ENDPOINT, "fmpcloud-daily"),
+  path = "",
+  n_processes = 6L,
+  versioned = FALSE,
+  cache = CACHEDIR
+)
+
+# EVENTS ------------------------------------------------------------------
+# get events data
+events <- pin_read(board_fmp, "EarningAnnouncements")
+events <- as.data.table(events)
+events[, `:=`(date = as.Date(date), symbol = as.character(symbol), time = as.character(time),
+              updatedFromDate = as.Date(updatedFromDate), fiscalDateEnding = as.Date(fiscalDateEnding))]
+
+# coarse filtering
+events <- events[date < Sys.Date()]                 # remove announcements for today
+events <- unique(events, by = c("symbol", "date"))  # remove duplicated symobl / date pair
+if (strategy == "PEAD") {
+  print(paste0("Remove ", sum(is.na(events$eps)), " observations because of missing eps values or ",
+               100 * round(sum(is.na(events$eps)) / nrow(events), 4), "% percent."))
+  events <- na.omit(events, cols = c("eps")) # remove rows with NA for earnings
+}
+
+# keep only usa stocks
+url <- modify_url("https://financialmodelingprep.com/", path = "api/v3/available-traded/list",
+                  query = list(apikey = Sys.getenv("APIKEY-FMPCLOUD") ))
+stocks <- rbindlist(content(GET(url)))
+usa_symbols <- stocks[exchangeShortName %in% c("AMEX", "NASDAQ", "NYSE", "OTC")]
+print(paste0("Remove ", nrow(events[!(symbol %in% usa_symbols$symbo)]),
+             " observations because they are not usa stocks, or ",
+             100 * round(nrow(events[!(symbol %in% usa_symbols$symbo)]) / nrow(events), 4), "% percent."))
+events <- events[symbol %in% usa_symbols$symbo]
+
+# investing.com data
+investingcom_ea <- as.data.table(storage_read_csv(CONTINVESTINGCOM, "EarningAnnouncementsInvestingCom.csv"))
+if (strategy == "PEAD") {
+  investingcom_ea <- na.omit(investingcom_ea, cols = c("eps", "eps_forecast"))
+}
+investingcom_ea <- investingcom_ea[, .(symbol, datetime, eps, eps_forecast, revenue, revenue_forecast, right_time)]
+investingcom_ea[, date_investingcom := as.Date(datetime)]
+setnames(investingcom_ea, colnames(investingcom_ea)[2:6], paste0(colnames(investingcom_ea)[2:6], "_investingcom"))
+
+# merge DT and investing com earnings surprises
+events <- merge(events, investingcom_ea,
+                by.x = c("symbol", "date"),
+                by.y = c("symbol", "date_investingcom"),
+                all.x = TRUE, all.y = FALSE)
+events <- events[date == as.Date(datetime_investingcom)] # keep only observations available in both datasets
+
+# choose events subsample
+if (events_data == "intersection") {
+  # replace FMP cloud data with investing.com data if FMP CLOUD data doesn't exists
+  events[, eps := ifelse(is.na(eps), eps_investingcom, eps)]
+  events[, epsEstimated := ifelse(is.na(epsEstimated), eps_forecast_investingcom, epsEstimated)]
+  events[, revenue := ifelse(is.na(revenue), revenue_investingcom, revenue)]
+  events[, revenueEstimated := ifelse(is.na(revenueEstimated), revenue_forecast_investingcom, revenueEstimated)]
+
+  # check if time are the same
+  events[!is.na(right_time) & right_time == "marketClosed ", right_time := "amc"]
+  events[!is.na(right_time) & right_time == "marketOpen ", right_time := "bmo"]
+  events[, same_announce_time := time == right_time]
+
+  # if both fmp cloud and investing.com data exists keep similar
+  print(paste0("Number of removed observations because of investing.com / FMP cloud disbalance is :",
+               nrow(events[abs(eps - eps_investingcom) > 0.02]), " or ",
+               round(nrow(events[abs(eps - eps_investingcom) > 0.02]) / nrow(events), 4) * 100, "% percent."))
+  events <- events[abs(eps - eps_investingcom) < 0.02] # keep only observations where earnings are very similar
+
+  # if PRE keep only same time
+  if (strategy == "PRE") {
+    # if both fmp cloud and investing.com data exists keep similar
+    print(paste0("Number of removed observations because time of announcements are not same :",
+                 sum(!((events$same_announce_time) == TRUE), na.rm = TRUE), " or ",
+                 round(sum(!((events$same_announce_time) == TRUE), na.rm = TRUE) / nrow(events), 4) * 100, "% percent."))
+    events <- events[events$same_announce_time == TRUE] # keep only observations where earnings are very similar
+  }
+}
+
+# remove duplicated events
+events <- unique(events, by = c("symbol", "date"))
+
+
+# MARKET DATA -------------------------------------------------------------
+# import market data from blob. This takes long time for the firs time
+board <- board_azure(
+  container = storage_container(ENDPOINT, "fmpcloud-daily"),
+  path = "",
+  n_processes = 6L,
+  versioned = FALSE,
+  cache = CACHEDIR
+)
+files_ <- pin_list(board)
+files_ <- setdiff(files_, list.files(CACHEDIR))
+lapply(files_, pin_download, board = board)
+files_ <- pin_list(board)
+files_ <- lapply(file.path(CACHEDIR, files_), list.files, recursive = TRUE, pattern = "\\.csv", full.names = TRUE)
+files_ <- unlist(files_)
+s <- Sys.time()
+prices_dt <- lapply(files_, fread)
+e <- Sys.time()
+e - s
+prices <- prices_dt[vapply(prices_dt, function(x) nrow(x) > 0, FUN.VALUE = logical(1))]
+prices <- rbindlist(prices)
+
+# cleand daily prices
+prices <- prices[symbol %in% unique(events$symbol)] # keep only symbols available in events
+prices[, date := as.Date(date)]
+prices <- prices[open > 0 & high > 0 & low > 0 & close > 0 & adjClose > 0] # remove rows with zero and negative prices
+setorder(prices, "symbol", "date")
+prices[, returns := adjClose   / data.table::shift(adjClose) - 1, by = symbol] # calculate returns
+prices <- prices[returns < 1] # TODO:: better outlier detection mechanism. For now, remove daily returns above 100%
+adjust_cols <- c("open", "high", "low")
+prices[, (adjust_cols) := lapply(.SD, function(x) x * (adjClose / close)), .SDcols = adjust_cols] # adjust open, high and low prices
+prices[, close := adjClose]
+prices <- na.omit(prices[, .(symbol, date, open, high, low, close, volume, returns)])
+prices_n <- prices[, .N, by = symbol]
+prices_n <- prices_n[which(prices_n$N > 700)]  # remove prices with only 700 or less observations
+prices <- prices[symbol %in% prices_n$symbol]
+prices <- prices[date %between% c(min(events$date) - 1100, max(prices$date, na.rm = TRUE))] # keep only data needed for events
+prices <- unique(prices, by = c("symbol", "date")) # remove duplicates if they exists
+
+
+
+# LABELING ----------------------------------------------------------------
+# calculate returns
+prices[, ret_22 := shift(close, -21L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"] # close not shift(close, -1L, "shift") ??
+prices[, ret_44 := shift(close, -43L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+prices[, ret_66 := shift(close, -65L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+prices[, amc_return := shift(open, -1L, "shift") / close - 1, by = "symbol"] # PRE
+prices[, bmo_return := open / shift(close) - 1, by = "symbol"] # PRE
+
+# calculate rolling sd
+prices[, sd_22 := roll::roll_sd(close / shift(close, 1L) - 1, 22), by = "symbol"]
+prices[, sd_44 := roll::roll_sd(close / shift(close, 1L) - 1, 44), by = "symbol"]
+prices[, sd_66 := roll::roll_sd(close / shift(close, 1L) - 1, 66), by = "symbol"]
+
+# calculate spy returns
+spy <- as.data.table(fmpcloudr::fmpc_price_history("SPY", min(prices$date) - 5, Sys.Date()))
+spy[, ret_22_spy := shift(adjClose, -21L, "shift") / shift(adjClose, -1L, "shift") - 1, by = "symbol"]
+spy[, ret_44_spy := shift(adjClose, -43L, "shift") / shift(adjClose, -1L, "shift") - 1, by = "symbol"]
+spy[, ret_66_spy := shift(adjClose, -65L, "shift") / shift(adjClose, -1L, "shift") - 1, by = "symbol"]
+
+# calculate excess returns
+prices <- merge(prices, spy[, .(date, ret_22_spy, ret_44_spy, ret_66_spy)], by = "date", all.x = TRUE, all.y = FALSE)
+prices[, ret_22_excess := ret_22 - ret_22_spy]
+prices[, ret_44_excess := ret_44 - ret_44_spy]
+prices[, ret_66_excess := ret_66 - ret_66_spy]
+prices[, `:=`(ret_22_spy = NULL, ret_44_spy = NULL, ret_66_spy = NULL)]
+setorder(prices, symbol, date)
+
+# calculate standardized returns
+prices[, ret_excess_stand_22 := ret_22_excess / shift(sd_22, -21L), by = "symbol"]
+prices[, ret_excess_stand_44 := ret_44_excess / shift(sd_44, -43L), by = "symbol"]
+prices[, ret_excess_stand_66 := ret_66_excess / shift(sd_66, -65L), by = "symbol"]
+
+# remove unnecesary coluns
+prices[, `:=`(ret_22 = NULL, ret_44 = NULL, ret_66 = NULL,
+              sd_22 = NULL, sd_44 = NULL, sd_66 = NULL,
+              ret_22_excess = NULL, ret_44_excess = NULL, ret_66_excess = NULL)]
+
+
+
+# MERGE MARKET DATA, EVENTS AND LABELS ------------------------------------
+# merge clf_data and labels
+dataset <- merge(events,
+                 prices[, .(symbol, date, ret_excess_stand_22, ret_excess_stand_44, ret_excess_stand_66,
+                            amc_return, bmo_return)],
+                 by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+
+# extreme labeling
+possible_target_vars <- c("ret_excess_stand_22", "ret_excess_stand_44", "ret_excess_stand_66")
+bin_extreme_col_names <- paste0("bin_extreme_", possible_target_vars)
+dataset[, (bin_extreme_col_names) := lapply(.SD, function(x) {
+  y <- cut(x,
+           quantile(x, probs = c(0, 0.2, 0.8, 1), na.rm = TRUE),
+           labels = c(-1, NA, 1),
+           include.lowest = TRUE)
+  as.factor(droplevels(y))
+}), .SDcols = possible_target_vars]
+# around zero labeling
+labeling_around_zero <- function(x) {
+  x_abs <- abs(x)
+  bin <- cut(x_abs, quantile(x_abs, probs = c(0, 0.3333), na.rm = TRUE), labels = 0L, include.lowest = TRUE)
+  max_0 <- max(x[bin == 0], na.rm = TRUE)
+  min_0 <- min(x[bin == 0], na.rm = TRUE)
+  levels(bin) <- c(levels(bin), 1L, -1L)
+  bin[x > max_0] <- as.character(1L)
+  bin[x < min_0] <- as.factor(-1)
+  return(bin)
+}
+bin_aroundzero_col_names <- paste0("bin_aroundzero_", possible_target_vars)
+dataset[, (bin_aroundzero_col_names) := lapply(.SD, labeling_around_zero), .SDcols = possible_target_vars]
+
+# sort dataset
+setorderv(dataset, c("symbol", "date"))
+
+
+
+# PRE ANALYSIS ------------------------------------------------------------
+# select coluimns we need
+data_pre <- dataset[, .(symbol, date, time, amc_return, bmo_return, fiscalDateEnding)]
+data_pre <- na.omit(data_pre)
+data_pre[time == "amc", after_annouoncement_return := amc_return]
+data_pre[time == "bmo", after_annouoncement_return := bmo_return ]
+table(data_pre$time)
+data_pre[symbol == "AMZN"]
+
+# # scrap all data
+# # financial analysis
+# library(findata)
+# fmp = FMP$new()
+# sp500_symobls <- unique(data_pre$symbol)
+# ratios <- lapply(sp500_symobls, fmp$get_financial_metrics, type = "ratios", period = "quarter")
+# ratios <- rbindlist(ratios)
+# pin_write(board_fundamentals, ratios, "ratios", type = "csv")
+# key_metrics <- lapply(sp500_symobls, fmp$get_financial_metrics, type = "key-metrics", period = "quarter")
+# key_metrics <- rbindlist(key_metrics)
+# pin_write(board_fundamentals, key_metrics, "key-metrics", type = "csv")
+# fin_growth <- lapply(sp500_symobls, fmp$get_financial_metrics, type = "financial-growth", period = "quarter")
+# fin_growth <- rbindlist(fin_growth)
+# pin_write(board_fundamentals, fin_growth, "financial-growth-growth", type = "csv")
+# # financial statements
+# get_fis <- function(fi_name = "balance-sheet-statement") {
+#   x <- lapply(sp500_symobls, fmp$get_fi_statement, statement = fi_name, period = "quarter")
+#   x <- rbindlist(x)
+#   pin_write(board_fundamentals, x, fi_name, type = "csv")
+# }
+# get_fis()
+# get_fis("income-statement")
+# get_fis("cash-flow-statement")
+
+# fundamental data
+pin_list(board_fundamentals)
+key_metrics <- as.data.table(pin_read(board_fundamentals, "key-metrics"))
+key_metrics[, price := pfcfRatio * freeCashFlowPerShare]
+key_metrics[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol))]
+fg <- as.data.table(pin_read(board_fundamentals, "financial-growth-growth"))
+fg[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol))]
+is <- as.data.table(pin_read(board_fundamentals, "income-statement"))
+is[, `:=`(date = as.Date(as.character(date)), symbol = as.character(symbol), fillingDate = as.Date(as.character(fillingDate)))]
+bs <- as.data.table(pin_read(board_fundamentals, "balance-sheet-statement"))
+bs[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol),
+          fillingDate = as.Date(as.character(fillingDate)))]
+cf <- as.data.table(pin_read(board_fundamentals, "cash-flow-statement"))
+cf[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol),
+          fillingDate = as.Date(as.character(fillingDate)))]
+ratios <- as.data.table(pin_read(board_fundamentals, "ratios"))
+ratios[, `:=`(period = NULL, date = as.Date(as.character(date)), symbol = as.character(symbol))]
+# merge fundamntal datasets
+fundamentals <- Reduce(function(x, y) merge(x, y, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE),
+                       list(is, bs, cf, key_metrics, fg, ratios))
+setorderv(fundamentals, c("symbol", "fillingDate"))
+fundamentals <- unique(fundamentals, by = c("symbol", "date"))
+# writexl::write_xlsx(fundamentals, "~/fundamentals.xlsx")
+
+# merge date pre and choosen fundamentals
+fund_cols <- c("symbol", "date", colnames(fundamentals)[100:ncol(fundamentals)])
+DT <- merge(data_pre, fundamentals[, ..fund_cols],
+            by.x = c("symbol", "fiscalDateEnding"),
+            by.y = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+DT[, `:=`(link = NULL, finalLink = NULL)]
+
+# remove columns with lots of NA values
+keep_cols <- names(which(colMeans(!is.na(DT)) > 0.5))
+print(paste0("Removing columns with many NA values: ", setdiff(colnames(DT), keep_cols)))
+DT <- DT[, .SD, .SDcols = keep_cols]
+DT <- na.omit(DT)
+
+# add features based on market data
+prices_events <- prices[open > 1e-005 & high > 1e-005 & low > 1e-005 & close > 1e-005 & symbol %in% unique(DT$symbol)]
+prices_events <- merge(prices_events,
+                       DT[, .(symbol, date, time, after_annouoncement_return)],
+                       by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+at_ <- which(!is.na(prices_events$after_annouoncement_return))
+OhlcvInstance = Ohlcv$new(prices_events[, 1:7], date_col = "date")
+lag_ <- ifelse(prices_events$time == "amc", 0, -1)
+at_ohlcv <- at_ + lag_[at_]
+
+# Debug
+head(at_, 20)
+head(lag_[at_], 20)
+head(at_ohlcv, 20)
+
+# Features from OHLLCV
+print("Calculate Ohlcv features.")
+OhlcvFeaturesInit = OhlcvFeatures$new(at = at_ohlcv,
+                                      frequnit = 1,
+                                      windows = c(5, 10, 22, 22 * 3, 22 * 6, 22 * 12),
+                                      quantile_divergence_window =  c(22, 22*3, 22*6, 22*12))
+OhlcvFeaturesSet = OhlcvFeaturesInit$get_ohlcv_features(OhlcvInstance)
+setorderv(OhlcvFeaturesSet, c("symbol", "date"))
+
+# DEBUG
+tail(dataset[, .(symbol, date, time)], 10)
+head(OhlcvFeaturesSet[symbol == "ZYXI", .(symbol, date)], 10)
+
+# Exuber features
+print("Calculate Exuber features.")
+s <- Sys.time()
+RollingExuberInit = RollingExuber$new(windows = c(200, 600), workers = 4L, at = at_,
+                                      lag = lag_[at_] * -1,
+                                      na_pad = TRUE,
+                                      simplify = FALSE,
+                                      exuber_lag = 1L)
+RollingExuberFeatures = RollingExuberInit$get_rolling_features(OhlcvInstance)
+e <- Sys.time()
+e - s
+gc()
+
+# DEBUG
+tail(dataset[, .(symbol, date, time)], 10)
+tail(RollingExuberFeatures[symbol == "ZYXI", .(symbol, date)], 10)
+
+# Forecast Features
+print("Calculate AutoArima features.")
+RollingForecatsInstance = RollingForecats$new(windows = c(100, 252),
+                                              workers = 8L,
+                                              lag = lag_[at_] * -1,
+                                              at = at_,
+                                              na_pad = TRUE,
+                                              simplify = FALSE,
+                                              forecast_type = "autoarima",
+                                              h = 22)
+RollingForecatsAutoarimaFeatures = RollingForecatsInstance$get_rolling_features(OhlcvInstance)
+print("Calculate Nnetar features.")
+gc()
+
+# merge all features test
+cols_ohlcv <- c("symbol", "date", colnames(OhlcvFeaturesSet)[9:ncol(OhlcvFeaturesSet)])
+features <- Reduce(function(x, y) merge(x, y, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE),
+                   list(OhlcvFeaturesSet[, ..cols_ohlcv], RollingExuberFeatures,
+                        RollingForecatsAutoarimaFeatures))
+
+# DEBUG
+features[, 1:5]
+DT[, 1:5]
+
+# merge DT and features
+features[, date_features := date]
+features <- features[DT, on = c("symbol", "date"), roll = +Inf]
+
+# DEBUG
+features[, .(symbol, date, date_features)]
+tail(features[, .(symbol, date, date_features)], 10)
+
+# save data with fundamentals
+setorderv(features, c("symbol", "date"))
+print("Saving features with fundamentals to blob.")
+fwrite(features, "D:/mlfin/mlr3_models/PRE-features.csv")
+# features <- fread("D:/mlfin/mlr3_models/PRE-features.csv")
+# colnames(features) <- gsub(" |-", "_", colnames(features))
+
+# remove columns with lots of NA values
+# keep_cols <- names(which(colMeans(!is.na(features)) > 0.6))
+# print(paste0("Removing columns with many NA values: ", setdiff(colnames(features), keep_cols)))
+# features <- features[, .SD, .SDcols = keep_cols]
+
+# remove missing values
+print(paste0("Number of feature before omiting missing valaues: ", nrow(features)))
+features <- na.omit(features)
+print(paste0("Number of feature after omiting missing valaues: ", nrow(features)))
+
+# important features
+cols_keep <- colnames(features)[9:ncol(features)]
+cols_keep <- setdiff(cols_keep, c("date_features", "fiscalDateEnding", "time", "index", "amc_return", "bmo_return"))
+X <- features[, ..cols_keep]
+X <- X[is.finite(rowSums(X[, .SD, .SDcols = is.numeric], na.rm = TRUE))] # remove inf values
+X <- na.omit(X) # remove NA values
+
+# remov constant and highly correlated values
+remove_cols <- colnames(X)[apply(X, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+X <- as.matrix(X)
+cor_matrix <- cor(X)
+cor_matrix_rm <- cor_matrix                  # Modify correlation matrix
+cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
+diag(cor_matrix_rm) <- 0
+remove_cols <- colnames(X)[apply(cor_matrix_rm, 2, function(x) any(x > 0.97))]
+print(paste0("Removing highly correlated featue (> 0.98): ", remove_cols))
+X <- X[, which(!(colnames(X) %in% remove_cols))]
+
+# f1st
+label_index <- which(colnames(X) == "after_annouoncement_return")
+f1st_fi <- f1st(X[, label_index], X[, -label_index], sub = TRUE)
+cov_index_f1st <- colnames(X[, -ncol(X)])[f1st_fi[[1]][, 1]]
+
+# f3st_1
+f3st_1 <- f3st(X[, label_index], X[, -label_index], m = 1)
+cov_index_f3st_1 <- unique(as.integer(f3st_1[[1]][1, ]))[-1]
+cov_index_f3st_1 <- cov_index_f3st_1[cov_index_f3st_1 != 0]
+cov_index_f3st_1 <- colnames(X[, -ncol(X)])[cov_index_f3st_1]
+
+# interesection of all important vars
+most_important_vars <- intersect(cov_index_f1st, cov_index_f3st_1)
+important_vars <- unique(cov_index_f1st, cov_index_f3st_1)
+
+# test, summaries, analyasis
+DT[, mean(after_annouoncement_return)]
+DT[, median(after_annouoncement_return)]
+DT[, min(after_annouoncement_return)]
+DT[, max(after_annouoncement_return)]
+nrow(DT[after_annouoncement_return >= 0]) / nrow(DT)
+nrow(DT[debtRatio > 0.8])
+DT[debtRatio < -1, mean(after_annouoncement_return)]
+
+# ML apprach
+cols_keep_ml <- c("symbol", "fiscalDateEnding", "date", "time", "after_annouoncement_return", important_vars)
+X <- features[, ..cols_keep_ml]
+
+# TODO ADD THIS INSIDE MLR3 GRAPH
+X[, y := data.table::year(as.Date(date))]
+cols <- c("after_annouoncement_return", important_vars)
+X[, (cols) := lapply(.SD, function(x) {Winsorize(as.numeric(x), probs = c(0.01, 0.99), na.rm = TRUE)}), by = "y", .SDcols = cols]
+X[, y := NULL]
+
+# train / test
+X_train <- X[date <= as.Date("2021-06-01")]
+dim(X_train)
+X_holdout <- X[date > as.Date("2021-06-01")]
+dim(X_holdout)
+
+# define task
+task <- as_task_regr(X_train[, 5:ncol(X_train)], target = "after_annouoncement_return", id ="pre")
+task_holdout <- as_task_regr(X_holdout[, 5:ncol(X_holdout)], target = "after_annouoncement_return", id ="pre")
+
+# indivudal learners for feature importance
+library(rpart.plot)
+learner = lrn("regr.rpart", maxdepth = 4, minbucket = 50, minsplit = 10, cp = 0.001)
+learner$param_set
+task_ <- task$clone()
+learner$train(task_)
+predictins = learner$predict(task_)
+predictins$score(msr("regr.mae"))
+learner$importance()
+rpart_model <- learner$model
+rpart.plot(rpart_model)
+
+
+# learners
+learners = list(
+  ranger = lrn("regr.ranger", id = "ranger"),
+  kknn = lrn("regr.kknn", id = "kknn"),
+  cv_glmnet = lrn("regr.cv_glmnet", id = "cv_glmnet"),
+  xgboost = lrn("regr.xgboost", id = "xgboost")
+)
+
+# create complete grapg
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  # learners
+  learners %>>%
+  po("regravg")
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:100, .(id, class, lower, upper)]
+as.data.table(graph_learner$param_set)[100:190, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  # interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # models
+  ranger.ranger.mtry.ratio = p_dbl(0.2, 1),
+  ranger.ranger.max.depth = p_int(2, 6),
+  kknn.kknn.k = p_int(5, 20),
+  # extratrees.extratrees.ntree = p_int(200, 1000),
+  # extratrees.extratrees.mtry = p_int(5, task_extreme$ncol),
+  # extratrees.extratrees.nodesize = p_int(2, 10),
+  # extratrees.extratrees.numRandomCuts = p_int(2, 5)
+  xgboost.xgboost.nrounds = p_int(100, 5000),
+  xgboost.xgboost.eta = p_dbl(1e-4, 1),
+  xgboost.xgboost.max_depth = p_int(1, 8),
+  xgboost.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  xgboost.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  xgboost.xgboost.lambda = p_dbl(0.1, 1),
+  xgboost.xgboost.gamma = p_dbl(1e-4, 1000),
+  xgboost.xgboost.alpha = p_dbl(1e-4, 1000),
+  xgboost.xgboost.subsample = p_dbl(0.1, 1)
+)
+# plan("multisession", workers = 4L)
+at_regr = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("regr.mae"),
+  search_space = search_space,
+  term_evals = 20
+)
+at_regr$train(task)
+
+# inspect results
+archive <- as.data.table(at_regr$archive)
+setorder(archive, "regr.mae")
+archive
+ggplot(archive, aes(x = ranger.ranger.mtry.ratio, y = regr.mae)) + geom_line()
+ggplot(archive[, mean(regr.mae), by = "ranger.ranger.max.depth"], aes(x = ranger.ranger.max.depth, y = V1)) + geom_line()
+ggplot(archive[, mean(regr.mae), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_regr$predict(task)
+preds$score(msr("regr.rmse"))
+prediciotns <- as.data.table(preds)
+prediciotns <- prediciotns[response < 0]
+nrow(prediciotns)
+prediciotns[, `:=`(truth_01 = ifelse(truth > 0, 1, 0), response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns$truth_01), factor(prediciotns$response_01, levels = c("0", "1")))
+
+# holdout reg
+preds_holdout <- at_regr$predict(task_holdout)
+preds_holdout$score(msrs(c("regr.rmse")))
+prediciotns_reg_holdout <- as.data.table(preds_holdout)
+prediciotns_reg_holdout <- cbind(X_holdout, prediciotns_reg_holdout)
+prediciotns_reg_holdout_sample <- prediciotns_reg_holdout[response < -0.01]
+nrow(prediciotns_reg_holdout_sample)
+prediciotns_reg_holdout_sample[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                      response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns_reg_holdout_sample$truth_01),
+                  factor(prediciotns_reg_holdout_sample$response_01, levels = c("0", "1")))
+prediciotns_reg_holdout_sample[truth_01 == 0, mean(truth)]
+prediciotns_reg_holdout_sample[truth_01 == 1, mean(truth)]
+prediciotns_reg_holdout_sample[truth_01 == 0, median(truth)]
+prediciotns_reg_holdout_sample[truth_01 == 1, median(truth)]
+
+# save data to blob
+qc_backtest <- copy(prediciotns_reg_holdout_sample)
+qc_backtest <- qc_backtest[, .(date, time, symbol, response)]
+# cols <- setdiff(cols_keep, "datetime")
+# qc_backtest[, (cols) := lapply(.SD, shift), .SDcols = cols] # VERY IMPORTANT STEP !
+qc_backtest <- na.omit(qc_backtest)
+qc_backtest <- qc_backtest[, .(symbol = paste0(unlist(symbol), collapse = ", "),
+                               prob1 = paste0(unlist(response), collapse = ","),
+                               time = paste0(unlist(time), collapse = ", ")), by = date]
+setorder(qc_backtest, "date")
+file_name <- "D:/risks/pr/pre.csv"
+fwrite(qc_backtest, file_name, col.names = FALSE, dateTimeAs = "write.csv", sep = ";")
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-backtest")
+storage_upload(cont, file_name, basename(file_name))
+
+
+
+
+# FEATURES ----------------------------------------------------------------
+# prepare arguments for features
+prices_events <- merge(prices, dataset, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+at_ <- which(!is.na(prices_events$eps))
+# fwrite(prices_dt[, 1:7], "D:/temp/PEAD-testdata.csv") # FOR TET IN FINFEATURES
+# fwrite(as.data.frame(at_), "D:/temp/PEAD-at.csv") # FOR TET IN FINFEATURES
+OhlcvInstance = Ohlcv$new(prices_dt[, 1:7], date_col = "date")
+if (strategy == "PEAD") {
+  lag_ <- -1L
+} else {
+  lag_ <- 1L
+  # ako je red u events amc. label je open_t+1 / close_t; lag je -1L
+  # ako je red u events bmo. label je open_t / close_t-1; lag je -2L
+}
+
+# Features from OHLLCV
+print("Calculate Ohlcv features.")
+OhlcvFeaturesInit = OhlcvFeatures$new(windows = c(5, 10, 22, 22 * 3, 22 * 6, 22 * 12),
+                                      quantile_divergence_window =  c(22, 22*3, 22*6, 22*12))
+OhlcvFeaturesSet = OhlcvFeaturesInit$get_ohlcv_features(OhlcvInstance)
+OhlcvFeaturesSetSample <- OhlcvFeaturesSet[at_ - lag_]
+setorderv(OhlcvFeaturesSetSample, c("symbol", "date"))
+############ DEBUG ##############
+head(dataset[, .(symbol, date)])
+head(OhlcvFeaturesSetSample[symbol == "AA", .(symbol, date)])
+############ DEBUG ##############
+
+# BidAsk features
+print("Calculate BidAsk features.")
+RollingBidAskInstance <- RollingBidAsk$new(windows = c(5, 22),
+                                           workers = 8L,
+                                           at = at_,
+                                           lag = lag_,
+                                           na_pad = TRUE,
+                                           simplify = FALSE)
+RollingBidAskFeatures = RollingBidAskInstance$get_rolling_features(OhlcvInstance)
+############ DEBUG ##############
+head(dataset[, .(symbol, date)])
+head(RollingBidAskFeatures[symbol == "AA", .(symbol, date)])
+############ DEBUG ##############
+
+gc()
+# BackCUSUM features
+print("Calculate BackCUSUM features.")
+RollingBackcusumInit = RollingBackcusum$new(windows = c(22 * 3),
+                                            workers = 8L,
+                                            at = at_,
+                                            lag = lag_,
+                                            na_pad = TRUE,
+                                            simplify = FALSE)
+RollingBackCusumFeatures = RollingBackcusumInit$get_rolling_features(OhlcvInstance)
+gc()
+# Exuber features
+print("Calculate Exuber features.")
+RollingExuberInit = RollingExuber$new(windows = c(300, 600),
+                                      workers = 8L,
+                                      at = at_,
+                                      lag = lag_,
+                                      na_pad = TRUE,
+                                      simplify = FALSE,
+                                      exuber_lag = 1L)
+RollingExuberFeatures = RollingExuberInit$get_rolling_features(OhlcvInstance)
+head(dataset[, .(symbol, date)])
+head(RollingExuberFeatures[symbol == "A", .(symbol, date)])
+gc()
+# Forecast Features
+print("Calculate AutoArima features.")
+RollingForecatsInstance = RollingForecats$new(windows = c(100, 252),
+                                              workers = 8L,
+                                              lag = lag_,
+                                              at = at_,
+                                              na_pad = TRUE,
+                                              simplify = FALSE,
+                                              forecast_type = "autoarima",
+                                              h = 22)
+RollingForecatsAutoarimaFeatures = RollingForecatsInstance$get_rolling_features(OhlcvInstance)
+print("Calculate Nnetar features.")
+gc()
+RollingForecatsInstance = RollingForecats$new(windows = c(200),
+                                              workers = 8L,
+                                              lag = lag_,
+                                              at = at_,
+                                              na_pad = TRUE,
+                                              simplify = FALSE,
+                                              forecast_type = "nnetar",
+                                              h = 22)
+RollingForecatNnetarFeatures = RollingForecatsInstance$get_rolling_features(OhlcvInstance)
+gc()
+# GAS
+print("Calculate GAS features.")
+RollingGasInit = RollingGas$new(windows = c(150),
+                                workers = 8L,
+                                at = at_,
+                                lag = lag_,
+                                na_pad = TRUE,
+                                simplify = FALSE,
+                                gas_dist = "sstd",
+                                gas_scaling = "Identity",
+                                prediction_horizont = 10)
+RollingGasFeatures = RollingGasInit$get_rolling_features(OhlcvInstance)
+gc()
+# Gpd features
+print("Calculate Gpd features.")
+RollingGpdInit = RollingGpd$new(windows = c(22 * 3, 22 * 6),
+                                workers = 8L,
+                                at = at_,
+                                lag = lag_,
+                                na_pad = TRUE,
+                                simplify = FALSE,
+                                threshold = 0.05)
+RollingGpdFeatures = RollingGpdInit$get_rolling_features(OhlcvInstance)
+gc()
+# theft catch22 features
+print("Calculate Catch22 features.")
+RollingTheftInit = RollingTheft$new(windows = c(5, 22, 22 * 3, 22 * 12),
+                                    workers = 8L,
+                                    at = at_,
+                                    lag = lag_,
+                                    na_pad = TRUE,
+                                    simplify = FALSE,
+                                    features_set = "catch22")
+RollingTheftCatch22Features = RollingTheftInit$get_rolling_features(OhlcvInstance)
+gc()
+# theft feasts features
+print("Calculate feasts features.")
+RollingTheftInit = RollingTheft$new(windows = c(22 * 3, 22 * 12),
+                                    workers = 8L,
+                                    at = at_,
+                                    lag = lag_,
+                                    na_pad = TRUE,
+                                    simplify = FALSE,
+                                    features_set = "feasts")
+RollingTheftFeastsFatures = RollingTheftInit$get_rolling_features(OhlcvInstance)
+gc()
+# theft tsfel features NO MESSAGES  !!!!
+print("Calculate Tsfeatures features.")
+RollingTheftInit = RollingTheft$new(windows = c(22 * 3, 22 * 12),
+                                    workers = 1L,
+                                    at = at_,
+                                    lag = lag_,
+                                    na_pad = TRUE,
+                                    simplify = FALSE,
+                                    features_set = "tsfel")
+RollingTheftTsfelFeatures = suppressMessages(RollingTheftInit$get_rolling_features(OhlcvInstance))
+gc()
+# theft tsfeatures features
+print("Calculate tsfeatures features.")
+RollingTsfeaturesInit = RollingTsfeatures$new(windows = c(22 * 3, 22 * 6),
+                                              workers = 8L,
+                                              at = at_,
+                                              lag = lag_,
+                                              na_pad = TRUE,
+                                              simplify = FALSE)
+RollingTsfeaturesFeatures = RollingTsfeaturesInit$get_rolling_features(OhlcvInstance)
+gc()
+
+
+# merge all features test
+cols_ohlcv <- c("symbol", "date", colnames(OhlcvFeaturesSetSample)[15:ncol(OhlcvFeaturesSetSample)])
+features <- Reduce(function(x, y) merge(x, y, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE),
+                   list(OhlcvFeaturesSetSample[, ..cols_ohlcv], RollingBidAskFeatures,
+                        RollingBackCusumFeatures, RollingExuberFeatures,
+                        RollingForecatsAutoarimaFeatures, RollingGasFeatures, RollingGpdFeatures,
+                        RollingTheftCatch22Features, RollingTheftFeastsFatures, RollingTheftTsfelFeatures,
+                        RollingTsfeaturesFeatures))
+
+# merge OHLCV and events
+features[, trading_date_after_event := date]
+features <- features[dataset, on = c("symbol", "date"), roll = -Inf]
+features[, .(symbol, date, trading_date_after_event)]
+colnames(features)
+
+# actual vs estimated
+features[, `:=`(
+  eps_diff = (eps - epsEstimated + 0.0001) / sd(eps - epsEstimated + 0.0001)
+  # rev_diff = (revenue - revenueEstimated) / close
+)]
+
+# save features to Azure blob
+setorderv(features, c("symbol", "date"))
+# save_blob_files(features, paste0("nofund-", file_name), "features")
+
+# fundamental data
+reports <- fread("D:/fundamental_data/pl.csv")
+reports[, `:=`(date = as.Date(date),
+               fillingDate = as.Date(fillingDate),
+               acceptedDateTime = as.POSIXct(acceptedDate, format = "%Y-%m-%d %H:%M:%S"),
+               acceptedDate = as.Date(acceptedDate, format = "%Y-%m-%d %H:%M:%S"))]
+fin_growth <- fread("D:/fundamental_data/fin_growth.csv")
+fin_growth[, date := as.Date(date)]
+fin_ratios <- fread("D:/fundamental_data/key_metrics.csv")
+fin_ratios[, date := as.Date(date)]
+
+# merge all fundamental data
+fundamentals <- merge(reports, fin_growth, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+fundamentals <- merge(fundamentals, fin_ratios, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+fundamentals <- fundamentals[date > as.Date("1998-01-01")]
+fundamentals[, acceptedDateFundamentals := acceptedDate]
+data.table::setnames(fundamentals, "date", "fundamental_date")
+fundamentals[, fundamental_acceptedDate := acceptedDate]
+str(fundamentals)
+
+# merge features and fundamental data
+features <- merge(features, fundamentals, by.x = c("symbol", "date"),
+                  by.y = c("symbol", "acceptedDate"), all.x = TRUE, all.y = FALSE)
+features[symbol == "AAPL", .(symbol, fundamental_date, date, fundamental_acceptedDate)]
+
+# mannually for naow
+features$priceToSalesRatio <- as.numeric(features$priceToSalesRatio)
+features$pfcfRatio <- as.numeric(features$pfcfRatio)
+features$evToSales <- as.numeric(features$evToSales)
+features$enterpriseValueOverEBITDA <- as.numeric(features$enterpriseValueOverEBITDA)
+features$evToFreeCashFlow <- as.numeric(features$evToFreeCashFlow)
+features$netDebtToEBITDA <- as.numeric(features$netDebtToEBITDA)
+features[, grep("^lm_", colnames(features)) := NULL]
+features[, grep("changes", colnames(features)) := NULL]
+
+# save data with fundamentals
+setorderv(features, c("symbol", "date"))
+print("Saving features with fundamentals to blob.")
+# fwrite(features, "D:/mlfin/mlr3_models/PEAD-features.csv")
+# features <- fread("D:/mlfin/mlr3_models/PEAD-features.csv")
+# colnames(features) <- gsub(" |-", "_", colnames(features))
+
+
+# FEATURES SPACE ----------------------------------------------------------
+# use fundamnetal ratios or not
+if (use_fundamental_data) {
+  features <- features[!is.na(epsgrowth)]
+} else {
+  keep_cols <- colnames(features)[1:which(colnames(features) == "eps_diff")]
+  features <- features[, ..keep_cols]
+  colnames(features) <- gsub("\\.x", "", colnames(features))
+}
+
+# features space from features raw
+cols_remove <- c("trading_date_after_event", "time", "datetime_investingcom",
+                 "eps_investingcom", "eps_forecast_investingcom", "revenue_investingcom",
+                 "revenue_forecast_investingcom", "time_dummy",
+                 "trading_date_after_event", "fundamental_date", "cik", "link", "finalLink",
+                 "fillingDate", "calendarYear", "eps.y", "revenue.y", "period.x", "period.y",
+                 "acceptedDateTime", "acceptedDateFundamentals", "reportedCurrency",
+                 "fundamental_acceptedDate", "period", "right_time")
+cols_non_features <- c("symbol", "date", "time", "right_time",
+                       "ret_excess_stand_22", "ret_excess_stand_44", "ret_excess_stand_66",
+                       colnames(features)[grep("aroundzero", colnames(features))],
+                       colnames(features)[grep("extreme", colnames(features))])
+cols_features <- setdiff(colnames(features), c(cols_remove, cols_non_features))
+cols <- c(cols_non_features, cols_features)
+features <- features[, .SD, .SDcols = cols]
+
+# add fred data
+get_fread_data <- function(id = "VIXCLS") {
+  data_ <- fredr(series_id = id, observation_start = min(features$date), observation_end = Sys.Date())
+  data_ <- as.data.table(data_)
+  data_ <- data_[, .(date, value)]
+  colnames(data_)[2] <- id
+  return(data_)
+}
+vix <- get_fread_data("VIXCLS")
+sp500 <- get_fread_data("SP500")
+# t10 <- get_fread_data("T10Y2Y")
+# ffr <- get_fread_data("DFF")
+# oilprices <- get_fread_data("DCOILWTICO")
+fread_features <- Reduce(function(x, y) merge(x, y, by = c("date"), all.x = TRUE, all.y = FALSE),
+                         list(vix, sp500))
+fread_features[, SP500_ret_month := SP500 / shift(SP500, 22) - 1]
+fread_features[, SP500_ret_year := SP500 / shift(SP500, 252) - 1]
+fread_features[, SP500_ret_week := SP500 / shift(SP500, 5) - 1]
+fread_features[, SP500 := NULL]
+features <- merge(features, fread_features, by = "date", all.x = TRUE, all.y = FALSE)
+
+
+
+# CLEAN DATA --------------------------------------------------------------
+# convert columns to numeric. This is important only if we import existing features
+clf_data <- copy(features)
+chr_to_num_cols <- colnames(clf_data[, ..cols_features][, .SD, .SDcols = is.character])
+clf_data <- clf_data[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+int_to_num_cols <- colnames(clf_data[, ..cols_features][, .SD, .SDcols = is.integer])
+clf_data <- clf_data[, (int_to_num_cols) := lapply(.SD, as.numeric), .SDcols = int_to_num_cols]
+
+# remove columns with many Inf
+# is.infinite.data.frame <- function(x) do.call(cbind, lapply(x, is.infinite))
+keep_cols <- names(which(colMeans(!is.infinite(as.data.frame(clf_data))) > 0.9))
+print(paste0("Removing columns with Inf values: ", setdiff(colnames(clf_data), keep_cols)))
+clf_data <- clf_data[, .SD, .SDcols = keep_cols]
+
+# remove rows with Inf values
+clf_data <- clf_data[is.finite(rowSums(clf_data[, .SD, .SDcols = is.numeric], na.rm = TRUE))]
+nrow(features)
+nrow(clf_data)
+
+# remove columns with lots of NA values
+keep_cols <- names(which(colMeans(!is.na(features)) > 0.9))
+keep_cols <- c(keep_cols, "bin_extreme_ret_excess_stand_22", "bin_extreme_ret_excess_stand_44", "bin_extreme_ret_excess_stand_66")
+print(paste0("Removing columns with many NA values: ", setdiff(colnames(features), keep_cols)))
+clf_data <- features[, .SD, .SDcols = keep_cols]
+
+# convert logical to integer
+chr_to_num_cols <- setdiff(colnames(clf_data[, .SD, .SDcols = is.character]), c("symbol", "time", "right_time"))
+clf_data <- clf_data[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+
+
+# INSPECT FEATURES --------------------------------------------------------
+# select features vector
+feature_cols <- intersect(cols_features, colnames(clf_data))
+
+# remove NA values
+clf_data <- na.omit(clf_data, cols = feature_cols)
+
+# remove constant columns
+features_ <- clf_data[, ..feature_cols]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+feature_cols <- setdiff(feature_cols, remove_cols)
+
+# remove highly correlated features
+features_ <- clf_data[, ..feature_cols]
+cor_matrix <- cor(features_)
+cor_matrix_rm <- cor_matrix                  # Modify correlation matrix
+cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
+diag(cor_matrix_rm) <- 0
+remove_cols <- colnames(features_)[apply(cor_matrix_rm, 2, function(x) any(x > 0.98))]
+print(paste0("Removing highly correlated featue (> 0.98): ", remove_cols))
+feature_cols <- setdiff(feature_cols, remove_cols)
+
+# TODO ADD THIS INSIDE MLR3 GRAPH
+clf_data[, y := data.table::year(as.Date(date))]
+cols <- c(feature_cols, "y")
+clf_data[, (cols) := lapply(.SD, function(x) {Winsorize(as.numeric(x), probs = c(0.01, 0.99), na.rm = TRUE)}), by = "y", .SDcols = cols]
+clf_data[, y := NULL]
+
+# remove constant columns
+features_ <- clf_data[, ..feature_cols]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+feature_cols <- setdiff(feature_cols, remove_cols)
+
+# choose label
+print(paste0("Choose among this features: ", colnames(clf_data)[grep("^ret_excess_stand", colnames(clf_data))]))
+LABEL = "ret_excess_stand_22"
+
+
+# FEATURE SELECTION -------------------------------------------------------
+
+# gausscov features selection exmaple from package
+# library(gausscov)
+# data(boston)
+# bostint <- fgeninter(boston[,1:13],2)[[1]]
+# dim(bostint)
+# a<-f1st(boston[,14],bostint,kmn=10,sub=TRUE)
+
+# another criterion
+# data(leukemia)
+# covch=c(2.023725,1182,1219,2888,0)
+# ind<-c(1182,1219,2888,0,0,0,0,0,0)
+# ind<-matrix(ind,ncol=3)
+# m<-3
+# a<-f3sti(leukemia[[1]],leukemia[[2]],covch,ind,m)
+
+# my try
+cols_keep <- c(feature_cols, LABEL)
+X <- clf_data[, ..cols_keep]
+X <- na.omit(X)
+X <- as.matrix(X)
+# X <- model.matrix(ret_44_excess ~ .^2, data = X)
+
+# f1st
+f1st_fi <- f1st(X[, ncol(X)], X[, -ncol(X)], kmn = 20, sub = TRUE)
+cov_index_f1st <- colnames(X[, -ncol(X)])[f1st_fi[[1]][, 1]]
+
+# f3st_1
+f3st_1 <- f3st(X[, ncol(X)], X[, -ncol(X)], m = 1)
+cov_index_f3st_1 <- unique(as.integer(f3st_1[[1]][1, ]))[-1]
+cov_index_f3st_1 <- cov_index_f3st_1[cov_index_f3st_1 != 0]
+cov_index_f3st_1 <- colnames(X[, -ncol(X)])[cov_index_f3st_1]
+
+# interesection of all important vars
+most_important_vars <- intersect(cov_index_f1st, cov_index_f3st_1)
+important_vars <- c(cov_index_f1st, cov_index_f3st_1)
+
+
+# DEFINE TASKS ------------------------------------------------------------
+# train/test and holdout set
+holdout_ids <- which(clf_data$date > start_holdout_date)
+X_model <- clf_data[-holdout_ids, ]
+X_holdout <- clf_data[holdout_ids, ] # TODO SAVE THIS FOR QUANTCONNECT BACKTESTING
+
+# select only labels and features
+labels <- colnames(X_model)[grep(LABEL, colnames(X_model))]
+X_model <- X_model[, .SD, .SDcols = c("symbol", "date", feature_cols, labels)]
+X_holdout <- X_holdout[, .SD, .SDcols = c("symbol", "date", feature_cols, labels)]
+
+# task with extreme bins
+X_model_ <- X_model[get(labels[3]) %in% c(-1, 1)]
+# X_model_[, labels[3] := droplevels(X_model_[, get(labels[3])])]
+X_holdout_ <- X_holdout[get(labels[3]) %in% c(-1, 1)]
+# X_holdout_[, labels[3] := droplevels(X_holdout_[, get(labels[3])])]
+X_model_$bin_extreme_ret_excess_stand_22 <- as.factor(X_model_$bin_extreme_ret_excess_stand_22)
+X_holdout_$bin_extreme_ret_excess_stand_22 <- as.factor(X_holdout_$bin_extreme_ret_excess_stand_22)
+task_extreme <- as_task_classif(X_model_[, .SD, .SDcols = !c("symbol","date", labels[1:2])],
+                                id = "extreme", target = labels[3], positive = "1")
+task_extreme_holdout <- as_task_classif(X_holdout_[, .SD, .SDcols = !c("symbol","date", labels[1:2])],
+                                        id = "extreme_holdout", target = labels[3], positive = "1")
+
+# task with aroundzero bins
+X_model$bin_aroundzero_ret_excess_stand_22 <- as.factor(X_model$bin_aroundzero_ret_excess_stand_22)
+X_holdout$bin_aroundzero_ret_excess_stand_22 <- as.factor(X_holdout$bin_aroundzero_ret_excess_stand_22)
+task_aroundzero <- as_task_classif(X_model[, .SD, .SDcols = !c("symbol","date", labels[c(1, 3)])],
+                                   id = "aroundzero", target = labels[2])
+task_aroundzero_holdout <- as_task_classif(X_holdout[, .SD, .SDcols = !c("symbol","date", labels[c(1, 3)])],
+                                           id = "aroundzero_holdout", target = labels[2])
+
+# task for regression
+task_reg <- as_task_regr(X_model[, .SD, .SDcols = !c("symbol","date", labels[2:3])], id = "reg", target = labels[1])
+task_reg_holdout <- as_task_regr(X_holdout[, .SD, .SDcols = !c("symbol","date", labels[2:3])], id = "reg_holdout", target = labels[1])
+
+
+
+# FEATURE SELECTION (TEST) ------------------------------------------------
+# select features
+# important_vars <- setdiff(important_vars, "TSFEL_0_Histogram_7_132")
+task_extreme$select(most_important_vars)
+task_aroundzero$select(most_important_vars)
+task_reg$select(most_important_vars)
+task_extreme_holdout$select(most_important_vars)
+task_aroundzero_holdout$select(most_important_vars)
+task_reg_holdout$select(most_important_vars)
+
+
+
+# DESCRIPTIVE ANALYSIS ----------------------------------------------------
+# dependent variable
+data_ <- task_reg$data()
+dim(data_)
+skimr::skim(data_$ret_excess_stand_66)
+
+# rpart tree
+# minsplit [2,128]
+# minbucket [1,64]
+# cp  [1e−04,0.1]
+# cp [1e−04,1]
+# maxdepth [1,30]
+# minbucket [1,100]
+# minsplit [1,100]
+library(rpart.plot)
+learner = lrn("classif.rpart", maxdepth = 4, predict_type = "prob", minbucket = 50, minsplit = 10, cp = 0.001)
+learner$param_set
+task_ <- task_extreme$clone()
+learner$train(task_)
+predictins = learner$predict(task_)
+predictins$score(msr("classif.acc"))
+learner$importance()
+rpart_model <- learner$model
+rpart.plot(rpart_model)
+
+
+
+# CLASSIFICATION AUTOML ---------------------------------------------------
+# learners
+learners = list(
+  ranger = lrn("classif.ranger", predict_type = "prob", id = "ranger"),
+  # log_reg = lrn("classif.log_reg", predict_type = "prob", id = "log_reg"),
+  kknn = lrn("classif.kknn", predict_type = "prob", id = "kknn"),
+  # extratrees = lrn("classif.extratrees", predict_type = "prob", id = "extratrees"),
+  cv_glmnet = lrn("classif.cv_glmnet", predict_type = "prob", id = "cv_glmnet"),
+  xgboost = lrn("classif.xgboost", predict_type = "prob", id = "xgboost")
+)
+# create graph from list of learners
+# choices = c("ranger", "log_reg", "kknn")
+# learners = po("branch", choices, id = "branch_learners") %>>%
+#   gunion(learners_l) %>>%
+#   po("unbranch", choices, id = "unbranch_learners")
+
+# create complete grapg
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # modelmatrix
+  # po("branch", options = c("nop_filter", "modelmatrix"), id = "interaction_branch") %>>%
+  # gunion(list(po("nop", id = "nop_filter"), po("modelmatrix", formula = ~ . ^ 2))) %>>%
+  # po("unbranch", id = "interaction_unbranch") %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learners %>>%
+  po("classifavg", innum = length(learners))
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:100, .(id, class, lower, upper)]
+as.data.table(graph_learner$param_set)[100:190, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  # interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # models
+  ranger.ranger.mtry.ratio = p_dbl(0.2, 1),
+  ranger.ranger.max.depth = p_int(2, 6),
+  kknn.kknn.k = p_int(5, 20),
+  # extratrees.extratrees.ntree = p_int(200, 1000),
+  # extratrees.extratrees.mtry = p_int(5, task_extreme$ncol),
+  # extratrees.extratrees.nodesize = p_int(2, 10),
+  # extratrees.extratrees.numRandomCuts = p_int(2, 5)
+  xgboost.xgboost.nrounds = p_int(100, 5000),
+  xgboost.xgboost.eta = p_dbl(1e-4, 1),
+  xgboost.xgboost.max_depth = p_int(1, 8),
+  xgboost.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  xgboost.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  xgboost.xgboost.lambda = p_dbl(0.1, 1),
+  xgboost.xgboost.gamma = p_dbl(1e-4, 1000),
+  xgboost.xgboost.alpha = p_dbl(1e-4, 1000),
+  xgboost.xgboost.subsample = p_dbl(0.1, 1)
+)
+# plan("multisession", workers = 4L)
+at_classif = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("classif.acc"),
+  search_space = search_space,
+  term_evals = 20
+)
+at_classif$train(task_extreme)
+
+# inspect results
+archive <- as.data.table(at_classif$archive)
+archive
+length(at_classif$state)
+ggplot(archive[, mean(classif.acc), by = "ranger.ranger.max.depth"], aes(x = ranger.ranger.max.depth, y = V1)) + geom_line()
+ggplot(archive[, mean(classif.acc), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_classif$predict(task_extreme)
+preds$confusion
+preds$score(msr("classif.acc"))
+
+# holdout extreme
+preds_holdout <- at_classif$predict(task_extreme_holdout)
+preds_holdout$confusion
+autoplot(preds_holdout, type = "roc")
+preds_holdout$score(msrs(c("classif.acc"))) # , "classif.recall", "classif.precision"
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+prediciotns_extreme_holdout <- prediciotns_extreme_holdout[prob.1 > 0.6]
+nrow(prediciotns_extreme_holdout)
+mlr3measures::acc(prediciotns_extreme_holdout$truth, prediciotns_extreme_holdout$response)
+
+# predictions for qc
+cols_qc <- c("symbol", "date")
+predictoins_qc <- cbind(X_holdout_[, ..cols_qc], as.data.table(preds_holdout))
+predictoins_qc[, grep("row_ids|truth", colnames(predictoins_qc)) := NULL]
+predictoins_qc <- unique(predictoins_qc)
+setorder(predictoins_qc, "date")
+
+# save to dropbox for live trading (create table for backtest)
+cols <- c("date", "symbol", colnames(predictoins_qc)[3:ncol(predictoins_qc)])
+pead_qc <- predictoins_qc[, ..cols]
+pead_qc <- pead_qc[, .(symbol = paste0(unlist(symbol), collapse = ", ")), by = date]
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-backtest")
+storage_write_csv2(pead_qc, cont, file = "pead_qc_backtest_graph.csv", col_names = FALSE)
+
+# save last predicitons for live trading
+# pead_qc_live <- pead_qc[date == max(date)]
+# bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+# cont <- storage_container(bl_endp_key, "qc-live")
+# storage_write_csv2(pead_qc_live, cont, file = "pead_qc_livr.csv", col_names = FALSE)
+
+
+
+
+# REGRESSION -------------------------------------------------------------
+# create graph
+# learners
+learners = list(
+  ranger = lrn("regr.ranger", id = "ranger"),
+  kknn = lrn("regr.kknn", id = "kknn"),
+  # extratrees = lrn("classif.extratrees", predict_type = "prob", id = "extratrees"),
+  cv_glmnet = lrn("regr.cv_glmnet", id = "cv_glmnet"),
+  xgboost = lrn("regr.xgboost", id = "xgboost")
+)
+
+# create complete grapg
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  # learners
+  learners %>>%
+  po("regravg")
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:100, .(id, class, lower, upper)]
+as.data.table(graph_learner$param_set)[100:190, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  # interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # models
+  ranger.ranger.mtry.ratio = p_dbl(0.2, 1),
+  ranger.ranger.max.depth = p_int(2, 6),
+  kknn.kknn.k = p_int(5, 20),
+  # extratrees.extratrees.ntree = p_int(200, 1000),
+  # extratrees.extratrees.mtry = p_int(5, task_extreme$ncol),
+  # extratrees.extratrees.nodesize = p_int(2, 10),
+  # extratrees.extratrees.numRandomCuts = p_int(2, 5)
+  xgboost.xgboost.nrounds = p_int(100, 5000),
+  xgboost.xgboost.eta = p_dbl(1e-4, 1),
+  xgboost.xgboost.max_depth = p_int(1, 8),
+  xgboost.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  xgboost.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  xgboost.xgboost.lambda = p_dbl(0.1, 1),
+  xgboost.xgboost.gamma = p_dbl(1e-4, 1000),
+  xgboost.xgboost.alpha = p_dbl(1e-4, 1000),
+  xgboost.xgboost.subsample = p_dbl(0.1, 1)
+)
+# plan("multisession", workers = 4L)
+at_regr = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("regr.mae"),
+  search_space = search_space,
+  term_evals = 20
+)
+at_regr$train(task_reg)
+
+# inspect results
+archive <- as.data.table(at_regr$archive)
+archive
+ggplot(archive, aes(x = ranger.ranger.mtry.ratio, y = regr.mae)) + geom_line()
+ggplot(archive[, mean(regr.mae), by = "ranger.ranger.max.depth"], aes(x = ranger.ranger.max.depth, y = V1)) + geom_line()
+ggplot(archive[, mean(regr.mae), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_ranger$predict(task_reg)
+preds$score(msr("regr.rmse"))
+
+# holdout extreme
+preds_holdout <- at_regr$predict(task_reg_holdout)
+preds_holdout$score(msrs(c("regr.rmse")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+
+prediciotns_extreme_holdout_buy <- prediciotns_extreme_holdout[response > 1]
+nrow(prediciotns_extreme_holdout_buy)
+prediciotns_extreme_holdout_buy[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                       response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns_extreme_holdout_buy$truth_01),
+                  factor(prediciotns_extreme_holdout_buy$response_01, levels = c("0", "1")))
+
+
+# SAVE DATA FRO BACKTEST --------------------------------------------------
+
+# predictions for qc
+cols_qc <- c("symbol", "date")
+predictoins_qc <- cbind(X_holdout[, ..cols_qc], as.data.table(preds_holdout))
+predictoins_qc[, grep("row_ids|truth", colnames(predictoins_qc)) := NULL]
+predictoins_qc <- unique(predictoins_qc)
+setorder(predictoins_qc, "date")
+
+# save to dropbox for live trading (create table for backtest)
+cols <- c("date", "symbol", colnames(predictoins_qc)[3:ncol(predictoins_qc)])
+pead_qc <- predictoins_qc[, ..cols]
+pead_qc <- pead_qc[, .(symbol = paste0(unlist(symbol), collapse = ", "),
+                       prob1 = paste0(unlist(response), collapse = ",")), by = date]
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-backtest")
+storage_write_csv2(pead_qc, cont, file = "pead_qc_backtest_graph.csv", col_names = FALSE)
+
+
+# save last predicitons for live trading
+pead_qc_live <- pead_qc[date == max(date)]
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-live")
+storage_write_csv2(pead_qc_live, cont, file = "pead_qc_livr.csv", col_names = FALSE)
+
+
+
+
+### GLMNET
+learner = lrn("regr.glmnet")
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learner
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:70, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # model
+  regr.glmnet.alpha = p_dbl(0, 1),
+  regr.glmnet.s = p_dbl(1e-4, 1000)
+)
+plan("multisession", workers = 4L)
+at_glmnet = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("regr.rmse"),
+  search_space = search_space,
+  term_evals = 25
+)
+at_glmnet$train(task_reg)
+
+# inspect results
+archive <- as.data.table(at_glmnet$archive)
+archive
+ggplot(archive, aes(x = regr.glmnet.alpha, y = regr.rmse)) + geom_line()
+ggplot(archive, aes(x = regr.glmnet.s, y = regr.rmse)) + geom_line()
+preds = at_glmnet$predict(task_reg)
+preds$score(msr("regr.rmse"))
+
+# holdout extreme
+preds_holdout <- at_glmnet$predict(task_reg_holdout)
+preds_holdout$score(msrs(c("regr.rmse")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+
+prediciotns_extreme_holdout_buy <- prediciotns_extreme_holdout[response > 0.02]
+nrow(prediciotns_extreme_holdout_buy)
+prediciotns_extreme_holdout_buy[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                       response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns_extreme_holdout_buy$truth_01),
+                  factor(prediciotns_extreme_holdout_buy$response_01, levels = c("0", "1")))
+
+
+
+### XGBOOST
+learner = lrn("regr.xgboost")
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learner
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:80, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # model
+  regr.xgboost.nrounds = p_int(100, 5000),
+  regr.xgboost.eta = p_dbl(1e-4, 1),
+  regr.xgboost.max_depth = p_int(1, 8),
+  regr.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  regr.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  regr.xgboost.lambda = p_dbl(0.1, 1),
+  regr.xgboost.gamma = p_dbl(1e-4, 1000),
+  regr.xgboost.alpha = p_dbl(1e-4, 1000),
+  regr.xgboost.subsample = p_dbl(0.1, 1)
+)
+plan("multisession", workers = 4L)
+at_xgboost = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("regr.rmse"),
+  search_space = search_space,
+  term_evals = 25
+)
+at_xgboost$train(task_reg)
+
+# inspect results
+archive <- as.data.table(at_xgboost$archive)
+archive
+preds = at_xgboost$predict(task_reg)
+preds$score(msr("regr.rmse"))
+
+# holdout extreme
+preds_holdout <- at_xgboost$predict(task_reg_holdout)
+preds_holdout$score(msrs(c("regr.rmse")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+
+prediciotns_extreme_holdout_buy <- prediciotns_extreme_holdout[response > 2]
+nrow(prediciotns_extreme_holdout_buy)
+prediciotns_extreme_holdout_buy[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                       response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns_extreme_holdout_buy$truth_01),
+                  factor(prediciotns_extreme_holdout_buy$response_01, levels = c("0", "1")))
+
+
+
+# TORCH -------------------------------------------------------------------
+learner <- lrn("classif.torch.tabnet", epochs = 15, batch_size = 128, predict_type = "prob")
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learner
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:60, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson")),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # model
+  classif.torch.tabnet.decision_width = p_int(8, 64),
+  classif.torch.tabnet.attention_width = p_int(8, 64),
+  classif.torch.tabnet.num_steps = p_int(4, 7),
+  classif.torch.tabnet.learn_rate = p_dbl(0.0001, 0.1)
+)
+plan("multisession", workers = 4L)
+at_tabnet = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("classif.acc"),
+  search_space = search_space,
+  term_evals = 15
+)
+at_tabnet$train(task_extreme)
+
+# inspect results
+archive <- as.data.table(at_tabnet$archive)
+archive
+ggplot(archive[, mean(classif.acc), by = "classif.torch.tabnet.decision_width"], aes(x = classif.torch.tabnet.decision_width, y = V1)) +
+  geom_line()
+ggplot(archive[, mean(classif.acc), by = "classif.torch.tabnet.attention_width"], aes(x = classif.torch.tabnet.attention_width, y = V1)) +
+  geom_line()
+ggplot(archive[, mean(classif.acc), by = "classif.torch.tabnet.num_steps"], aes(x = classif.torch.tabnet.num_steps, y = V1)) +
+  geom_line()
+ggplot(archive[, mean(classif.acc), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_tabnet$predict(task_extreme)
+preds$score(msr("classif.acc"))
+
+# holdout extreme
+preds_holdout <- at_tabnet$predict(task_extreme_holdout)
+preds_holdout$score(msrs(c("classif.acc")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+
+prediciotns_extreme_holdout_buy <- prediciotns_extreme_holdout[prob.1 > 0.6]
+nrow(prediciotns_extreme_holdout_buy)
+prediciotns_extreme_holdout_buy[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                       response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(prediciotns_extreme_holdout$truth, prediciotns_extreme_holdout$response)
+
+
+
diff --git a/pead_v3.R b/pead_v3.R
new file mode 100644
index 0000000..ac11360
--- /dev/null
+++ b/pead_v3.R
@@ -0,0 +1,1070 @@
+options(progress_enabled = FALSE)
+
+library(data.table)
+library(checkmate)
+library(tiledb)
+library(httr)
+library(fredr)
+library(alfred)
+library(finfeatures)
+library(gausscov)
+library(mlr3)
+library(mlr3verse)
+library(ggplot2)
+library(rpart.plot)
+library(DescTools)
+library(reticulate)
+library(findata)
+# Python environment and python modules
+# Instructions: some functions use python modules. Steps to use python include:
+# 1. create new conda environment:
+#    https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html
+#    Choose python 3.8. for example:
+#    conda create -n mlfinlabenv python=3.8
+# 2. Install following packages inside environments
+#    mlfinlab
+#    tsfresh
+#    TSFEL
+# python packages
+reticulate::use_python("C:/ProgramData/Anaconda3/envs/mlfinlabenv/python.exe", required = TRUE)
+mlfinlab = reticulate::import("mlfinlab", convert = FALSE)
+pd = reticulate::import("pandas", convert = FALSE)
+builtins = import_builtins(convert = FALSE)
+main = import_main(convert = FALSE)
+tsfel = reticulate::import("tsfel", convert = FALSE)
+
+
+
+# SET UP ------------------------------------------------------------------
+# check if we have all necessary env variables
+assert_choice("AWS-ACCESS-KEY", names(Sys.getenv()))
+assert_choice("AWS-SECRET-KEY", names(Sys.getenv()))
+assert_choice("AWS-REGION", names(Sys.getenv()))
+assert_choice("BLOB-ENDPOINT", names(Sys.getenv()))
+assert_choice("BLOB-KEY", names(Sys.getenv()))
+assert_choice("APIKEY-FMPCLOUD", names(Sys.getenv()))
+assert_choice("FRED-KEY", names(Sys.getenv()))
+
+# set credentials
+config <- tiledb_config()
+config["vfs.s3.aws_access_key_id"] <- Sys.getenv("AWS-ACCESS-KEY")
+config["vfs.s3.aws_secret_access_key"] <- Sys.getenv("AWS-SECRET-KEY")
+config["vfs.s3.region"] <- Sys.getenv("AWS-REGION")
+context_with_config <- tiledb_ctx(config)
+fredr_set_key(Sys.getenv("FRED-KEY"))
+
+# parameters
+strategy = "PEAD"  # PEAD (for predicting post announcement drift) or PRE (for predicting pre announcement)
+start_holdout_date = as.Date("2021-06-01") # observations after this date belongs to holdout set
+events_data <- "intersection" # data source, one of "fmp", "investingcom", "intersection"
+
+
+
+# EARING ANNOUNCEMENT DATA ------------------------------------------------
+# get events data from FMP
+arr <- tiledb_array("s3://equity-usa-earningsevents", as.data.frame = TRUE)
+events <- arr[]
+events <- as.data.table(events)
+setorder(events)
+
+# coarse filtering
+events <- events[date < Sys.Date()]                 # remove announcements for today
+events <- unique(events, by = c("symbol", "date"))  # remove duplicated symbol / date pair
+if (strategy == "PEAD") {
+  print(paste0("Remove ", sum(is.na(events$eps)), " observations because of missing eps values or ",
+               100 * round(sum(is.na(events$eps)) / nrow(events), 4), "% percent of data."))
+  events <- na.omit(events, cols = c("eps")) # remove rows with NA for earnings
+}
+
+# keep only usa stocks
+url <- modify_url("https://financialmodelingprep.com/",
+                  path = "api/v3/stock/list",
+                  query = list(apikey = Sys.getenv("APIKEY-FMPCLOUD")))
+res <- GET(url)
+stocks <- rbindlist(content(res), fill = TRUE)
+stock_symbols <- stocks[type == "stock", symbol]
+print(paste0("Remove ", nrow(events[!(symbol %in% stock_symbols)]),
+             " observations because they are not stocks but ETF, fund etc., or  ",
+             100 * round( nrow(events[!(symbol %in% stock_symbols)]) / nrow(events), 4),
+             "% percent."))
+events <- events[symbol %in% stock_symbols] # keep only stocks
+us_symbols <- stocks[exchangeShortName %in% c("AMEX", "NASDAQ", "NYSE", "OTC"), symbol]
+print(paste0("Remove ", nrow(events[!(symbol %in% us_symbols)]),
+             " observations because they are not us stocks, or ",
+             100 * round( nrow(events[!(symbol %in% us_symbols)]) / nrow(events), 4),
+             "% percent."))
+events <- events[symbol %in% us_symbols] # keep only US stocks
+
+# get investing.com data
+arr <- tiledb_array("s3://equity-usa-earningsevents-investingcom",
+                    as.data.frame = TRUE)
+investingcom_ea <- arr[]
+investingcom_ea <- as.data.table(investingcom_ea)
+if (strategy == "PEAD") {
+  investingcom_ea <- na.omit(investingcom_ea, cols = c("eps", "eps_forecast"))
+}
+investingcom_ea <- investingcom_ea[, .(symbol, time, eps, eps_forecast, revenue, revenue_forecast, right_time)]
+investingcom_ea[, date_investingcom := as.Date(time)]
+setnames(investingcom_ea, colnames(investingcom_ea)[2:6], paste0(colnames(investingcom_ea)[2:6], "_investingcom"))
+
+# merge DT and investing com earnings surprises
+events <- merge(events, investingcom_ea,
+                by.x = c("symbol", "date"),
+                by.y = c("symbol", "date_investingcom"),
+                all.x = TRUE, all.y = FALSE)
+
+# choose events subsample
+if (events_data == "intersection") {
+
+  # keep only observations available in both datasets by checking dates
+  events <- events[!is.na(date) & !is.na(as.Date(time_investingcom))]
+
+  # replace FMP cloud data with investing.com data if FMP CLOUD data doesn't exists
+  # events[, eps := ifelse(is.na(eps), eps_investingcom, eps)]
+  # events[, epsEstimated := ifelse(is.na(epsEstimated), eps_forecast_investingcom, epsEstimated)]
+  # events[, revenue := ifelse(is.na(revenue), revenue_investingcom, revenue)]
+  # events[, revenueEstimated := ifelse(is.na(revenueEstimated), revenue_forecast_investingcom, revenueEstimated)]
+
+  # check if time are the same
+  events[!is.na(right_time) & right_time == "marketClosed ", right_time := "amc"]
+  events[!is.na(right_time) & right_time == "marketOpen ", right_time := "bmo"]
+  events[, same_announce_time := time == right_time]
+
+  # if both fmp cloud and investing.com data exists keep similar
+  print(paste0("Number of removed observations because of investing.com / FMP cloud disbalance is :",
+               nrow(events[abs(eps - eps_investingcom) > 0.02]), " or ",
+               round(nrow(events[abs(eps - eps_investingcom) > 0.02]) / nrow(events), 4) * 100, "% percent."))
+  events <- events[abs(eps - eps_investingcom) < 0.02] # keep only observations where earnings are very similar
+
+  # if PRE keep only same time
+  if (strategy == "PRE") {
+    # if both fmp cloud and investing.com data exists keep similar
+    print(paste0("Number of removed observations because time of announcements are not same :",
+                 sum(!((events$same_announce_time) == TRUE), na.rm = TRUE), " or ",
+                 round(sum(!((events$same_announce_time) == TRUE), na.rm = TRUE) / nrow(events), 4) * 100, "% percent."))
+    events <- events[events$same_announce_time == TRUE] # keep only observations where earnings are very similar
+  }
+}
+
+# remove duplicated events
+events <- unique(events, by = c("symbol", "date"))
+
+
+
+# MARKET DATA AND FUNDAMENTALS ---------------------------------------------
+# import market data and fundamentals
+factors = Factors$new()
+factors_l = factors$get_factors()
+price_factors <- factors_l$prices_factos
+fundamental_factors <- factors_l$fundamental_factors
+macro <- factors_l$macro
+
+# free resources
+rm(factors_l)
+gc()
+
+# filter dates and symbols
+prices_dt <- unique(price_factors, by = c("symbol", "date"))
+setorder(prices_dt, symbol, date)
+prices_dt <- prices_dt[symbol %in% c(unique(events$symbol), "SPY")]
+prices_dt <- prices_dt[date > as.Date("2010-01-01")]
+prices_n <- prices_dt[, .N, by = symbol]
+prices_n <- prices_n[which(prices_n$N > 700)]  # remove prices with only 700 or less observations
+prices_dt <- prices_dt[symbol %in% prices_n$symbol]
+
+# save SPY for later and keep only events symbols
+spy <- prices_dt[symbol == "SPY", .(symbol, date, open, high, low, close, volume, returns)]
+
+
+
+# REGRESSION LABELING ----------------------------------------------------------
+# calculate returns
+prices_dt[, ret_5 := shift(close, -5L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]   # PEAD
+prices_dt[, ret_22 := shift(close, -21L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"] # PEAD
+prices_dt[, ret_44 := shift(close, -43L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"] # PEAD
+prices_dt[, ret_66 := shift(close, -65L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"] # PEAD
+prices_dt[, amc_return := shift(open, -1L, "shift") / close - 1, by = "symbol"] # PRE
+prices_dt[, bmo_return := open / shift(close) - 1, by = "symbol"] # PRE
+
+# calculate rolling sd
+prices_dt[, sd_5 := roll::roll_sd(close / shift(close, 1L) - 1, 5), by = "symbol"]
+prices_dt[, sd_22 := roll::roll_sd(close / shift(close, 1L) - 1, 22), by = "symbol"]
+prices_dt[, sd_44 := roll::roll_sd(close / shift(close, 1L) - 1, 44), by = "symbol"]
+prices_dt[, sd_66 := roll::roll_sd(close / shift(close, 1L) - 1, 66), by = "symbol"]
+
+# calculate spy returns
+spy[, ret_5_spy := shift(close, -5L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+spy[, ret_22_spy := shift(close, -21L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+spy[, ret_44_spy := shift(close, -43L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+spy[, ret_66_spy := shift(close, -65L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+
+# calculate excess returns
+prices_dt <- merge(prices_dt,
+                   spy[, .(date, ret_5_spy, ret_22_spy, ret_44_spy, ret_66_spy)],
+                   by = "date", all.x = TRUE, all.y = FALSE)
+prices_dt[, ret_5_excess := ret_5 - ret_5_spy]
+prices_dt[, ret_22_excess := ret_22 - ret_22_spy]
+prices_dt[, ret_44_excess := ret_44 - ret_44_spy]
+prices_dt[, ret_66_excess := ret_66 - ret_66_spy]
+prices_dt[, `:=`(ret_5_spy = NULL, ret_22_spy = NULL, ret_44_spy = NULL, ret_66_spy = NULL)]
+setorder(prices_dt, symbol, date)
+
+# calculate standardized returns
+prices_dt[, ret_excess_stand_5 := ret_5_excess / shift(sd_5, -4L), by = "symbol"]
+prices_dt[, ret_excess_stand_22 := ret_22_excess / shift(sd_22, -21L), by = "symbol"]
+prices_dt[, ret_excess_stand_44 := ret_44_excess / shift(sd_44, -43L), by = "symbol"]
+prices_dt[, ret_excess_stand_66 := ret_66_excess / shift(sd_66, -65L), by = "symbol"]
+
+# remove unnecesary columns
+prices_dt[, `:=`(ret_5 = NULL, ret_22 = NULL, ret_44 = NULL, ret_66 = NULL,
+                 sd_5 = NULL, sd_22 = NULL, sd_44 = NULL, sd_66 = NULL,
+                 ret_5_excess = NULL, ret_22_excess = NULL, ret_44_excess = NULL, ret_66_excess = NULL)]
+
+# remove NA values
+prices_dt <- na.omit(prices_dt, cols = c("symbol", "date", "ret_excess_stand_5",
+                                         "ret_excess_stand_22",  "ret_excess_stand_44",
+                                         "ret_excess_stand_66"))
+
+
+
+# MERGE MARKET DATA, EVENTS AND CLASSIF LABELS ---------------------------------
+# merge clf_data and labels
+dataset <- merge(events,
+                 prices_dt[, .(symbol, date,
+                               ret_excess_stand_5, ret_excess_stand_22,
+                               ret_excess_stand_44, ret_excess_stand_66,
+                               amc_return, bmo_return)],
+                 by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+
+# extreme labeling
+possible_target_vars <- c("ret_excess_stand_5", "ret_excess_stand_22",
+                          "ret_excess_stand_44", "ret_excess_stand_66")
+bin_extreme_col_names <- paste0("bin_extreme_", possible_target_vars)
+dataset[, (bin_extreme_col_names) := lapply(.SD, function(x) {
+  y <- cut(x,
+           quantile(x, probs = c(0, 0.2, 0.8, 1), na.rm = TRUE),
+           labels = c(-1, NA, 1),
+           include.lowest = TRUE)
+  as.factor(droplevels(y))
+}), .SDcols = possible_target_vars]
+
+# around zero labeling
+labeling_around_zero <- function(x) {
+  x_abs <- abs(x)
+  bin <- cut(x_abs, quantile(x_abs, probs = c(0, 0.3333), na.rm = TRUE), labels = 0L, include.lowest = TRUE)
+  max_0 <- max(x[bin == 0], na.rm = TRUE)
+  min_0 <- min(x[bin == 0], na.rm = TRUE)
+  levels(bin) <- c(levels(bin), 1L, -1L)
+  bin[x > max_0] <- as.character(1L)
+  bin[x < min_0] <- as.factor(-1)
+  return(bin)
+}
+bin_aroundzero_col_names <- paste0("bin_aroundzero_", possible_target_vars)
+dataset[, (bin_aroundzero_col_names) := lapply(.SD, labeling_around_zero), .SDcols = possible_target_vars]
+
+# simple labeling (ret > 0 -> 1, vice versa)
+possible_target_vars <- c("ret_excess_stand_5", "ret_excess_stand_22", "ret_excess_stand_44", "ret_excess_stand_66")
+bin_extreme_col_names <- paste0("bin_simple_", possible_target_vars)
+dataset[, (bin_extreme_col_names) := lapply(.SD, function(x) {
+  as.factor(ifelse(x > 0, 1, 0))
+}), .SDcols = possible_target_vars]
+
+# decile labeling
+bin_decile_col_names <- paste0("bin_decile_", possible_target_vars)
+dataset[, (bin_decile_col_names) := lapply(.SD, function(x) {
+  y <- cut(x,
+           quantile(x, probs = c(0, seq(0.1, 0.9, 0.1), 1), na.rm = TRUE),
+           labels = 1:10,
+           include.lowest = TRUE)
+  as.factor(droplevels(y))
+}), .SDcols = possible_target_vars]
+
+# sort dataset
+setorderv(dataset, c("symbol", "date"))
+
+
+
+# FEATURES ----------------------------------------------------------------
+# prepare arguments for features
+prices_events <- merge(prices_dt, dataset[, .(symbol, date, eps)],
+                       by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+at_ <- which(!is.na(prices_events$eps))
+
+# Ohlcv feaures
+OhlcvInstance = Ohlcv$new(prices_dt[, .(symbol, date, open, high, low, close, volume)],
+                          date_col = "date")
+if (strategy == "PEAD") {
+  lag_ <- -1L # negative lag means look forward
+} else {
+  lag_ <- 1L
+  # ako je red u events amc. label je open_t+1 / close_t; lag je -1L
+  # ako je red u events bmo. label je open_t / close_t-1; lag je -2L
+}
+
+# free memory
+rm(prices_events)
+gc()
+
+# Features from OHLLCV
+print("Calculate Ohlcv features.")
+OhlcvFeaturesInit = OhlcvFeatures$new(at = NULL,
+                                      windows = c(5, 10, 22, 22 * 3, 22 * 6, 22 * 12, 22 * 12 * 2),
+                                      quantile_divergence_window =  c(22, 22*3, 22*6, 22*12, 22*12*2))
+OhlcvFeaturesSet = OhlcvFeaturesInit$get_ohlcv_features(OhlcvInstance)
+OhlcvFeaturesSetSample <- OhlcvFeaturesSet[at_ - lag_]
+setorderv(OhlcvFeaturesSetSample, c("symbol", "date"))
+# DEBUG
+head(dataset[, .(symbol, date)])
+head(OhlcvFeaturesSetSample[symbol == "A", .(symbol, date)])
+tail(dataset[, .(symbol, date)], 10)
+OhlcvFeaturesSetSample[symbol == "ZYXI", .(symbol, date)]
+
+# free memory
+rm(OhlcvFeaturesSet)
+gc()
+
+# BidAsk features
+print("Calculate BidAsk features.")
+RollingBidAskInstance <- RollingBidAsk$new(windows = c(5, 22, 22 * 6),
+                                           workers = 8L,
+                                           at = at_,
+                                           lag = lag_,
+                                           methods = c("EDGE", "Roll", "OHLC", "OHL.CHL"))
+RollingBidAskFeatures = RollingBidAskInstance$get_rolling_features(OhlcvInstance)
+gc()
+# DEBUG
+head(dataset[, .(symbol, date)])
+head(RollingBidAskFeatures[symbol == "AA", .(symbol, date)])
+
+# BackCUSUM features
+print("Calculate BackCUSUM features.")
+RollingBackcusumInit = RollingBackcusum$new(windows = c(22 * 3, 22 * 6), workers = 8L,
+                                            at = at_, lag = lag_,
+                                            alternative = c("greater", "two.sided"),
+                                            return_power = c(1, 2))
+RollingBackCusumFeatures = RollingBackcusumInit$get_rolling_features(OhlcvInstance)
+
+# Exuber features
+print("Calculate Exuber features.")
+RollingExuberInit = RollingExuber$new(windows = c(100, 300, 600),
+                                      workers = 8L,
+                                      at = at_,
+                                      lag = lag_,
+                                      exuber_lag = 1L)
+RollingExuberFeatures = RollingExuberInit$get_rolling_features(OhlcvInstance, TRUE)
+head(dataset[, .(symbol, date)])
+head(RollingExuberFeatures[symbol == "A", .(symbol, date)])
+gc()
+
+# Forecast Features
+print("Calculate AutoArima features.")
+RollingForecatsInstance = RollingForecats$new(windows = c(252 * 2), workers = 8L,
+                                              lag = lag_, at = at_,
+                                              forecast_type = c("autoarima", "nnetar", "ets"),
+                                              h = 22)
+RollingForecatsFeatures = RollingForecatsInstance$get_rolling_features(OhlcvInstance)
+
+# GAS
+print("Calculate GAS features.")
+RollingGasInit = RollingGas$new(windows = c(100, 252),
+                                workers = 8L,
+                                at = at_,
+                                lag = lag_,
+                                gas_dist = "sstd",
+                                gas_scaling = "Identity",
+                                prediction_horizont = 10)
+RollingGasFeatures = RollingGasInit$get_rolling_features(OhlcvInstance)
+# ERROR:
+#   Error in merge.data.table(x, y, by = c("symbol", "date"), all.x = TRUE,  :
+#                               Elements listed in `by` must be valid column names in x and y
+#                             In addition: Warning message:
+#                               In merge.data.table(x, y, by = c("symbol", "date"), all.x = TRUE,  :
+#
+#                                                     Error in merge.data.table(x, y, by = c("symbol", "date"), all.x = TRUE, :
+#                                                                                 Elements listed in `by` must be valid column names in x and y
+
+# Gpd features
+print("Calculate Gpd features.")
+RollingGpdInit = RollingGpd$new(windows = c(22 * 3, 22 * 6), workers = 8L,
+                                at = at_, lag = lag_,
+                                threshold = c(0.03, 0.05, 0.07))
+RollingGpdFeatures = RollingGpdInit$get_rolling_features(OhlcvInstance)
+
+# theft catch22 features
+print("Calculate Catch22 features.")
+RollingTheftInit = RollingTheft$new(windows = c(5, 22, 22 * 3, 22 * 12),
+                                    workers = 8L, at = at_, lag = lag_,
+                                    features_set = c("catch22", "feasts"))
+RollingTheftCatch22Features = RollingTheftInit$get_rolling_features(OhlcvInstance)
+gc()
+
+# theft tsfeatures features
+print("Calculate tsfeatures features.")
+RollingTsfeaturesInit = RollingTsfeatures$new(windows = c(22 * 3, 22 * 6),
+                                              workers = 8L, at = at_,
+                                              lag = lag_, scale = TRUE)
+RollingTsfeaturesFeatures = RollingTsfeaturesInit$get_rolling_features(OhlcvInstance)
+gc()
+
+# theft tsfel features, Must be alone, because number of workers have to be 1L
+print("Calculate tsfel features.")
+RollingTheftInit = RollingTheft$new(windows = c(22 * 3, 22 * 12), workers = 1L,
+                                    at = at_, lag = lag_,  features_set = "tsfel")
+RollingTheftTsfelFeatures = suppressMessages(RollingTheftInit$get_rolling_features(OhlcvInstance))
+gc()
+
+# quarks
+RollingQuarksInit = RollingQuarks$new(windows = 22 * 6, workers = 6L, at = at_,
+                                      lag = lag_, model = c("EWMA", "GARCH"),
+                                      method = c("plain", "age"))
+RollingQuarksFeatures = RollingQuarksInit$get_rolling_features(OhlcvInstance)
+gc()
+
+# TVGARCH
+# SLOW !!!
+# Error:
+# Error in checkForRemoteErrors(val) :
+#   one node produced an error: system is computationally singular: reciprocal condition number = 1.63061e-16
+# RollingTvgarchInit = RollingTvgarch$new(windows = 22 * 6,
+#                                         workers = 6L,
+#                                         at = at_,
+#                                         lag = lag_,
+#                                         na_pad = TRUE,
+#                                         simplify = FALSE)
+# RollingTvgarchFeatures = RollingTvgarchInit$get_rolling_features(OhlcvInstance)
+
+# Wavelet arima
+RollingWaveletArimaInstance = RollingWaveletArima$new(windows = 252, workers = 6L,
+                                                      lag = lag_, at = at_, filter = "haar")
+RollingWaveletArimaFeatures = RollingWaveletArimaInstance$get_rolling_features(OhlcvInstance)
+gc()
+
+# merge all features test
+features_set <- Reduce(function(x, y) merge(x, y, by = c("symbol", "date"),
+                                            all.x = TRUE, all.y = FALSE),
+                       list(RollingBidAskFeatures,
+                            RollingBackCusumFeatures,
+                            # RollingExuberFeatures,
+                            RollingForecatsFeatures,
+                            # RollingGasFeatures,
+                            # RollingGpdFeatures,
+                            RollingTheftCatch22Features,
+                            RollingTheftTsfelFeatures,
+                            RollingTsfeaturesFeatures,
+                            RollingQuarksFeatures,
+                            # RollingTvgarchFeatures
+                            RollingWaveletArimaFeatures
+                       ))
+features <- features_set[OhlcvFeaturesSetSample, on = c("symbol", "date"), roll = Inf]
+head(OhlcvFeaturesSetSample[, 1:5])
+head(features_set[, 1:5])
+head(features[, 1:5])
+
+# save ohlcv features and merged features
+# time_ <- format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
+# fwrite(OhlcvFeaturesSet, paste0("D:/features/OhlcvFeatues-PEAD-", time_, ".csv"))
+# fwrite(features, paste0("D:/features-PEAD-", time_, ".csv"))
+# fwrite(RollingGasFeatures, paste0("D:/features-PEAD-GPD", time_, ".csv"))
+
+# import features
+# list.files("D:/features")
+features_set <- fread("D:/features/features-PEAD-20230104090450.csv")
+features_gpd <- fread("D:/features-PEAD-GPD20230116090322.csv")
+features_set <- merge(features_set, features_gpd, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+# OhlcvFeaturesSetSample <- fread("D:/features/OhlcvFeatuesPEAD-20230104113949.csv")
+# features <- fread("D:/features/features-PEAD-20221216220140.csv")
+
+# merge OHLCV and events
+features[, trading_date_after_event := date]
+features <- features[dataset, on = c("symbol", "date"), roll = -Inf]
+features[, .(symbol, date, trading_date_after_event)]
+
+# remove missing values for trading_date_after_event
+features <- features[!is.na(trading_date_after_event)]
+
+# predictors from events data
+features[, `:=`(
+  nincr = frollsum(eps > epsEstimated, 4, na.rm = TRUE),
+  nincr_half = frollsum(eps > epsEstimated, 2, na.rm = TRUE),
+  nincr_2y = frollsum(eps > epsEstimated, 8, na.rm = TRUE),
+  nincr_3y = frollsum(eps > epsEstimated, 12, na.rm = TRUE),
+  eps_diff = (eps - epsEstimated + 0.00001) / (epsEstimated + 0.00001)
+)]
+
+# clean fundamentals
+fundamentals <- fundamental_factors[date > as.Date("2009-01-01")]
+fundamentals[, acceptedDateFundamentals := acceptedDate]
+data.table::setnames(fundamentals, "date", "fundamental_date")
+fundamentals <- unique(fundamentals, by = c("symbol", "acceptedDate"))
+
+# merge features and fundamental data
+features = fundamentals[features, on = c("symbol", "acceptedDate" = "date"), roll = Inf]
+features[, .(symbol, acceptedDate, acceptedDateTime)]
+
+# remove unnecesary columns
+features[, `:=`(period.x = NULL, period.y = NULL, period = NULL, link = NULL,
+                finalLink = NULL, reportedCurrency = NULL)]
+features[symbol == "AAPL", .(symbol, fundamental_date, acceptedDate, acceptedDateFundamentals)]
+
+# change date name
+setnames(features, "acceptedDate", "date")
+
+# convert char features to numeric features
+char_cols <- features[, colnames(.SD), .SDcols = is.character]
+char_cols <- setdiff(char_cols, c("symbol", "time", "right_time"))
+features[, (char_cols) := lapply(.SD, as.numeric), .SDcols = char_cols]
+
+# import transcripts sentiments datadata
+config <- tiledb_config()
+config["vfs.s3.aws_access_key_id"] <- Sys.getenv("AWS-ACCESS-KEY")
+config["vfs.s3.aws_secret_access_key"] <- Sys.getenv("AWS-SECRET-KEY")
+config["vfs.s3.region"] <- "us-east-1"
+context_with_config <- tiledb_ctx(config)
+arr <- tiledb_array("s3://equity-transcripts-sentiments",
+                    as.data.frame = TRUE,
+                    query_layout = "UNORDERED",
+)
+system.time(transcript_sentiments <- arr[])
+tiledb_array_close(arr)
+sentiments_dt <- as.data.table(transcript_sentiments)
+setnames(sentiments_dt, "date", "time_transcript")
+attr(sentiments_dt$time, "tz") <- "UTC"
+sentiments_dt[, date := as.Date(time)]
+sentiments_dt[, time := NULL]
+
+# merge with features
+features <- sentiments_dt[features, on = c("symbol", "date"), roll = -Inf]
+features[, .(symbol, date, time_transcript, Not_FLS_positive)]
+
+# remove observations where transcripts are more than 2 days away
+features <- features[date - as.Date(time_transcript) >= -1]
+
+# macro data
+features <- macro[features, on = "date", roll = Inf]
+
+# add macro data to features
+macro_cols <- colnames(macro)[2:ncol(macro)]
+features[, (macro_cols) := lapply(.SD, nafill, type = "locf"), .SDcols = macro_cols]
+
+# checks
+any(duplicated(features[, .(symbol, date)]))
+
+
+
+# FEATURES SPACE ----------------------------------------------------------
+# features space from features raw
+cols_remove <- c("trading_date_after_event", "time", "datetime_investingcom",
+                 "eps_investingcom", "eps_forecast_investingcom", "revenue_investingcom",
+                 "revenue_forecast_investingcom", "time_dummy",
+                 "trading_date_after_event", "fundamental_date", "cik", "link", "finalLink",
+                 "fillingDate", "calendarYear", "eps.y", "revenue.y", "period.x", "period.y",
+                 "acceptedDateTime", "acceptedDateFundamentals", "reportedCurrency",
+                 "fundamental_acceptedDate", "period", "right_time",
+                 "updatedFromDate", "fiscalDateEnding", "time_investingcom",
+                 "same_announce_time", "eps", "epsEstimated", "revenue", "revenueEstimated",
+                 "same_announce_time", "time_transcript", "i.time")
+cols_non_features <- c("symbol", "date", "time", "right_time",
+                       "ret_excess_stand_5", "ret_excess_stand_22", "ret_excess_stand_44", "ret_excess_stand_66",
+                       colnames(features)[grep("aroundzero", colnames(features))],
+                       colnames(features)[grep("extreme", colnames(features))],
+                       colnames(features)[grep("bin_simple", colnames(features))],
+                       colnames(features)[grep("bin_decile", colnames(features))],
+                       "bmo_return", "amc_return",
+                       "open", "high", "low", "close", "volume", "returns")
+cols_features <- setdiff(colnames(features), c(cols_remove, cols_non_features))
+head(cols_features, 10)
+tail(cols_features, 500)
+cols <- c(cols_non_features, cols_features)
+features <- features[, .SD, .SDcols = cols]
+
+
+
+# CLEAN DATA --------------------------------------------------------------
+# convert columns to numeric. This is important only if we import existing features
+clf_data <- copy(features)
+chr_to_num_cols <- setdiff(colnames(clf_data[, .SD, .SDcols = is.character]), c("symbol", "time", "right_time"))
+clf_data <- clf_data[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+int_to_num_cols <- colnames(clf_data[, .SD, .SDcols = is.integer])
+clf_data <- clf_data[, (int_to_num_cols) := lapply(.SD, as.numeric), .SDcols = int_to_num_cols]
+log_to_num_cols <- colnames(clf_data[, .SD, .SDcols = is.logical])
+clf_data <- clf_data[, (log_to_num_cols) := lapply(.SD, as.numeric), .SDcols = log_to_num_cols]
+
+# remove duplicates
+clf_data <- unique(clf_data, by = c("symbol", "date"))
+
+# remove columns with many NA
+keep_cols <- names(which(colMeans(!is.na(clf_data)) > 0.95))
+print(paste0("Removing columns with many NA values: ", setdiff(colnames(clf_data), c(keep_cols, "right_time"))))
+clf_data <- clf_data[, .SD, .SDcols = keep_cols]
+
+# remove Inf and Nan values if they exists
+is.infinite.data.frame <- function(x) do.call(cbind, lapply(x, is.infinite))
+keep_cols <- names(which(colMeans(!is.infinite(as.data.frame(clf_data))) > 0.99))
+print(paste0("Removing columns with Inf values: ", setdiff(colnames(clf_data), keep_cols)))
+clf_data <- clf_data[, .SD, .SDcols = keep_cols]
+
+# remove inf values
+n_0 <- nrow(clf_data)
+clf_data <- clf_data[is.finite(rowSums(clf_data[, .SD, .SDcols = is.numeric], na.rm = TRUE))]
+n_1 <- nrow(clf_data)
+print(paste0("Removing ", n_0 - n_1, " rows because of Inf values"))
+
+# define feature columns
+feature_cols <- colnames(clf_data)[colnames(clf_data) %in% cols_features]
+
+# remove NA values
+n_0 <- nrow(clf_data)
+clf_data <- na.omit(clf_data, cols = feature_cols)
+n_1 <- nrow(clf_data)
+print(paste0("Removing ", n_0 - n_1, " rows because of NA values"))
+
+# remove constant columns
+# TODO: Move this to mlr3 pipeline !
+features_ <- clf_data[, ..feature_cols]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+feature_cols <- setdiff(feature_cols, remove_cols)
+
+# save features
+fwrite(clf_data, "D:/features/pead-predictors.csv")
+config <- tiledb_config()
+config["vfs.s3.aws_access_key_id"] <- Sys.getenv("AWS-ACCESS-KEY")
+config["vfs.s3.aws_secret_access_key"] <- Sys.getenv("AWS-SECRET-KEY")
+config["vfs.s3.region"] <- Sys.getenv("AWS-REGION")
+context_with_config <- tiledb_ctx(config)
+fromDataFrame(
+  obj = clf_data,
+  uri = "s3://predictors-pead",
+  col_index = c("symbol", "date"),
+  sparse = TRUE,
+  tile_domain=list(date=cbind(as.Date("1970-01-01"),
+                              as.Date("2099-12-31"))),
+  allows_dups = FALSE
+)
+
+
+
+# PREPROCESSING -----------------------------------------------------------
+# TODO: add all this mlr4 pipeline
+#  winsorization (remove outliers)
+clf_data[, q_ := data.table::quarter(as.Date(date, origin = as.Date("1970-01-01")))]
+clf_data[, (feature_cols) := lapply(.SD, Winsorize, probs = c(0.01, 0.99), na.rm = TRUE),
+         .SDcols = feature_cols,
+         by = q_]
+clf_data[, c("q_")  := NULL]
+
+# remove constant columns
+# TODO: Move this to mlr3 pipeline !
+features_ <- clf_data[, ..feature_cols]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+feature_cols <- setdiff(feature_cols, remove_cols)
+
+# remove highly correlated features
+# TODO move this to mlr3 pipe7line !
+features_ <- clf_data[, ..feature_cols]
+cor_matrix <- cor(features_)
+cor_matrix_rm <- cor_matrix                  # Modify correlation matrix
+cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
+diag(cor_matrix_rm) <- 0
+remove_cols <- colnames(features_)[apply(cor_matrix_rm, 2, function(x) any(x > 0.99))]
+print(paste0("Removing highly correlated featue (> 0.99): ", remove_cols))
+feature_cols <- setdiff(feature_cols, remove_cols)
+
+# remove missing values
+n_0 <- nrow(clf_data)
+clf_data <- na.omit(clf_data)
+n_1 <- nrow(clf_data)
+print(paste0("Removing ", n_0 - n_1, " rows because of NA values"))
+
+# uniformisation of features
+clf_data[, q_ := data.table::quarter(as.Date(date, origin = as.Date("1970-01-01")))]
+clf_data[, (feature_cols) := lapply(.SD, function(x) ecdf(x)(x)),
+         .SDcols = feature_cols,
+         by = q_]
+clf_data[, c("q_")  := NULL]
+skimr::skim(clf_data$TSFEL_0_Absolute_energy_264)
+skimr::skim(clf_data$autoarima_sd_504_Hi80)
+skimr::skim(clf_data$eps_diff)
+skimr::skim(clf_data$revenueGrowth)
+
+
+
+# FEATURE SLECTION --------------------------------------------------------
+# choose label
+print(paste0("Choose among this features: ",
+             colnames(clf_data)[grep("^ret_excess_stand", colnames(clf_data))]))
+LABEL = "ret_excess_stand_22"
+
+# TODO Move this to mlr3 pipeline!
+# define feature matrix
+cols_keep <- c(feature_cols, LABEL)
+X <- clf_data[, ..cols_keep]
+
+# winsorize LABEL
+X[, (LABEL) := Winsorize(get(LABEL), probs = c(0.01, 0.99), na.rm = TRUE)]
+skimr::skim(X[, get(LABEL)])
+label_index <- which(colnames(X) == LABEL)
+
+# gausscov requre matrix
+X <- as.matrix(X)
+y <- X[, label_index]
+X <- X[, -label_index]
+
+# data(abcq)
+# dim(abcq)
+# abcql<-flag(abcq,240,4,16)
+# a <- f1st(abcql[[1]],abcql[[2]])
+
+# f1st
+############## ADD 1 !!!!!!!!!???????? ############
+f1st_fi_ <- f1st(y, X, kmn = 10)
+predictors_f1st <- colnames(X)[f1st_fi_[[1]][, 1]]
+
+# f3st_1
+f3st_1_ <- f3st(y, X, kmn = 10, m = 1)
+predictors_f3st_1 <- unique(as.integer(f3st_1_[[1]][1, ]))[-1]
+predictors_f3st_1 <- predictors_f3st_1[predictors_f3st_1 != 0]
+predictors_f3st_1 <- colnames(X)[predictors_f3st_1]
+
+# f3st_1 m=2
+f3st_2_ <- f3st(X[, ncol(X)], X[, -ncol(X)], kmn = 20, m = 2)
+cov_index_f3st_2 <- unique(as.integer(f3st_2_[[1]][1, ]))[-1]
+cov_index_f3st_2 <- cov_index_f3st_2[cov_index_f3st_2 != 0]
+cov_index_f3st_2 <- colnames(X[, -ncol(X)])[cov_index_f3st_2]
+
+# # f3st_1 m=3
+# f3st_3_ <- f3st(X[, ncol(X)], X[, -ncol(X)], kmn = 20, m = 3)
+# cov_index_f3st_3_ <- unique(as.integer(f3st_3_[[1]][1, ]))[-1]
+# cov_index_f3st_3 <- cov_index_f3st_3[cov_index_f3st_3 != 0]
+# cov_index_f3st_3 <- colnames(X[, -ncol(X)])[cov_index_f3st_3]
+
+# save important vars
+ivars <- list(
+  predictors_f1st = predictors_f1st,
+  predictors_f3st_1 = predictors_f3st_1
+  # f3st_2_ = f3st_2_
+)
+time_ <- format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
+saveRDS(ivars, paste0("D:/mlfin/mlr3_models/PEAD-ivars-", time_, ".rds"))
+
+# import important vars
+# file.info(list.files("D:/mlfin/mlr3_models", full.names = TRUE, pattern = "PEAD"))
+# ivars <- readRDS("D:/mlfin/mlr3_models/PEAD-ivars-20221219093210.rds")
+# f1st_fi_ <- colnames(X[, -ncol(X)])[ivars$f1st_fi_[[1]][, 1]]
+# cov_index_f3st_1 <- unique(as.integer(ivars$f3st_1_[[1]][1, ]))[-1]
+# cov_index_f3st_1 <- cov_index_f3st_1[cov_index_f3st_1 != 0]
+# cov_index_f3st_1 <- colnames(X[, -ncol(X)])[cov_index_f3st_1]
+# cov_index_f3st_2 <- unique(as.integer(ivars$f3st_2_[[1]][1, ]))[-1]
+# cov_index_f3st_2 <- cov_index_f3st_2[cov_index_f3st_2 != 0]
+# cov_index_f3st_2 <- colnames(X[, -ncol(X)])[cov_index_f3st_2]
+
+# interesection of all important vars
+most_important_vars <- intersect(predictors_f1st, predictors_f3st_1)
+important_vars <- unique(c(predictors_f1st, predictors_f3st_1))
+
+
+
+# DEFINE TASKS ------------------------------------------------------------
+# select only labels and features
+labels <- colnames(clf_data)[grep(LABEL, colnames(clf_data))]
+X_mlr3 <- clf_data[, .SD, .SDcols = c("symbol", "date", feature_cols, labels)]
+
+# add groupid
+X_mlr3[, monthid := paste0(data.table::year(as.Date(date, origin = "1970-01-01")),
+                           data.table::month(as.Date(date, origin = "1970-01-01")))]
+setorder(X_mlr3, date)
+
+# task with aroundzero bins
+task_aroundzero <- as_task_classif(X_mlr3[, .SD, .SDcols = !c("symbol","date", labels[!grepl("aroundzero", labels)])],
+                                   id = "aroundzero",
+                                   target = labels[grep("aroundzero", labels)])
+
+# task with aroundzero bins
+task_decile <- as_task_classif(X_mlr3[, .SD, .SDcols = !c("symbol","date", labels[!grepl("decile", labels)])],
+                               id = "decile",
+                               target = labels[grep("decile", labels)])
+
+# bin simple
+task_simple <- as_task_classif(X_mlr3[, .SD, .SDcols = !c("symbol","date", labels[!grepl("simple", labels)])],
+                               id = "simple",
+                               target = labels[grep("simple", labels)])
+
+# task for regression
+task_reg <- as_task_regr(X_mlr3[, .SD, .SDcols = !c("symbol","date", labels[!grepl("^ret_excess_stand", labels)])],
+                         id = "reg", target = labels[grep("^ret_excess_stand", labels)])
+
+# task with extreme bins
+label_ <- labels[grep("extreme", labels)]
+X_mlr3_ <- X_mlr3[get(label_) %in% c(-1, 1) & !is.na(get(label_))]
+X_mlr3_[, (label_) := droplevels(X_mlr3_[, get(label_)])]
+task_extreme <- as_task_classif(X_mlr3_[, .SD, .SDcols = !c("symbol","date", labels[!grepl("extreme", labels)])],
+                                id = "extreme",
+                                target = labels[grep("extreme", labels)],
+                                positive = "1")
+
+# create custom cv and validation set
+create_validation_set <- function(task) {
+  # add group role
+  task_ <- task$clone()
+  task_$set_col_roles("monthid", "group")
+  groups = task_$groups
+
+  # add validation set
+  val_ind <- min(which(groups$group == "202111")):nrow(groups)
+  task$set_row_roles(rows = val_ind, role = "holdout")
+}
+create_validation_set(task_aroundzero)
+create_validation_set(task_decile)
+create_validation_set(task_simple)
+create_validation_set(task_reg)
+
+#  Instantiate Resampling
+custom = rsmp("custom")
+task_ <- task_aroundzero$clone()
+task_$set_col_roles("monthid", "group")
+groups = task_$groups
+rm(task_)
+groups_v <- groups[, unique(group)]
+train_length <- 24
+test_length <- 1
+train_groups <- lapply(0:(length(groups_v)-(train_length+1)), function(x) x + (1:train_length))
+test_groups <- lapply(train_groups, function(x) tail(x, 1) + test_length)
+train_sets <- lapply(train_groups, function(x) groups[group %in% groups_v[x], row_id])
+test_sets <- lapply(test_groups, function(x) groups[group %in% groups_v[x], row_id])
+custom$instantiate(task_aroundzero, train_sets, test_sets)
+# custom$train_set(1)
+# custom$test_set(1)
+
+
+
+# FEATURE SELECTION (TEST) ------------------------------------------------
+# select features
+test_ <- na.omit(unique(c(predictors_f3st_1)))
+# task_extreme$select(test_)
+task_aroundzero$select(test_)
+task_simple$select(test_)
+task_decile$select(test_)
+task_reg$select(test_)
+
+# rpart tree classificatoin function
+tree_visualization <- function(task_, maxdepth = 4, cp = 0.002) {
+  learner = lrn("classif.rpart", maxdepth = maxdepth,
+                predict_type = "prob", cp = cp)
+  learner$train(task_)
+  predictins = learner$predict(task_)
+  print(predictins$score(c(msr("classif.acc"), msr("classif.recall"), msr("classif.precision"), msr("classif.fbeta"))))
+  print(learner$importance())
+  rpart_model <- learner$model
+  rpart.plot(rpart_model)
+}
+tree_visualization(task_simple$clone(), cp = 0.001)
+tree_visualization(task_simple$clone(), cp = 0.0001)
+tree_visualization(task_simple$clone(), cp = 0.00001)
+
+# rpart tree regression
+learner = lrn("regr.rpart", maxdepth = 4, cp = 0.01)
+task_ <- task_reg$clone()
+learner$train(task_reg)
+predictins = learner$predict(task_reg)
+predictins$score(msr("regr.mae"))
+learner$importance()
+rpart_model <- learner$model
+rpart.plot(rpart_model)
+
+
+
+# CLASSIFICATION AUTOML ---------------------------------------------------
+# learners
+learners_l = list(
+  ranger = lrn("classif.ranger", predict_type = "prob", id = "ranger"),
+  # log_reg = lrn("classif.log_reg", predict_type = "prob", id = "log_reg"),
+  # kknn = lrn("classif.kknn", predict_type = "prob", id = "kknn"),
+  # cv_glmnet = lrn("classif.cv_glmnet", predict_type = "prob", id = "cv_glmnet"),
+  xgboost = lrn("classif.xgboost", predict_type = "prob", id = "xgboost")
+)
+# create graph from list of learners
+choices = c("ranger", "xgboost")
+learners = po("branch", choices, id = "branch_learners") %>>%
+  gunion(learners_l) %>>%
+  po("unbranch", choices, id = "unbranch_learners")
+
+# create complete grapg
+graph = po("removeconstants", ratio = 0.01) %>>%
+  # modelmatrix
+  po("branch", options = c("nop_filter", "modelmatrix"), id = "interaction_branch") %>>%
+  gunion(list(po("nop", id = "nop_filter"), po("modelmatrix", formula = ~ . ^ 2))) %>>%
+  po("unbranch", id = "interaction_unbranch") %>>%
+  po("removeconstants", id = "removeconstants_2", ratio = 0.01) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learners%>>%
+  po("classifavg", innum = length(learners_l))
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:70, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # models
+  ranger.ranger.mtry.ratio = p_dbl(0.2, 1),
+  ranger.ranger.max.depth = p_int(2, 4),
+  # kknn.kknn.k = p_int(5, 20),
+  xgboost.xgboost.nrounds = p_int(100, 5000),
+  xgboost.xgboost.eta = p_dbl(1e-4, 1),
+  xgboost.xgboost.max_depth = p_int(1, 8),
+  xgboost.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  xgboost.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  xgboost.xgboost.lambda = p_dbl(0.1, 1),
+  xgboost.xgboost.gamma = p_dbl(1e-4, 1000),
+  xgboost.xgboost.alpha = p_dbl(1e-4, 1000),
+  xgboost.xgboost.subsample = p_dbl(0.1, 1)
+)
+# plan("multisession", workers = 4L)
+
+rr = resample(task_aroundzero, graph_learner, custom, store_models = TRUE)
+rr$aggregate(msr("classif.acc"))
+rr$warnings
+rr$resampling
+rr$prediction()
+
+# holdout prediction
+rr$
+
+rr_decile = resample(task_decile, graph_learner, custom, store_models = TRUE)
+
+
+at_classif = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = custom,
+  measure = msr("classif.acc"),
+  search_space = search_space
+  # term_evals = 10
+)
+at_classif
+# at_classif$train(task_aroundzero)
+
+# inspect results
+at_classif$tuning_result
+at_classif$learner
+archive <- as.data.table(at_classif$archive)
+length(at_classif$state)
+ggplot(archive[, mean(classif.fbeta), by = "ranger.ranger.max.depth"], aes(x = ranger.ranger.max.depth, y = V1)) + geom_line()
+ggplot(archive[, mean(classif.fbeta), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+ggplot(archive[, mean(classif.fbeta), by = "interaction_branch.selection"], aes(x = interaction_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_classif$predict(task_extreme)
+preds$confusion
+preds$score(list(msr("classif.acc")))
+preds$score(list(msr("classif.fbeta"), msr("classif.acc")))
+
+# holdout extreme
+preds_holdout <- at_classif$predict(task_extreme_holdout)
+preds_holdout$confusion
+autoplot(preds_holdout, type = "roc")
+preds_holdout$score(msrs(c("classif.acc")))
+preds_holdout$score(msrs(c("classif.acc", "classif.recall", "classif.precision", "classif.fbeta")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+prediciotns_extreme_holdout <- prediciotns_extreme_holdout[`prob.1` > 0.6]
+nrow(prediciotns_extreme_holdout)
+mlr3measures::acc(prediciotns_extreme_holdout$truth,
+                  prediciotns_extreme_holdout$response)
+prediciotns_extreme_holdout[, truth := as.factor(ifelse(truth == 0, 1, -1))]
+prediciotns_extreme_holdout$truth <- droplevels(prediciotns_extreme_holdout$truth)
+prediciotns_extreme_holdout$response <- droplevels(prediciotns_extreme_holdout$response)
+# levels(prediciotns_extreme_holdout$response) <- c("-1", "1")
+# mlr3measures::acc(prediciotns_extreme_holdout$truth,
+#                   prediciotns_extreme_holdout$response)
+
+# try extreme on bin simple
+X_model_sim <- copy(X_holdout)
+levels(X_model_sim$bin_simple_ret_excess_stand_5) <- c("-1", "1")
+X_model_sim <- X_model_sim[, .SD, .SDcols = !c("symbol","date", labels[!grepl("simple", labels)])]
+setnames(X_model_sim, "bin_simple_ret_excess_stand_5", "bin_extreme_ret_excess_stand_5")
+X_model_sim$bin_extreme_ret_excess_stand_5
+# summary(X_model_sim$eps_diff)
+# X_model_sim <- X_model_sim[eps_diff > .1 | eps_diff < -.1] # sample here !
+# dim(X_model_sim)
+task_simple_on_extreme <- as_task_classif(na.omit(X_model_sim), id = "simple_on_extreme",
+                                          target = labels[grep("extreme", labels)])
+task_simple_on_extreme$select(test_)
+preds_holdout <- at_classif$predict(task_simple_on_extreme)
+as.data.table(task_simple_on_extreme)
+preds_holdout$confusion
+autoplot(preds_holdout, type = "roc")
+preds_holdout$score(msrs(c("classif.acc", "classif.recall", "classif.precision", "classif.fbeta")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+prediciotns_extreme_holdout <- prediciotns_extreme_holdout[prob.1 > 0.55]
+nrow(prediciotns_extreme_holdout)
+mlr3measures::acc(prediciotns_extreme_holdout$truth, prediciotns_extreme_holdout$response)
+
+
+task_simple_extreme_holdout
+
+# which variable correlate with extreme?
+cols_ <- c(colnames(X_model)[3:which(colnames(X_model) == "DCOILWTICO_ret_week")], "ret_excess_stand_5")
+test_ <- X_model[, ..cols_]
+dim(test_)
+test_[, 700:703]
+test_[, 1:3]
+# test_[, bin_extreme_ret_excess_stand_5 := as.integer(as.character(bin_extreme_ret_excess_stand_5))]
+# test_ <- test_[!is.na(bin_extreme_ret_excess_stand_5)]
+corr_bin <- cor(test_[, 1:702], test_$ret_excess_stand_5)
+class(corr_bin)
+head(corr_bin)
+head(corr_bin[order(corr_bin[, 1], decreasing = TRUE), , drop = FALSE])
+
+# predictions for qc
+cols_qc <- c("symbol", "date")
+predictoins_qc <- cbind(X_holdout[, ..cols_qc], as.data.table(preds_holdout))
+predictoins_qc[, grep("row_ids|truth", colnames(predictoins_qc)) := NULL]
+predictoins_qc <- unique(predictoins_qc)
+setorder(predictoins_qc, "date")
+
+# save to dropbox for live trading (create table for backtest)
+cols <- c("date", "symbol", colnames(predictoins_qc)[4:ncol(predictoins_qc)])
+pead_qc <- predictoins_qc[, ..cols]
+pead_qc[, date := as.character(date)]
+print(unique(pead_qc$symbol))
+pead_qc <- pead_qc[, .(symbol = paste0(unlist(symbol), collapse = ", "),
+                       prob1 = paste0(unlist(prob.1), collapse = ",")), by = date]
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-backtest")
+storage_write_csv2(pead_qc, cont, file = "hft.csv", col_names = FALSE)
+
+
+
+# TRAIN FINAL MODEL -------------------------------------------------------
+# train final model
+hft_mlr3_model <- at_classif$learner$train(task_extreme)
+
+# holdout extreme
+preds_holdout <- hft_mlr3_model$predict(task_aroundzero_holdout)
+preds_holdout$confusion
+autoplot(preds_holdout, type = "roc")
+preds_holdout$score(msrs(c("classif.acc", "classif.recall", "classif.precision", "classif.fbeta")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+prediciotns_extreme_holdout <- prediciotns_extreme_holdout[`prob.1` > 0.60]
+nrow(prediciotns_extreme_holdout)
+mlr3measures::acc(prediciotns_extreme_holdout$truth,
+                  prediciotns_extreme_holdout$response)
+mlr3measures::acc(prediciotns_extreme_holdout$truth,
+                  prediciotns_extreme_holdout$response)
+
+
+# time_ <- format.POSIXct(Sys.time(), format = "%Y%m%d%H%M%S")
+# saveRDS(hft_mlr3_model,
+#         paste0("D:/mlfin/mlr3_models/hft_mlr3_model-", time_, ".rds"))
+# hft_mlr3_model
+#
+#
+# hftmlr_model = readRDS(file = "D:/mlfin/mlr3_models/hft_mlr3_model-20220830164033.rds")
+# saveRDS(hftmlr_model,
+#         paste0("D:/mlfin/mlr3_models/hftmlr_model.rds"))
+

commit 55829d52b281f4e9394b08d2ff8432d38f06a1e8
Author: MislavSag <mislav.sagovac@contentio.biz>
Date:   Wed Apr 6 11:35:39 2022 +0200

    pead script

diff --git a/pead.R b/pead.R
index e69de29..849c5e7 100644
--- a/pead.R
+++ b/pead.R
@@ -0,0 +1,1074 @@
+library(data.table)
+library(checkmate)
+library(AzureStor)
+library(httr)
+library(fmpcloudr)
+library(pins)
+library(mlr3verse)
+library(mlr3torch)
+library(finfeatures)
+library(ggplot2)
+library(gausscov)
+library(DescTools)
+library(fredr)
+library(future.apply)
+library(reticulate)
+# Python environment and python modules
+# Instructions: some functions use python modules. Steps to use python include:
+# 1. create new conda environment:
+#    https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html
+#    Choose python 3.8. for example:
+#    conda create -n mlfinlabenv python=3.8
+# 2. Install following packages inside environments
+#    mlfinlab
+#    tsfresh
+#    TSFEL
+reticulate::use_python("C:/ProgramData/Anaconda3/envs/mlfinlabenv/python.exe", required = TRUE) # check the path on yout system!
+pd <- reticulate::import("pandas", convert = FALSE) # import pandas
+mlfinlab <- reticulate::import("mlfinlab", convert = FALSE) # import mlfinlab
+
+
+# SET UP ------------------------------------------------------------------
+# checks
+assert_choice("BLOB-ENDPOINT", names(Sys.getenv()))
+assert_choice("BLOB-KEY", names(Sys.getenv()))
+assert_choice("APIKEY-FMPCLOUD", names(Sys.getenv()))
+
+# global vars
+ENDPOINT = storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+CONT = storage_container(ENDPOINT, "fmpcloud")
+CONTINVESTINGCOM = storage_container(ENDPOINT, "investingcom")
+fmpc_set_token(Sys.getenv("APIKEY-FMPCLOUD"))
+CACHEDIR = "D:/findata" # here define your local folder wher data will be saved
+fred_api_key <- "fb7e8cbac4b84762980f507906176c3c"
+fredr_set_key(fred_api_key)
+
+# parameters
+strategy = "PEAD"  # can be PEAD (for predicting post announcement drift) or PRE (for predicting pre announcement)
+use_fundamental_data = FALSE  # should we use fundamental data as features?
+start_holdout_date = as.Date("2021-01-01") # observations after this date belongs to holdout set
+
+
+# EVENTS ------------------------------------------------------------------
+# get events data
+events <- as.data.table(storage_read_csv(CONT, "EarningAnnouncements.csv")) # PINS !
+events <- na.omit(events, cols = c("eps", "epsEstimated")) # remove rows with NA for earnings
+events <- events[date < Sys.Date()] # remove announcements for today
+
+# keep only usa stocks
+url <- modify_url("https://financialmodelingprep.com/", path = "api/v3/available-traded/list",
+                  query = list(apikey = Sys.getenv("APIKEY-FMPCLOUD") ))
+stocks <- rbindlist(content(GET(url)))
+filter_symbols <- stocks[exchange %in% c("AMEX", "New York Stock Exchange Arca",
+                                         "New York Stock Exchange", "NasdaqGS",
+                                         "Nasdaq", "NASDAQ", "AMEX", "NYSEArca",
+                                         "NASDAQ Global Market", "Nasdaq Global Market",
+                                         "NYSE American", "Nasdaq Capital Market",
+                                         "Nasdaq Global Select")]
+events <- events[symbol %in% filter_symbols$symbo]
+
+# investing.com data
+investingcom_ea <- as.data.table(storage_read_csv(CONTINVESTINGCOM, "EarningAnnouncementsInvestingCom.csv"))
+investingcom_ea <- na.omit(investingcom_ea, cols = c("eps", "eps_forecast"))
+investingcom_ea <- investingcom_ea[, .(symbol, datetime, eps, eps_forecast, revenue, revenue_forecast, right_time)]
+investingcom_ea[, date_investingcom := as.Date(datetime)]
+setnames(investingcom_ea, colnames(investingcom_ea)[2:6], paste0(colnames(investingcom_ea)[2:6], "_investingcom"))
+
+# merge DT and investing com earnings surprises
+events <- merge(events, investingcom_ea,
+                by.x = c("symbol", "date"),
+                by.y = c("symbol", "date_investingcom"),
+                all.x = TRUE, all.y = FALSE)
+events <- events[date == as.Date(datetime_investingcom)] # keep only observations available in both datasets
+
+# replace FMP cloud data with investing.com data if FMP CLOUD data doesn't exists
+events[, eps := ifelse(is.na(eps), eps_investingcom, eps)]
+events[, epsEstimated := ifelse(is.na(epsEstimated), eps_forecast_investingcom, epsEstimated)]
+events[, revenue := ifelse(is.na(revenue), revenue_investingcom, revenue)]
+events[, revenueEstimated := ifelse(is.na(revenueEstimated), revenue_forecast_investingcom, revenueEstimated)]
+
+# check if time are the same
+events[, right_time := ifelse(is.na(right_time), NA, ifelse(right_time == "marketClosed ", "amc", "bmc"))]
+events[, time_dummy := time == right_time]
+
+# if both fmp cloud and investing.com data exists keep similar
+print(paste0("Number of removed observations because of investing.com / FMP cloud disbalance is :",
+             nrow(events[abs(eps - eps_investingcom) > 0.04])))
+events <- events[abs(eps - eps_investingcom) < 0.04] # keep only observations where earnings are very similar
+
+# remove duplicated events
+events <- unique(events, by = c("symbol", "date"))
+
+
+# MARKET DATA -------------------------------------------------------------
+# import market data from blob. This takes long time for the firs time
+board <- board_azure(
+  container = storage_container(ENDPOINT, "fmpcloud-daily"),
+  path = "",
+  n_processes = 6L,
+  versioned = FALSE,
+  cache = CACHEDIR
+)
+files_ <- pin_list(board)
+files_ <- setdiff(files_, list.files(CACHEDIR))
+lapply(files_, pin_download, board = board)
+files_ <- pin_list(board)
+files_ <- lapply(file.path(CACHEDIR, files_), list.files, recursive = TRUE, pattern = "\\.csv", full.names = TRUE)
+files_ <- unlist(files_)
+s <- Sys.time()
+prices_dt <- lapply(files_, fread)
+e <- Sys.time()
+e - s
+prices <- prices_dt[vapply(prices_dt, function(x) nrow(x) > 0, FUN.VALUE = logical(1))]
+prices <- rbindlist(prices)
+
+# cleand daily prices
+prices <- prices[symbol %in% unique(events$symbol)] # keep only symbols available in events
+prices[, date := as.Date(date)]
+prices <- prices[open > 0 & high > 0 & low > 0 & close > 0 & adjClose > 0] # remove rows with zero and negative prices
+setorder(prices, "symbol", "date")
+prices[, returns := adjClose   / data.table::shift(adjClose) - 1, by = symbol] # calculate returns
+prices <- prices[returns < 1] # TODO:: better outlier detection mechanism. For now, remove daily returns above 100%
+adjust_cols <- c("open", "high", "low")
+prices[, (adjust_cols) := lapply(.SD, function(x) x * (adjClose / close)), .SDcols = adjust_cols] # adjust open, high and low prices
+prices[, close := adjClose]
+prices <- na.omit(prices[, .(symbol, date, open, high, low, close, volume, returns)])
+prices_n <- prices[, .N, by = symbol]
+prices_n <- prices_n[which(prices_n$N > 700)]  # remove prices with only 700 or less observations
+prices <- prices[symbol %in% prices_n$symbol]
+prices <- prices[date %between% c(min(events$date) - 1100, max(prices$date, na.rm = TRUE))] # keep only data needed for events
+prices <- unique(prices, by = c("symbol", "date")) # remove duplicates if they exists
+
+
+
+# LABELING ----------------------------------------------------------------
+# calculate returns
+prices[, ret_22 := shift(close, -21L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+prices[, ret_44 := shift(close, -43L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+prices[, ret_66 := shift(close, -65L, "shift") / shift(close, -1L, "shift") - 1, by = "symbol"]
+
+# calculate rolling sd
+prices[, sd_22 := roll::roll_sd(close / shift(close, 1L) - 1, 22), by = "symbol"]
+prices[, sd_44 := roll::roll_sd(close / shift(close, 1L) - 1, 44), by = "symbol"]
+prices[, sd_66 := roll::roll_sd(close / shift(close, 1L) - 1, 66), by = "symbol"]
+
+# calculate spy returns
+spy <- as.data.table(fmpcloudr::fmpc_price_history("SPY", min(prices$date) - 5, Sys.Date()))
+spy[, ret_22_spy := shift(adjClose, -21L, "shift") / shift(adjClose, -1L, "shift") - 1, by = "symbol"]
+spy[, ret_44_spy := shift(adjClose, -43L, "shift") / shift(adjClose, -1L, "shift") - 1, by = "symbol"]
+spy[, ret_66_spy := shift(adjClose, -65L, "shift") / shift(adjClose, -1L, "shift") - 1, by = "symbol"]
+
+# calculate excess returns
+prices <- merge(prices, spy[, .(date, ret_22_spy, ret_44_spy, ret_66_spy)], by = "date", all.x = TRUE, all.y = FALSE)
+prices[, ret_22_excess := ret_22 - ret_22_spy]
+prices[, ret_44_excess := ret_44 - ret_44_spy]
+prices[, ret_66_excess := ret_66 - ret_66_spy]
+prices[, `:=`(ret_22_spy = NULL, ret_44_spy = NULL, ret_66_spy = NULL)]
+setorder(prices, symbol, date)
+
+# calculate standardized returns
+prices[, ret_excess_stand_22 := ret_22_excess / shift(sd_22, -21L), by = "symbol"]
+prices[, ret_excess_stand_44 := ret_44_excess / shift(sd_44, -43L), by = "symbol"]
+prices[, ret_excess_stand_66 := ret_66_excess / shift(sd_66, -65L), by = "symbol"]
+
+# remove unnecesary coluns
+prices[, `:=`(ret_22 = NULL, ret_44 = NULL, ret_66 = NULL,
+              sd_22 = NULL, sd_44 = NULL, sd_66 = NULL,
+              ret_22_excess = NULL, ret_44_excess = NULL, ret_66_excess = NULL)]
+
+# labels for PRE announcement drift
+# prices_dt[, close_open_return := close / open - 1, by = "symbol"]
+# prices_dt[, open_close_return := open / shift(close) - 1, by = "symbol"]
+
+
+
+
+# ADD FEATURES (LATER THIS GOES TO FINFEATURES) ---------------------------
+# ath divergence
+# prices[, ath_month_div := (shift(frollapply(high, 22, max), 1L) / close) - 1]
+# prices[, ath_week_div := (shift(frollapply(high, 5, max), 1L) / close) - 1]
+
+
+# MERGE MARKET DATA, EVENTS AND LABELS ------------------------------------
+# merge clf_data and labels
+dataset <- merge(events,
+                 prices[, .(symbol, date, ret_excess_stand_22, ret_excess_stand_44, ret_excess_stand_66)],
+                 by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+
+# extreme labeling
+possible_target_vars <- c("ret_excess_stand_22", "ret_excess_stand_44", "ret_excess_stand_66")
+bin_extreme_col_names <- paste0("bin_extreme_", possible_target_vars)
+dataset[, (bin_extreme_col_names) := lapply(.SD, function(x) {
+  y <- cut(x,
+           quantile(x, probs = c(0, 0.2, 0.8, 1), na.rm = TRUE),
+           labels = c(-1, NA, 1),
+           include.lowest = TRUE)
+  as.factor(droplevels(y))
+}), .SDcols = possible_target_vars]
+# around zero labeling
+labeling_around_zero <- function(x) {
+  x_abs <- abs(x)
+  bin <- cut(x_abs, quantile(x_abs, probs = c(0, 0.3333), na.rm = TRUE), labels = 0L, include.lowest = TRUE)
+  max_0 <- max(x[bin == 0], na.rm = TRUE)
+  min_0 <- min(x[bin == 0], na.rm = TRUE)
+  levels(bin) <- c(levels(bin), 1L, -1L)
+  bin[x > max_0] <- as.character(1L)
+  bin[x < min_0] <- as.factor(-1)
+  return(bin)
+}
+bin_aroundzero_col_names <- paste0("bin_aroundzero_", possible_target_vars)
+dataset[, (bin_aroundzero_col_names) := lapply(.SD, labeling_around_zero), .SDcols = possible_target_vars]
+
+# sort dataset
+setorderv(dataset, c("symbol", "date"))
+
+
+# FEATURES ----------------------------------------------------------------
+# prepare arguments for features
+prices_events <- merge(prices, dataset, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+at_ <- which(!is.na(prices_events$eps))
+# fwrite(prices_dt[, 1:7], "D:/temp/PEAD-testdata.csv") # FOR TET IN FINFEATURES
+# fwrite(as.data.frame(at_), "D:/temp/PEAD-at.csv") # FOR TET IN FINFEATURES
+OhlcvInstance = Ohlcv$new(prices_dt[, 1:7], date_col = "date")
+if (strategy == "PEAD") {
+  lag_ <- -1L
+} else {
+  lag_ <- 1L
+  # ako je red u events amc. label je open_t+1 / close_t; lag je -1L
+  # ako je red u events bmo. label je open_t / close_t-1; lag je -2L
+}
+
+# Features from OHLLCV
+print("Calculate Ohlcv features.")
+OhlcvFeaturesInit = OhlcvFeatures$new(windows = c(5, 10, 22, 22 * 3, 22 * 6, 22 * 12),
+                                      quantile_divergence_window =  c(22, 22*3, 22*6, 22*12))
+OhlcvFeaturesSet = OhlcvFeaturesInit$get_ohlcv_features(OhlcvInstance)
+OhlcvFeaturesSetSample <- OhlcvFeaturesSet[at_ - lag_]
+setorderv(OhlcvFeaturesSetSample, c("symbol", "date"))
+############ DEBUG ##############
+head(dataset[, .(symbol, date)])
+head(OhlcvFeaturesSetSample[symbol == "AA", .(symbol, date)])
+############ DEBUG ##############
+
+# BidAsk features
+print("Calculate BidAsk features.")
+RollingBidAskInstance <- RollingBidAsk$new(windows = c(5, 22),
+                                           workers = 8L,
+                                           at = at_,
+                                           lag = lag_,
+                                           na_pad = TRUE,
+                                           simplify = FALSE)
+RollingBidAskFeatures = RollingBidAskInstance$get_rolling_features(OhlcvInstance)
+############ DEBUG ##############
+head(dataset[, .(symbol, date)])
+head(RollingBidAskFeatures[symbol == "AA", .(symbol, date)])
+############ DEBUG ##############
+
+gc()
+# BackCUSUM features
+print("Calculate BackCUSUM features.")
+RollingBackcusumInit = RollingBackcusum$new(windows = c(22 * 3),
+                                            workers = 8L,
+                                            at = at_,
+                                            lag = lag_,
+                                            na_pad = TRUE,
+                                            simplify = FALSE)
+RollingBackCusumFeatures = RollingBackcusumInit$get_rolling_features(OhlcvInstance)
+gc()
+# Exuber features
+print("Calculate Exuber features.")
+RollingExuberInit = RollingExuber$new(windows = c(300, 600),
+                                      workers = 8L,
+                                      at = at_,
+                                      lag = lag_,
+                                      na_pad = TRUE,
+                                      simplify = FALSE,
+                                      exuber_lag = 1L)
+RollingExuberFeatures = RollingExuberInit$get_rolling_features(OhlcvInstance)
+head(dataset[, .(symbol, date)])
+head(RollingExuberFeatures[symbol == "A", .(symbol, date)])
+gc()
+# Forecast Features
+print("Calculate AutoArima features.")
+RollingForecatsInstance = RollingForecats$new(windows = c(100, 252),
+                                              workers = 8L,
+                                              lag = lag_,
+                                              at = at_,
+                                              na_pad = TRUE,
+                                              simplify = FALSE,
+                                              forecast_type = "autoarima",
+                                              h = 22)
+RollingForecatsAutoarimaFeatures = RollingForecatsInstance$get_rolling_features(OhlcvInstance)
+print("Calculate Nnetar features.")
+gc()
+RollingForecatsInstance = RollingForecats$new(windows = c(200),
+                                              workers = 8L,
+                                              lag = lag_,
+                                              at = at_,
+                                              na_pad = TRUE,
+                                              simplify = FALSE,
+                                              forecast_type = "nnetar",
+                                              h = 22)
+RollingForecatNnetarFeatures = RollingForecatsInstance$get_rolling_features(OhlcvInstance)
+gc()
+# GAS
+print("Calculate GAS features.")
+RollingGasInit = RollingGas$new(windows = c(150),
+                                workers = 8L,
+                                at = at_,
+                                lag = lag_,
+                                na_pad = TRUE,
+                                simplify = FALSE,
+                                gas_dist = "sstd",
+                                gas_scaling = "Identity",
+                                prediction_horizont = 10)
+RollingGasFeatures = RollingGasInit$get_rolling_features(OhlcvInstance)
+gc()
+# Gpd features
+print("Calculate Gpd features.")
+RollingGpdInit = RollingGpd$new(windows = c(22 * 3, 22 * 6),
+                                workers = 8L,
+                                at = at_,
+                                lag = lag_,
+                                na_pad = TRUE,
+                                simplify = FALSE,
+                                threshold = 0.05)
+RollingGpdFeatures = RollingGpdInit$get_rolling_features(OhlcvInstance)
+gc()
+# theft catch22 features
+print("Calculate Catch22 features.")
+RollingTheftInit = RollingTheft$new(windows = c(5, 22, 22 * 3, 22 * 12),
+                                    workers = 8L,
+                                    at = at_,
+                                    lag = lag_,
+                                    na_pad = TRUE,
+                                    simplify = FALSE,
+                                    features_set = "catch22")
+RollingTheftCatch22Features = RollingTheftInit$get_rolling_features(OhlcvInstance)
+gc()
+# theft feasts features
+print("Calculate feasts features.")
+RollingTheftInit = RollingTheft$new(windows = c(22 * 3, 22 * 12),
+                                    workers = 8L,
+                                    at = at_,
+                                    lag = lag_,
+                                    na_pad = TRUE,
+                                    simplify = FALSE,
+                                    features_set = "feasts")
+RollingTheftFeastsFatures = RollingTheftInit$get_rolling_features(OhlcvInstance)
+gc()
+# theft tsfel features NO MESSAGES  !!!!
+print("Calculate Tsfeatures features.")
+RollingTheftInit = RollingTheft$new(windows = c(22 * 3, 22 * 12),
+                                    workers = 1L,
+                                    at = at_,
+                                    lag = lag_,
+                                    na_pad = TRUE,
+                                    simplify = FALSE,
+                                    features_set = "tsfel")
+RollingTheftTsfelFeatures = suppressMessages(RollingTheftInit$get_rolling_features(OhlcvInstance))
+gc()
+# theft tsfeatures features
+print("Calculate tsfeatures features.")
+RollingTsfeaturesInit = RollingTsfeatures$new(windows = c(22 * 3, 22 * 6),
+                                              workers = 8L,
+                                              at = at_,
+                                              lag = lag_,
+                                              na_pad = TRUE,
+                                              simplify = FALSE)
+RollingTsfeaturesFeatures = RollingTsfeaturesInit$get_rolling_features(OhlcvInstance)
+gc()
+
+
+# merge all features test
+cols_ohlcv <- c("symbol", "date", colnames(OhlcvFeaturesSetSample)[15:ncol(OhlcvFeaturesSetSample)])
+features <- Reduce(function(x, y) merge(x, y, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE),
+                   list(OhlcvFeaturesSetSample[, ..cols_ohlcv], RollingBidAskFeatures,
+                        RollingBackCusumFeatures, RollingExuberFeatures,
+                        RollingForecatsAutoarimaFeatures, RollingGasFeatures, RollingGpdFeatures,
+                        RollingTheftCatch22Features, RollingTheftFeastsFatures, RollingTheftTsfelFeatures,
+                        RollingTsfeaturesFeatures))
+
+# merge OHLCV and events
+features[, trading_date_after_event := date]
+features <- features[dataset, on = c("symbol", "date"), roll = -Inf]
+features[, .(symbol, date, trading_date_after_event)]
+colnames(features)
+
+# actual vs estimated
+features[, `:=`(
+  eps_diff = (eps - epsEstimated + 0.0001) / sd(eps - epsEstimated + 0.0001)
+  # rev_diff = (revenue - revenueEstimated) / close
+)]
+
+# save features to Azure blob
+setorderv(features, c("symbol", "date"))
+# save_blob_files(features, paste0("nofund-", file_name), "features")
+
+# fundamental data
+reports <- fread("D:/fundamental_data/pl.csv")
+reports[, `:=`(date = as.Date(date),
+               fillingDate = as.Date(fillingDate),
+               acceptedDateTime = as.POSIXct(acceptedDate, format = "%Y-%m-%d %H:%M:%S"),
+               acceptedDate = as.Date(acceptedDate, format = "%Y-%m-%d %H:%M:%S"))]
+fin_growth <- fread("D:/fundamental_data/fin_growth.csv")
+fin_growth[, date := as.Date(date)]
+fin_ratios <- fread("D:/fundamental_data/key_metrics.csv")
+fin_ratios[, date := as.Date(date)]
+
+# merge all fundamental data
+fundamentals <- merge(reports, fin_growth, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+fundamentals <- merge(fundamentals, fin_ratios, by = c("symbol", "date"), all.x = TRUE, all.y = FALSE)
+fundamentals <- fundamentals[date > as.Date("1998-01-01")]
+fundamentals[, acceptedDateFundamentals := acceptedDate]
+data.table::setnames(fundamentals, "date", "fundamental_date")
+fundamentals[, fundamental_acceptedDate := acceptedDate]
+str(fundamentals)
+
+# merge features and fundamental data
+features <- merge(features, fundamentals, by.x = c("symbol", "date"),
+                  by.y = c("symbol", "acceptedDate"), all.x = TRUE, all.y = FALSE)
+features[symbol == "AAPL", .(symbol, fundamental_date, date, fundamental_acceptedDate)]
+
+# mannually for naow
+features$priceToSalesRatio <- as.numeric(features$priceToSalesRatio)
+features$pfcfRatio <- as.numeric(features$pfcfRatio)
+features$evToSales <- as.numeric(features$evToSales)
+features$enterpriseValueOverEBITDA <- as.numeric(features$enterpriseValueOverEBITDA)
+features$evToFreeCashFlow <- as.numeric(features$evToFreeCashFlow)
+features$netDebtToEBITDA <- as.numeric(features$netDebtToEBITDA)
+features[, grep("^lm_", colnames(features)) := NULL]
+features[, grep("changes", colnames(features)) := NULL]
+
+# save data with fundamentals
+setorderv(features, c("symbol", "date"))
+print("Saving features with fundamentals to blob.")
+# fwrite(features, "D:/mlfin/mlr3_models/PEAD-features.csv")
+# features <- fread("D:/mlfin/mlr3_models/PEAD-features.csv")
+# colnames(features) <- gsub(" |-", "_", colnames(features))
+
+
+# FEATURES SPACE ----------------------------------------------------------
+# use fundamnetal ratios or not
+if (use_fundamental_data) {
+  features <- features[!is.na(epsgrowth)]
+} else {
+  keep_cols <- colnames(features)[1:which(colnames(features) == "eps_diff")]
+  features <- features[, ..keep_cols]
+  colnames(features) <- gsub("\\.x", "", colnames(features))
+}
+
+# features space from features raw
+cols_remove <- c("trading_date_after_event", "time", "datetime_investingcom",
+                 "eps_investingcom", "eps_forecast_investingcom", "revenue_investingcom",
+                 "revenue_forecast_investingcom", "time_dummy",
+                 "trading_date_after_event", "fundamental_date", "cik", "link", "finalLink",
+                 "fillingDate", "calendarYear", "eps.y", "revenue.y", "period.x", "period.y",
+                 "acceptedDateTime", "acceptedDateFundamentals", "reportedCurrency",
+                 "fundamental_acceptedDate", "period", "right_time")
+cols_non_features <- c("symbol", "date", "time", "right_time",
+                       "ret_excess_stand_22", "ret_excess_stand_44", "ret_excess_stand_66",
+                       colnames(features)[grep("aroundzero", colnames(features))],
+                       colnames(features)[grep("extreme", colnames(features))])
+cols_features <- setdiff(colnames(features), c(cols_remove, cols_non_features))
+cols <- c(cols_non_features, cols_features)
+features <- features[, .SD, .SDcols = cols]
+
+# add fred data
+get_fread_data <- function(id = "VIXCLS") {
+  data_ <- fredr(series_id = id, observation_start = min(features$date), observation_end = Sys.Date())
+  data_ <- as.data.table(data_)
+  data_ <- data_[, .(date, value)]
+  colnames(data_)[2] <- id
+  return(data_)
+}
+vix <- get_fread_data("VIXCLS")
+sp500 <- get_fread_data("SP500")
+# t10 <- get_fread_data("T10Y2Y")
+# ffr <- get_fread_data("DFF")
+# oilprices <- get_fread_data("DCOILWTICO")
+fread_features <- Reduce(function(x, y) merge(x, y, by = c("date"), all.x = TRUE, all.y = FALSE),
+                         list(vix, sp500))
+fread_features[, SP500_ret_month := SP500 / shift(SP500, 22) - 1]
+fread_features[, SP500_ret_year := SP500 / shift(SP500, 252) - 1]
+fread_features[, SP500_ret_week := SP500 / shift(SP500, 5) - 1]
+fread_features[, SP500 := NULL]
+features <- merge(features, fread_features, by = "date", all.x = TRUE, all.y = FALSE)
+
+
+
+# CLEAN DATA --------------------------------------------------------------
+# convert columns to numeric. This is important only if we import existing features
+clf_data <- copy(features)
+chr_to_num_cols <- colnames(clf_data[, ..cols_features][, .SD, .SDcols = is.character])
+clf_data <- clf_data[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+int_to_num_cols <- colnames(clf_data[, ..cols_features][, .SD, .SDcols = is.integer])
+clf_data <- clf_data[, (int_to_num_cols) := lapply(.SD, as.numeric), .SDcols = int_to_num_cols]
+
+# remove columns with many Inf
+# is.infinite.data.frame <- function(x) do.call(cbind, lapply(x, is.infinite))
+keep_cols <- names(which(colMeans(!is.infinite(as.data.frame(clf_data))) > 0.9))
+print(paste0("Removing columns with Inf values: ", setdiff(colnames(clf_data), keep_cols)))
+clf_data <- clf_data[, .SD, .SDcols = keep_cols]
+
+# remove rows with Inf values
+clf_data <- clf_data[is.finite(rowSums(clf_data[, .SD, .SDcols = is.numeric], na.rm = TRUE))]
+nrow(features)
+nrow(clf_data)
+
+# remove columns with lots of NA values
+keep_cols <- names(which(colMeans(!is.na(features)) > 0.9))
+keep_cols <- c(keep_cols, "bin_extreme_ret_excess_stand_22", "bin_extreme_ret_excess_stand_44", "bin_extreme_ret_excess_stand_66")
+print(paste0("Removing columns with many NA values: ", setdiff(colnames(features), keep_cols)))
+clf_data <- features[, .SD, .SDcols = keep_cols]
+
+# convert logical to integer
+chr_to_num_cols <- setdiff(colnames(clf_data[, .SD, .SDcols = is.character]), c("symbol", "time", "right_time"))
+clf_data <- clf_data[, (chr_to_num_cols) := lapply(.SD, as.numeric), .SDcols = chr_to_num_cols]
+
+
+# INSPECT FEATURES --------------------------------------------------------
+# select features vector
+feature_cols <- intersect(cols_features, colnames(clf_data))
+
+# remove NA values
+clf_data <- na.omit(clf_data, cols = feature_cols)
+
+# remove constant columns
+features_ <- clf_data[, ..feature_cols]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+feature_cols <- setdiff(feature_cols, remove_cols)
+
+# remove highly correlated features
+features_ <- clf_data[, ..feature_cols]
+cor_matrix <- cor(features_)
+cor_matrix_rm <- cor_matrix                  # Modify correlation matrix
+cor_matrix_rm[upper.tri(cor_matrix_rm)] <- 0
+diag(cor_matrix_rm) <- 0
+remove_cols <- colnames(features_)[apply(cor_matrix_rm, 2, function(x) any(x > 0.98))]
+print(paste0("Removing highly correlated featue (> 0.98): ", remove_cols))
+feature_cols <- setdiff(feature_cols, remove_cols)
+
+# TODO ADD THIS INSIDE MLR3 GRAPH
+clf_data[, y := data.table::year(as.Date(date))]
+cols <- c(feature_cols, "y")
+clf_data[, (cols) := lapply(.SD, function(x) {Winsorize(as.numeric(x), probs = c(0.01, 0.99), na.rm = TRUE)}), by = "y", .SDcols = cols]
+clf_data[, y := NULL]
+
+# remove constant columns
+features_ <- clf_data[, ..feature_cols]
+remove_cols <- colnames(features_)[apply(features_, 2, var, na.rm=TRUE) == 0]
+print(paste0("Removing feature with 0 standard deviation: ", remove_cols))
+feature_cols <- setdiff(feature_cols, remove_cols)
+
+# choose label
+print(paste0("Choose among this features: ", colnames(clf_data)[grep("^ret_excess_stand", colnames(clf_data))]))
+LABEL = "ret_excess_stand_22"
+
+
+# FEATURE SELECTION -------------------------------------------------------
+
+# gausscov features selection exmaple from package
+# library(gausscov)
+# data(boston)
+# bostint <- fgeninter(boston[,1:13],2)[[1]]
+# dim(bostint)
+# a<-f1st(boston[,14],bostint,kmn=10,sub=TRUE)
+
+# another criterion
+# data(leukemia)
+# covch=c(2.023725,1182,1219,2888,0)
+# ind<-c(1182,1219,2888,0,0,0,0,0,0)
+# ind<-matrix(ind,ncol=3)
+# m<-3
+# a<-f3sti(leukemia[[1]],leukemia[[2]],covch,ind,m)
+
+# my try
+cols_keep <- c(feature_cols, LABEL)
+X <- clf_data[, ..cols_keep]
+X <- na.omit(X)
+X <- as.matrix(X)
+# X <- model.matrix(ret_44_excess ~ .^2, data = X)
+
+# f1st
+f1st_fi <- f1st(X[, ncol(X)], X[, -ncol(X)], kmn = 20, sub = TRUE)
+cov_index_f1st <- colnames(X[, -ncol(X)])[f1st_fi[[1]][, 1]]
+
+# f3st_1
+f3st_1 <- f3st(X[, ncol(X)], X[, -ncol(X)], m = 1)
+cov_index_f3st_1 <- unique(as.integer(f3st_1[[1]][1, ]))[-1]
+cov_index_f3st_1 <- cov_index_f3st_1[cov_index_f3st_1 != 0]
+cov_index_f3st_1 <- colnames(X[, -ncol(X)])[cov_index_f3st_1]
+
+# interesection of all important vars
+most_important_vars <- intersect(cov_index_f1st, cov_index_f3st_1)
+important_vars <- c(cov_index_f1st, cov_index_f3st_1)
+
+
+# DEFINE TASKS ------------------------------------------------------------
+# train/test and holdout set
+holdout_ids <- which(clf_data$date > start_holdout_date)
+X_model <- clf_data[-holdout_ids, ]
+X_holdout <- clf_data[holdout_ids, ] # TODO SAVE THIS FOR QUANTCONNECT BACKTESTING
+
+# select only labels and features
+labels <- colnames(X_model)[grep(LABEL, colnames(X_model))]
+X_model <- X_model[, .SD, .SDcols = c("symbol", "date", feature_cols, labels)]
+X_holdout <- X_holdout[, .SD, .SDcols = c("symbol", "date", feature_cols, labels)]
+
+# task with extreme bins
+X_model_ <- X_model[get(labels[3]) %in% c(-1, 1)]
+# X_model_[, labels[3] := droplevels(X_model_[, get(labels[3])])]
+X_holdout_ <- X_holdout[get(labels[3]) %in% c(-1, 1)]
+# X_holdout_[, labels[3] := droplevels(X_holdout_[, get(labels[3])])]
+X_model_$bin_extreme_ret_excess_stand_22 <- as.factor(X_model_$bin_extreme_ret_excess_stand_22)
+X_holdout_$bin_extreme_ret_excess_stand_22 <- as.factor(X_holdout_$bin_extreme_ret_excess_stand_22)
+task_extreme <- as_task_classif(X_model_[, .SD, .SDcols = !c("symbol","date", labels[1:2])],
+                                id = "extreme", target = labels[3], positive = "1")
+task_extreme_holdout <- as_task_classif(X_holdout_[, .SD, .SDcols = !c("symbol","date", labels[1:2])],
+                                        id = "extreme_holdout", target = labels[3], positive = "1")
+
+# task with aroundzero bins
+X_model$bin_aroundzero_ret_excess_stand_22 <- as.factor(X_model$bin_aroundzero_ret_excess_stand_22)
+X_holdout$bin_aroundzero_ret_excess_stand_22 <- as.factor(X_holdout$bin_aroundzero_ret_excess_stand_22)
+task_aroundzero <- as_task_classif(X_model[, .SD, .SDcols = !c("symbol","date", labels[c(1, 3)])],
+                                   id = "aroundzero", target = labels[2])
+task_aroundzero_holdout <- as_task_classif(X_holdout[, .SD, .SDcols = !c("symbol","date", labels[c(1, 3)])],
+                                           id = "aroundzero_holdout", target = labels[2])
+
+# task for regression
+task_reg <- as_task_regr(X_model[, .SD, .SDcols = !c("symbol","date", labels[2:3])], id = "reg", target = labels[1])
+task_reg_holdout <- as_task_regr(X_holdout[, .SD, .SDcols = !c("symbol","date", labels[2:3])], id = "reg_holdout", target = labels[1])
+
+
+
+# FEATURE SELECTION (TEST) ------------------------------------------------
+# select features
+# important_vars <- setdiff(important_vars, "TSFEL_0_Histogram_7_132")
+task_extreme$select(most_important_vars)
+task_aroundzero$select(most_important_vars)
+task_reg$select(most_important_vars)
+task_extreme_holdout$select(most_important_vars)
+task_aroundzero_holdout$select(most_important_vars)
+task_reg_holdout$select(most_important_vars)
+
+
+
+# DESCRIPTIVE ANALYSIS ----------------------------------------------------
+# dependent variable
+data_ <- task_reg$data()
+dim(data_)
+skimr::skim(data_$ret_excess_stand_66)
+
+# rpart tree
+# minsplit [2,128]
+# minbucket [1,64]
+# cp  [1e−04,0.1]
+# cp [1e−04,1]
+# maxdepth [1,30]
+# minbucket [1,100]
+# minsplit [1,100]
+library(rpart.plot)
+learner = lrn("classif.rpart", maxdepth = 4, predict_type = "prob", minbucket = 50, minsplit = 10, cp = 0.001)
+learner$param_set
+task_ <- task_extreme$clone()
+learner$train(task_)
+predictins = learner$predict(task_)
+predictins$score(msr("classif.acc"))
+learner$importance()
+rpart_model <- learner$model
+rpart.plot(rpart_model)
+
+
+
+# CLASSIFICATION AUTOML ---------------------------------------------------
+# learners
+learners = list(
+  ranger = lrn("classif.ranger", predict_type = "prob", id = "ranger"),
+  # log_reg = lrn("classif.log_reg", predict_type = "prob", id = "log_reg"),
+  kknn = lrn("classif.kknn", predict_type = "prob", id = "kknn"),
+  # extratrees = lrn("classif.extratrees", predict_type = "prob", id = "extratrees"),
+  cv_glmnet = lrn("classif.cv_glmnet", predict_type = "prob", id = "cv_glmnet"),
+  xgboost = lrn("classif.xgboost", predict_type = "prob", id = "xgboost")
+)
+# create graph from list of learners
+# choices = c("ranger", "log_reg", "kknn")
+# learners = po("branch", choices, id = "branch_learners") %>>%
+#   gunion(learners_l) %>>%
+#   po("unbranch", choices, id = "unbranch_learners")
+
+# create complete grapg
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # modelmatrix
+  # po("branch", options = c("nop_filter", "modelmatrix"), id = "interaction_branch") %>>%
+  # gunion(list(po("nop", id = "nop_filter"), po("modelmatrix", formula = ~ . ^ 2))) %>>%
+  # po("unbranch", id = "interaction_unbranch") %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learners %>>%
+  po("classifavg", innum = length(learners))
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:100, .(id, class, lower, upper)]
+as.data.table(graph_learner$param_set)[100:190, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  # interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # models
+  ranger.ranger.mtry.ratio = p_dbl(0.2, 1),
+  ranger.ranger.max.depth = p_int(2, 6),
+  kknn.kknn.k = p_int(5, 20),
+  # extratrees.extratrees.ntree = p_int(200, 1000),
+  # extratrees.extratrees.mtry = p_int(5, task_extreme$ncol),
+  # extratrees.extratrees.nodesize = p_int(2, 10),
+  # extratrees.extratrees.numRandomCuts = p_int(2, 5)
+  xgboost.xgboost.nrounds = p_int(100, 5000),
+  xgboost.xgboost.eta = p_dbl(1e-4, 1),
+  xgboost.xgboost.max_depth = p_int(1, 8),
+  xgboost.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  xgboost.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  xgboost.xgboost.lambda = p_dbl(0.1, 1),
+  xgboost.xgboost.gamma = p_dbl(1e-4, 1000),
+  xgboost.xgboost.alpha = p_dbl(1e-4, 1000),
+  xgboost.xgboost.subsample = p_dbl(0.1, 1)
+)
+# plan("multisession", workers = 4L)
+at_classif = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("classif.acc"),
+  search_space = search_space,
+  term_evals = 20
+)
+at_classif$train(task_extreme)
+
+# inspect results
+archive <- as.data.table(at_classif$archive)
+archive
+length(at_classif$state)
+ggplot(archive[, mean(classif.acc), by = "ranger.ranger.max.depth"], aes(x = ranger.ranger.max.depth, y = V1)) + geom_line()
+ggplot(archive[, mean(classif.acc), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_classif$predict(task_extreme)
+preds$confusion
+preds$score(msr("classif.acc"))
+
+# holdout extreme
+preds_holdout <- at_classif$predict(task_extreme_holdout)
+preds_holdout$confusion
+autoplot(preds_holdout, type = "roc")
+preds_holdout$score(msrs(c("classif.acc"))) # , "classif.recall", "classif.precision"
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+prediciotns_extreme_holdout <- prediciotns_extreme_holdout[prob.1 > 0.6]
+nrow(prediciotns_extreme_holdout)
+mlr3measures::acc(prediciotns_extreme_holdout$truth, prediciotns_extreme_holdout$response)
+
+# predictions for qc
+cols_qc <- c("symbol", "date")
+predictoins_qc <- cbind(X_holdout_[, ..cols_qc], as.data.table(preds_holdout))
+predictoins_qc[, grep("row_ids|truth", colnames(predictoins_qc)) := NULL]
+predictoins_qc <- unique(predictoins_qc)
+setorder(predictoins_qc, "date")
+
+# save to dropbox for live trading (create table for backtest)
+cols <- c("date", "symbol", colnames(predictoins_qc)[3:ncol(predictoins_qc)])
+pead_qc <- predictoins_qc[, ..cols]
+pead_qc <- pead_qc[, .(symbol = paste0(unlist(symbol), collapse = ", ")), by = date]
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-backtest")
+storage_write_csv2(pead_qc, cont, file = "pead_qc_backtest_graph.csv", col_names = FALSE)
+
+# save last predicitons for live trading
+# pead_qc_live <- pead_qc[date == max(date)]
+# bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+# cont <- storage_container(bl_endp_key, "qc-live")
+# storage_write_csv2(pead_qc_live, cont, file = "pead_qc_livr.csv", col_names = FALSE)
+
+
+
+
+# REGRESSION -------------------------------------------------------------
+# create graph
+# learners
+learners = list(
+  ranger = lrn("regr.ranger", id = "ranger"),
+  kknn = lrn("regr.kknn", id = "kknn"),
+  # extratrees = lrn("classif.extratrees", predict_type = "prob", id = "extratrees"),
+  cv_glmnet = lrn("regr.cv_glmnet", id = "cv_glmnet"),
+  xgboost = lrn("regr.xgboost", id = "xgboost")
+)
+
+# create complete grapg
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  # learners
+  learners %>>%
+  po("regravg")
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:100, .(id, class, lower, upper)]
+as.data.table(graph_learner$param_set)[100:190, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  # interaction_branch.selection = p_fct(levels = c("nop_filter", "modelmatrix")),
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # models
+  ranger.ranger.mtry.ratio = p_dbl(0.2, 1),
+  ranger.ranger.max.depth = p_int(2, 6),
+  kknn.kknn.k = p_int(5, 20),
+  # extratrees.extratrees.ntree = p_int(200, 1000),
+  # extratrees.extratrees.mtry = p_int(5, task_extreme$ncol),
+  # extratrees.extratrees.nodesize = p_int(2, 10),
+  # extratrees.extratrees.numRandomCuts = p_int(2, 5)
+  xgboost.xgboost.nrounds = p_int(100, 5000),
+  xgboost.xgboost.eta = p_dbl(1e-4, 1),
+  xgboost.xgboost.max_depth = p_int(1, 8),
+  xgboost.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  xgboost.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  xgboost.xgboost.lambda = p_dbl(0.1, 1),
+  xgboost.xgboost.gamma = p_dbl(1e-4, 1000),
+  xgboost.xgboost.alpha = p_dbl(1e-4, 1000),
+  xgboost.xgboost.subsample = p_dbl(0.1, 1)
+)
+# plan("multisession", workers = 4L)
+at_regr = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("regr.mae"),
+  search_space = search_space,
+  term_evals = 20
+)
+at_regr$train(task_reg)
+
+# inspect results
+archive <- as.data.table(at_regr$archive)
+archive
+ggplot(archive, aes(x = ranger.ranger.mtry.ratio, y = regr.mae)) + geom_line()
+ggplot(archive[, mean(regr.mae), by = "ranger.ranger.max.depth"], aes(x = ranger.ranger.max.depth, y = V1)) + geom_line()
+ggplot(archive[, mean(regr.mae), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_ranger$predict(task_reg)
+preds$score(msr("regr.rmse"))
+
+# holdout extreme
+preds_holdout <- at_regr$predict(task_reg_holdout)
+preds_holdout$score(msrs(c("regr.rmse")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+
+prediciotns_extreme_holdout_buy <- prediciotns_extreme_holdout[response > 1]
+nrow(prediciotns_extreme_holdout_buy)
+prediciotns_extreme_holdout_buy[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                       response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns_extreme_holdout_buy$truth_01),
+                  factor(prediciotns_extreme_holdout_buy$response_01, levels = c("0", "1")))
+
+
+# SAVE DATA FRO BACKTEST --------------------------------------------------
+
+# predictions for qc
+cols_qc <- c("symbol", "date")
+predictoins_qc <- cbind(X_holdout[, ..cols_qc], as.data.table(preds_holdout))
+predictoins_qc[, grep("row_ids|truth", colnames(predictoins_qc)) := NULL]
+predictoins_qc <- unique(predictoins_qc)
+setorder(predictoins_qc, "date")
+
+# save to dropbox for live trading (create table for backtest)
+cols <- c("date", "symbol", colnames(predictoins_qc)[3:ncol(predictoins_qc)])
+pead_qc <- predictoins_qc[, ..cols]
+pead_qc <- pead_qc[, .(symbol = paste0(unlist(symbol), collapse = ", "),
+                       prob1 = paste0(unlist(response), collapse = ",")), by = date]
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-backtest")
+storage_write_csv2(pead_qc, cont, file = "pead_qc_backtest_graph.csv", col_names = FALSE)
+
+
+# save last predicitons for live trading
+pead_qc_live <- pead_qc[date == max(date)]
+bl_endp_key <- storage_endpoint(Sys.getenv("BLOB-ENDPOINT"), key=Sys.getenv("BLOB-KEY"))
+cont <- storage_container(bl_endp_key, "qc-live")
+storage_write_csv2(pead_qc_live, cont, file = "pead_qc_livr.csv", col_names = FALSE)
+
+
+
+
+### GLMNET
+learner = lrn("regr.glmnet")
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learner
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:70, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # model
+  regr.glmnet.alpha = p_dbl(0, 1),
+  regr.glmnet.s = p_dbl(1e-4, 1000)
+)
+plan("multisession", workers = 4L)
+at_glmnet = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("regr.rmse"),
+  search_space = search_space,
+  term_evals = 25
+)
+at_glmnet$train(task_reg)
+
+# inspect results
+archive <- as.data.table(at_glmnet$archive)
+archive
+ggplot(archive, aes(x = regr.glmnet.alpha, y = regr.rmse)) + geom_line()
+ggplot(archive, aes(x = regr.glmnet.s, y = regr.rmse)) + geom_line()
+preds = at_glmnet$predict(task_reg)
+preds$score(msr("regr.rmse"))
+
+# holdout extreme
+preds_holdout <- at_glmnet$predict(task_reg_holdout)
+preds_holdout$score(msrs(c("regr.rmse")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+
+prediciotns_extreme_holdout_buy <- prediciotns_extreme_holdout[response > 0.02]
+nrow(prediciotns_extreme_holdout_buy)
+prediciotns_extreme_holdout_buy[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                       response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns_extreme_holdout_buy$truth_01),
+                  factor(prediciotns_extreme_holdout_buy$response_01, levels = c("0", "1")))
+
+
+
+### XGBOOST
+learner = lrn("regr.xgboost")
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson", "pca", "ica"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"), po("pca", scale. = TRUE), po("ica"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learner
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:80, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson", "pca", "ica")),
+  pca.rank. = p_int(2, 6, depends = prep_branch.selection == "pca"),
+  ica.n.comp = p_int(2, 6, depends = prep_branch.selection == "ica"),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # model
+  regr.xgboost.nrounds = p_int(100, 5000),
+  regr.xgboost.eta = p_dbl(1e-4, 1),
+  regr.xgboost.max_depth = p_int(1, 8),
+  regr.xgboost.colsample_bytree = p_dbl(0.1, 1),
+  regr.xgboost.colsample_bylevel = p_dbl(0.1, 1),
+  regr.xgboost.lambda = p_dbl(0.1, 1),
+  regr.xgboost.gamma = p_dbl(1e-4, 1000),
+  regr.xgboost.alpha = p_dbl(1e-4, 1000),
+  regr.xgboost.subsample = p_dbl(0.1, 1)
+)
+plan("multisession", workers = 4L)
+at_xgboost = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("regr.rmse"),
+  search_space = search_space,
+  term_evals = 25
+)
+at_xgboost$train(task_reg)
+
+# inspect results
+archive <- as.data.table(at_xgboost$archive)
+archive
+preds = at_xgboost$predict(task_reg)
+preds$score(msr("regr.rmse"))
+
+# holdout extreme
+preds_holdout <- at_xgboost$predict(task_reg_holdout)
+preds_holdout$score(msrs(c("regr.rmse")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+
+prediciotns_extreme_holdout_buy <- prediciotns_extreme_holdout[response > 2]
+nrow(prediciotns_extreme_holdout_buy)
+prediciotns_extreme_holdout_buy[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                       response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(as.factor(prediciotns_extreme_holdout_buy$truth_01),
+                  factor(prediciotns_extreme_holdout_buy$response_01, levels = c("0", "1")))
+
+
+
+# TORCH -------------------------------------------------------------------
+learner <- lrn("classif.torch.tabnet", epochs = 15, batch_size = 128, predict_type = "prob")
+graph = po("removeconstants", ratio = 0.05) %>>%
+  # scaling
+  po("branch", options = c("nop_prep", "yeojohnson"), id = "prep_branch") %>>%
+  gunion(list(po("nop", id = "nop_prep"), po("yeojohnson"))) %>>%
+  po("unbranch", id = "prep_unbranch") %>>%
+  learner
+plot(graph)
+graph_learner = as_learner(graph)
+as.data.table(graph_learner$param_set)[1:60, .(id, class, lower, upper)]
+search_space = ps(
+  # preprocesing
+  prep_branch.selection = p_fct(levels = c("nop_prep", "yeojohnson")),
+  yeojohnson.standardize = p_lgl(depends = prep_branch.selection == "yeojohnson"),
+  # model
+  classif.torch.tabnet.decision_width = p_int(8, 64),
+  classif.torch.tabnet.attention_width = p_int(8, 64),
+  classif.torch.tabnet.num_steps = p_int(4, 7),
+  classif.torch.tabnet.learn_rate = p_dbl(0.0001, 0.1)
+)
+plan("multisession", workers = 4L)
+at_tabnet = auto_tuner(
+  method = "random_search",
+  learner = graph_learner,
+  resampling = rsmp("cv", folds = 3),
+  measure = msr("classif.acc"),
+  search_space = search_space,
+  term_evals = 15
+)
+at_tabnet$train(task_extreme)
+
+# inspect results
+archive <- as.data.table(at_tabnet$archive)
+archive
+ggplot(archive[, mean(classif.acc), by = "classif.torch.tabnet.decision_width"], aes(x = classif.torch.tabnet.decision_width, y = V1)) +
+  geom_line()
+ggplot(archive[, mean(classif.acc), by = "classif.torch.tabnet.attention_width"], aes(x = classif.torch.tabnet.attention_width, y = V1)) +
+  geom_line()
+ggplot(archive[, mean(classif.acc), by = "classif.torch.tabnet.num_steps"], aes(x = classif.torch.tabnet.num_steps, y = V1)) +
+  geom_line()
+ggplot(archive[, mean(classif.acc), by = "prep_branch.selection"], aes(x = prep_branch.selection, y = V1)) + geom_bar(stat = "identity")
+preds = at_tabnet$predict(task_extreme)
+preds$score(msr("classif.acc"))
+
+# holdout extreme
+preds_holdout <- at_tabnet$predict(task_extreme_holdout)
+preds_holdout$score(msrs(c("classif.acc")))
+prediciotns_extreme_holdout <- as.data.table(preds_holdout)
+
+prediciotns_extreme_holdout_buy <- prediciotns_extreme_holdout[prob.1 > 0.6]
+nrow(prediciotns_extreme_holdout_buy)
+prediciotns_extreme_holdout_buy[, `:=`(truth_01 = ifelse(truth > 0, 1, 0),
+                                       response_01 = ifelse(response > 0, 1, 0))]
+mlr3measures::acc(prediciotns_extreme_holdout$truth, prediciotns_extreme_holdout$response)

commit 95bdc57d4e4e46dbe9ce9847def9881a008cc767
Author: MislavSag <mislav.sagovac@contentio.biz>
Date:   Wed Apr 6 11:33:40 2022 +0200

    Init

diff --git a/.gitignore b/.gitignore
new file mode 100644
index 0000000..5b6a065
--- /dev/null
+++ b/.gitignore
@@ -0,0 +1,4 @@
+.Rproj.user
+.Rhistory
+.RData
+.Ruserdata
diff --git a/PEAD.Rproj b/PEAD.Rproj
new file mode 100644
index 0000000..e83436a
--- /dev/null
+++ b/PEAD.Rproj
@@ -0,0 +1,16 @@
+Version: 1.0
+
+RestoreWorkspace: Default
+SaveWorkspace: Default
+AlwaysSaveHistory: Default
+
+EnableCodeIndexing: Yes
+UseSpacesForTab: Yes
+NumSpacesForTab: 2
+Encoding: UTF-8
+
+RnwWeave: Sweave
+LaTeX: pdfLaTeX
+
+AutoAppendNewline: Yes
+StripTrailingWhitespace: Yes
diff --git a/pead.R b/pead.R
new file mode 100644
index 0000000..e69de29
